1. 110: Je tiens aussi à remercier mon ami Franz Ridde , professeur en MPSI au lycée du Parc de Lyon , qui ***m'*** a fourni un grand nombre d' exercices ..




1. 142: Il servira de support au cours , de guide et permettra , à ceux qui ***le*** souhaitent , d' approfondir quelques sujets ..
1. 3891: Partie génératrice Soit A E , on dit que A est une partie génératrice de E si Vect(A ) E Famille génératrice Soit ( ai ) iI E I une famille de vecteurs de E , on dit que c' est une famille génératrice de E si Quelle différence y a -t -il entre la famille ( ai ) iI et ai , i I ? Dans un ensemble , les termes ne apparaissent qu' une seule fois , alors que dans une famille , il est possible de ***les*** répéter ..
1. 6692: on a la décomposition en somme directe de E suivante : Vect(ei ) Démonstration Immédiat : on utilise la proposition 1.7 , page 29 et on remarque que la famille ( ei ) iI est libre si et seulement si ***les*** Vect(ei ) sont en somme directe ..
1. 7437: On a donc p n. On peut aussi énoncer ce résultat avec une famille génératrice de cardinal quelconque ( peut-être infini ) , où l' on pourra échanger p vecteurs de cette famille tout en ***la*** gardant génératrice ..
1. 8084: Si une famille de plus de n 1 éléments est libre , on pourrait ***la*** compléter en une base qui contiendrait au moins n 1 éléments , ce qui contredit dim E n. 2 ..
1. 16654: Comment démontrer qu' une famille de formes linéaires est une base ? En utilisant la base ante - duale ( si l' on est capable de ***la*** trouver ) ..
1. 17410: Alors : Il suffit de ***le*** vérifier pour x h .a , où h Ker ( ) et K. ( Hérédité ) : supposons le résultat vrai au rang p 1 , soit ( 1 , ..
1. 19003: , xp ) Kp : où ***les*** ai , j et les bi sont des scalaires 2 ..
1. 27192: En effet , il suffit de savoir ***le*** faire sur une matrice 2 2 ( a 6 0 et b 6 0 ) : Il est important de noter que : 1 ..
1. 27379: 2.7.1 Soit la matrice : ( a ) Calculer son rang r. ( b ) Trouver deux matrices P et Q inversibles telles que : 2.7.2 Déterminer ***les*** a K tels que la matrice : soit inversible Démontrer que A est inversible et calculer son inverse ..
1. 37037: Cependant , pour une matrice , il est fondamental de préciser le corps K dans lequel on travaille ( il est possible qu' une matrice Mn ( R ) ne soit pas diagonalisable mais qu' elle soit diagonalisable si on ***la*** voit comme une matrice de Mn ( C ) ) ..
1. 38663: On peut vérifier en Wxmaxima , mais il faut savoir ***le*** faire à la main ! On recommence sur la sous-matrice 2 2 : A1 est la matrice d' un endomorphisme u1 de E1 dans la base ( e2 , e3 ) , où E1 Vecte2 , e3 ..
1. 40550: Lorsque l' on part d' une suite récurrente multiple ( les coefficients étant constants ) , on peut vectorialiser et ***la*** considérer comme un système récurrent ..
1. 40764: Lorsque l' on part d' une équation différentielle linéaire d' ordre p , à coefficients constants de la forme : on peut ***la*** vectorialiser , pour se ramener à un système en posant Par exemple , on peut transformer : Le cas où la matrice A est diagonalisable est facile car si A P D P 1 avec D Diag(1 , ..
1. 41144: 4.4.5 Résoudre le système différentiel 4.4.6 Déterminer ***les*** a R tels que le système admette au moins une solution non nulle bornée au voisinage de ..
1. 47394: on trigonalise Bk de manière à ***la*** mettre sous la forme : Bk k .Ink Nk où Nk est triangulaire supérieure nilpotente ..
1. 47960: On conclut alors en appliquant la réduction de Frobenius à u. On peut aussi ***le*** démontrer directement ( voir l' exercice 5.3.11 , page 251 ) ..
1. 48696: Extraction de racine : soit A Mn ( K ) et p N , existe -t -il des matrices B telles que B p A ? Et si c' est le cas , comment ***les*** trouver toutes ? 2 ..
1. 48737: Logarithme : soit A Mn ( K ) ( K R ou C ) , existe -t -il des matrices B telles que B p A ? Et si c' est le cas , comment ***les*** trouver toutes ? L' extraction de racine possède deux propriétés immédiates : 1 ..
1. 50830: Étape 2 Si il existe sur la première ligne ( ou la première colonne ) un élément m1,k ( ou mk,1 ) non multiple de m1,1 , on ***le*** remplace ( en utilisant une transvection ) par le reste de la division euclidienne de m1,k ( ou mk,1 ) par m1,1 et on revient à l' étape 1 en permutant les colonnes ( ou les lignes ) 1 et k. Etape 3 L' étape 2 a pour effet de diminuer strictement ( M ) , elle ne peut donc se réaliser qu' un nombre fini de fois ..
1. 50932: On utilise alors m1,1 comme pivot pour ***les*** annuler ..






1. 20150: Réciproquement , si A ai , j ( i , j)1,n1,p Mn , p ( K ) , on peut ***lui*** associer canoniquement l' application linéaire f définie sur Kp ( de base canonique ( e1 , ..




1. 24: Algèbre linéaire Alain Chillès ( ) , , , Valentin Vinoles , Adrien Joseph Remerciements Nous tenons à remercier chaudement tous les professeurs qui ***nous*** ont aidés à écrire ce livre , notamment en corrigeant les inévitables fautes ..
1. 7912: Ce qui ***nous*** donne , par exemple , Cherchons un supplémentaire de F ( et une base de ce supplémentaire ) : on cherche un vecteur qui ne est pas dans Vect(e1 , e2 ) ..
1. 14884: Mais , par décomposition en somme directe , on a : En appliquant f , il vient : Dans le cas de la dimension finie ( dim E ) , on obtient que Im(f ) est de dimension finie et que dim Im(f ) dim F Or , la formule de Grasmann ( proposition 1.3 , page 44 ) ***nous*** donne que dim F dim E dim Ker(f ) soit , le théorème du rang ! ( théorème 1.4 , page 57 ) Pourquoi appelle -t -on ce résultat théorème de factorisation des applications linéaires ? Si on regarde le diagramme 1.3 , de la présente page ..
1. 15427: ) Si v est inversible , alors u v 1 w. Dans le cas contraire , nous allons essayer de ***nous*** y ramener : ( Analyse ) Si u existe , alors b w v u donc w Pour pouvoir restreindre v à F 0 ( supplémentaire de Ker(v ) ) , nous allons imposer une condition supplémentaire à u permettant la co-restriction à F 0 de u : e inversible ! donc , dans ce cas , on a la condition nécessaire : ( Synthèse ) Soit u L ( E , E 0 ) défini par : ou , si l' on préfère : Alors , si x E , on a Le candidat ne est parfois pas celui dont on a besoin ! La vérification est indispensable ! b. La co-restriction est possible d' après l' hypothèse ..
1. 17037: La dimension commune de tous les supplémentaires de F est appelée codimension de F et notée ( si E F G ) : codim F dim G Si E est de dimension finie , tous les sous-espaces vectoriels de E sont de codimension finie et si F est un sous-espace vectoriel de E , alors : codim F dim E dim F Cette notion ne est donc pas intéressante en dimension finie , elle ***nous*** sera surtout utile en dimension 1 ..
1. 17489: On a on peut donc appliquer l' hypothèse de récurrence qui ***nous*** donne : On a alors : donc , d' après l' initialisation : Dans R3 , les hyperplans sont des plans et on a la situation géométrique de la figure 1.7 , de la présente page ..
1. 17573: Notons H1 Ker(1 ) , H2 Ker(2 ) , si 1 et 2 sont indépendantes , les deux plans se coupent suivant la droite D. Soit K un plan contenant D ( comme sur le dessin ) , où K Ker ( ) , le théorème ***nous*** assure alors Le plan K a donc pour équation : Cette équation est définie à un coefficient de proportionnalité près , donc Figure 1.7 Hyperplans de R3 Le résultat de cette proposition est particulièrement intéressant en géométrie affine ..
1. 19342: ( e ) Comparer aux solutions du système récurrent obtenu par discrétisation : Interpolation Proposition 1.14 Interpolation de Lagrange Soit f : I K , où I est un intervalle de R. Soit x1 xn des réels dans I , on appelle fonction polynomiale d' interpolation de Lagrange l' unique fonction polynomiale P de degré n , telle que Elle est égale à : Démonstration E f polynomiale de degré n Cet espace vectoriel est clairement de dimension n , de base La famille de E ? définie par : étant une base de E ? , on sait qu' il existe une base ante - duale ( Pk ) k1,n qui vérifie : Un calcul simple ***nous*** démontre que : On cherche ensuite une solution sous la forme : en évaluant sur les xj , on trouve l' unique solution de l' énoncé ..
1. 25385: La factorisation de uM ***nous*** donne l' existence d' un supplémentaire E1 de Ker(uM ) isomorphe à Im(uM ) ..
1. 25437: , ep ) de Ker(uM ) ce qui ***nous*** donne une base E ( e1 , ..
1. 29782: Cela ***nous*** donne un moyen effectif de calculer la signature d' une permutation ( bien qu' il existe des algorithmes nettement plus performants ) ..
1. 33030: On peut démontrer que le calcul du déterminant d' une matrice carrée de taille n par la méthode du pivot de Gauss nécessite un nombre d' opération de l' ordre de n3 , ce qui est bien meilleur que n!. Soit à calculer ( n 2 ) : En faisant les transvections successives ( qui conservent le déterminant ) : On fait apparaître deux lignes identiques , donc : Si a , b , c , d , e , f , g , h et i sont dans K , alors e f aei dhc gbf gec ahf dbi que l' on peut mémoriser par la règle de Sarrus : On remarque , qu' avant développement , Wxmaxima ***nous*** proposait une formule non développée , qu' on peut ré-écrire : Que se passe -t -il pour n plus grand ? On reconnaît l' expression : Soit A Mn ( K ) , soit ( k , ) 1 , n , on note a Ak , la matrice de Mn1 ( K ) obtenue à partir de A en supprimant sa k - ième ligne et sa -ième colonne ..
1. 36377: Il pourrait être tentant de passer systématiquement par le polynôme caractéristique pour trouver les éléments propres de u , ce serait pourtant une grosse erreur , car si il ***nous*** permet de trouver les valeurs propres de u , il ne nous donne aucune information sur les espaces propres ..
1. 36389: Il pourrait être tentant de passer systématiquement par le polynôme caractéristique pour trouver les éléments propres de u , ce serait pourtant une grosse erreur , car si il nous permet de trouver les valeurs propres de u , il ne ***nous*** donne aucune information sur les espaces propres ..
1. 40339: La recherche d' une solution particulière , soit évidente , soit par variation de la constante a : ***Nous*** sommes donc ramenés au calcul de An ..
1. 45212: La propriété précédente implique que : ( Ak ) kN est bornée , alors ( A ) 1 et si ( A ) 1 alors ( Ak ) kN est bornée Ainsi , le calcul du rayon spectral de A ( souvent calculé de manière approchée dans les applications ) ***nous*** permet de démontrer la stabilité d' une méthode numérique ..
1. 45757: A ) B(s ) ds ***Nous*** sommes donc ramenés au calcul de exp(t ..
1. 48652: ( f ) Démontrer que : ( g ) Démontrer que : ( h ) En déduire la proposition 5.3 , page 249 Résolution d' équations matricielles Nous allons ***nous*** intéresser à deux types d' équations : 1 ..
1. 48997: On en déduit que B1 est diagonalisable dans C , égale à I2 ou semblable à Diag(j , j 2 ) avec j exp(2 i 3 ) , ce qui ramené dans R ***nous*** donne : Finalement , les B qui conviennent vérifient : Le calcul brutal ne est pas efficace ! Même si l' on pense à montrer que B C ( A ) ..
1. 51684: Dans Z5 Z ( Nous noterons toujours les classes sous la forme a ) Le même raisonnement ***nous*** conduit , lorsque le polynôme caractéristique est scindé aux matrices ( ( , ) Z5 Z2 ) impossible de période 1 , 5 ou 20 de période 1 , 2 ou 4 En effet , on sait d' après le petit théorème de Fermat que ce qui justifie la période 1 , 2 ou 4 pour la troisième forme de matrice ..
1. 51814: De plus , si n N , à l' aide de la formule du binôme de Newton , on a si 6 0 ( cas évident où la période est 1 , à partir du second rang ) et 6 1 ( cas simple ou la périodicité est 5 , la première condition ci-dessous étant inutile ) , la matrice est égale à I2 si ce qui ***nous*** donne une période de 10 ou 20 ..
1. 18616: On définit l' application transposée de u et on note : ( a ) Démontrer que t ( u v ) t u t v. ( b ) Démontrer que : ( c ) Démontrer que : Applications Systèmes linéaires Ce paragraphe , très simple , est fondamental ! Nous ***nous*** en servirons très souvent ! Soit E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) et e0 E 0 , on appelle système linéaire l' équation d' inconnue x E : L' ensemble : est appelé ensemble des solutions de ( S ) ..
1. 49447: Nous ***nous*** intéressons ici à la relation de similitude ..
