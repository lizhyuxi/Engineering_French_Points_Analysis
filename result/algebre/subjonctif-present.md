621

**688**: , En Produit cartésien de la famille d' ensembles ( Ei ) iI , où I est un ensemble quelQ conque les éléments de iI Ei sont notés ( xi ) iI où , pour tout i I , xi Ei Ensemble des Q familles d' éléments de l' ensemble E indexées par l' ensemble F ( correspond à iF Ei où tous les Ei sont égaux à E ) Classe d' équivalence de x pour la relation R Classe(x , R ) Quantificateurs Quantificateurs ( usage ) Quel que ***soit***

**1753**: , xn ) dans la base E Déterminant d' un endomorphisme u L ( E ) Cofacteur d' indices ( i , j ) de la matrice A Comatrice de A Déterminant de Vandermonde Ensemble des formes p - linéaires de E dans K Ensemble des formes p - linéaires symétriques de E dans K Ensemble des formes p - linéaires antisymétriques de E dans K Réduction des endomorphismes Sp(u ) ou Sp(A ) multu ( ) ou multA ( ) Espace propre de u L ( E ) ou A pour la valeur propre K Spectre de u L ( E ) ou A Polynôme caractéristique de u L ( E ) ou A Multiplicité de dans u ou A Algèbre engendrée par u ou A Signification Polynôme d' endomorphisme ou de matrice Idéal annulateur de u ou A Polynôme minimal de u ou A Matrice compagnon du polynôme P Norme subordonnée de u ou A Espace des endomorphismes continus de E Rayon spectral de u ou A Commutant de u ou A Espace caractéristique de u ou A Chapitre 1 Espaces vectoriels sur R ou C Dans ce chapitre , nous noterons K les corps R ou C. Cela signifie alors que le résultat énoncé est vrai dans R et dans C. Généralités Premières définitions ***Soit*** E un ensemble non vide , on dit que E est un K - espace vectoriel ( ou un espace vectoriel sur K ) si il vérifie les axiomes suivants : 1

**2210**: Si X est un ensemble et si E est un K - espace vectoriel , alors F ( X , E ) f : X E est un K - espace vectoriel ***Soit*** E un K - espace vectoriel

**2226**: Combinaison linéaire d' un nombre fini de vecteurs ***Soit*** ( x1 ,

**2419**: Produit fini d' espaces vectoriels ***Soit*** E1 , ... , En des K - espaces vectoriels , l' ensemble E1 En est alors muni d' une structure de K - espace vectoriel définie par ( avec des notations évidentes ) : Produit quelconque d' espaces vectoriels Si E est un K - espace vectoriel et I un ensemble ( d' indices ) , alors , de même , E I est muni d' une structure de K - espace vectoriel définie par ( avec des notations évidentes ) : 1

**2585**: 1.1.1 Démontrer que , dans tout K - espace vectoriel , les relations suivantes sont vérifiées : 1.1.2 Parmi les ensembles suivants , lesquels , munis des opérations usuelles , sont des R - espaces vectoriels ? Sous-espaces vectoriels ***Soit*** E un K - espace vectoriel et F E , on dit que F est un sous-espace vectoriel de E si : F est stable par ( c' est - à - dire que pour tout ( x , y ) F 2 , x y F ) F est stable par

**2661**: ***Soit*** E un K - espace vectoriel tel que E 6 0E et soit x E 0E

**2674**: Soit E un K - espace vectoriel tel que E 6 0E et ***soit*** x E 0E

**2827**: ***Soit*** E un K - espace vectoriel et soit F E , F 6

**2835**: Soit E un K - espace vectoriel et ***soit*** F E , F 6

**2874**: Démonstration Supposons que F ***soit*** sous-espace vectoriel de E. Alors est une opération interne sur F F ( car F est stable par ) , qui est associative ( car elle l' est sur E F ) , possède un élément neutre 0E F , tout élément de F possède un unique opposé dans F ( si x F , x ( 1).x F car F est stable par

**3099**: ***Soit*** E un K - espace vectoriel et soit F E , F 6

**3107**: Soit E un K - espace vectoriel et ***soit*** F E , F 6

**3139**: Démonstration Supposons que F ***soit*** un sous-espace vectoriel de E. Soit x1 ,

**3145**: Démonstration Supposons que F soit un sous-espace vectoriel de E. ***Soit*** x1 ,

**3165**: , xn des vecteurs de F ( qui existent car F 6 ) et ***soit*** ( 1 ,

**3216**: Réciproquement , supposons que F ***soit*** stable par combinaisons linéaires

**3266**: On a alors Finalement , F est un sous-espace vectoriel de E. ***Soit*** E un K - espace vectoriel

**3339**: Stabilité par intersection finie Si F1 et F2 sont deux sous-espaces vectoriels de E , alors F1 F2 est un sous-espace vectoriel de E. Stabilité par intersection quelconque Plus généralement , si ( Fi ) iI est une famille de sous-espaces vectoriels de E , alors Fi est un sous-espace vectoriel de E Démonstration On a 0E F car 0E Fi pour tout i I ***Soit*** ( x , y ) F 2

**3386**: ***Soit*** x F et soit K. En particulier , pour tout i I on a x Fi donc .x Fi pour tout i I ( car les Fi sont stables par

**3390**: Soit x F et ***soit*** K. En particulier , pour tout i I on a x Fi donc .x Fi pour tout i I ( car les Fi sont stables par

**3517**: ***Soit*** E un K - espace vectoriel et soit A E , on appelle sous-espace vectoriel engendré par A le plus petit sous-espace vectoriel de E contenant A. On le note : Démonstration que la notion de sous-espace vectoriel engendré par une partie est bien définie L' existence d' un plus petit sous-espace vectoriel contenant A mérite une justification

**3525**: Soit E un K - espace vectoriel et ***soit*** A E , on appelle sous-espace vectoriel engendré par A le plus petit sous-espace vectoriel de E contenant A. On le note : Démonstration que la notion de sous-espace vectoriel engendré par une partie est bien définie L' existence d' un plus petit sous-espace vectoriel contenant A mérite une justification

**3644**: Par définition , tout sous-espace vectoriel de E qui contient A contient aussi Vect(A ) , c' est donc bien le petit sous-espace vectoriel de E contenant A. ***Soit*** E un K - espace vectoriel

**3794**: ( ) A est inclus dans Vect(A ) ( par définition ) qui est stable par combinaisons linéaires , donc Vect(A ) contient toutes les combinaisons linéaires de vecteurs de A. ***Soit*** E un K - espace vectoriel

**3804**: Partie génératrice ***Soit*** A E , on dit que A est une partie génératrice de E si Vect(A ) E Famille génératrice Soit ( ai ) iI E I une famille de vecteurs de E , on dit que c' est une famille génératrice de E si Quelle différence y a -t -il entre la famille ( ai ) iI et ai , i I ? Dans un ensemble , les termes ne apparaissent qu' une seule fois , alors que dans une famille , il est possible de les répéter

**3824**: Partie génératrice Soit A E , on dit que A est une partie génératrice de E si Vect(A ) E Famille génératrice ***Soit*** ( ai ) iI E I une famille de vecteurs de E , on dit que c' est une famille génératrice de E si Quelle différence y a -t -il entre la famille ( ai ) iI et ai , i I ? Dans un ensemble , les termes ne apparaissent qu' une seule fois , alors que dans une famille , il est possible de les répéter

**4116**: 1.2.2 Déterminer une partie génératrice simple du plan de K3 d' équation 1.2.3 Déterminer une famille génératrice simple du plan vectoriel de K4 , d' équations : 1.2.4 ***Soit*** a R , démontrer que la famille ( x 7 ( x a)n ) nN est une famille génératrice du R - espace vectoriel des fonctions polynomiales

**4146**: 1.2.6 ***Soit*** F un sous-espace vectoriel d' un K - espace vectoriel E , que dire de 1.2.7 Soit E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E tels que : Que peut -on en conclure ? 1.2.8 Soit E un K - espace vectoriel , A et B deux parties de E , comparer : Vect(A B ) et Vect(A ) Vect(B ) Vect(A B ) et Vect(A ) Vect(B ) 1.2.9 Soit E un K - espace vectoriel tel que E 6 0E et soit ( Ei ) i1,n des sous-espaces vectoriels de E , tous distincts de E. Démontrer que : À quelle condition est -il un sous-espace vectoriel de E ? 1.2.10 Reprendre l' exercice précédent lorsque l' on considère une famille dénombrable de sous-espaces vectoriels ( En ) nN

**4163**: 1.2.6 Soit F un sous-espace vectoriel d' un K - espace vectoriel E , que dire de 1.2.7 ***Soit*** E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E tels que : Que peut -on en conclure ? 1.2.8 Soit E un K - espace vectoriel , A et B deux parties de E , comparer : Vect(A B ) et Vect(A ) Vect(B ) Vect(A B ) et Vect(A ) Vect(B ) 1.2.9 Soit E un K - espace vectoriel tel que E 6 0E et soit ( Ei ) i1,n des sous-espaces vectoriels de E , tous distincts de E. Démontrer que : À quelle condition est -il un sous-espace vectoriel de E ? 1.2.10 Reprendre l' exercice précédent lorsque l' on considère une famille dénombrable de sous-espaces vectoriels ( En ) nN

**4171**: 1.2.6 Soit F un sous-espace vectoriel d' un K - espace vectoriel E , que dire de 1.2.7 Soit E un K - espace vectoriel , ***soit*** E1 , E2 et E3 trois sous-espaces vectoriels de E tels que : Que peut -on en conclure ? 1.2.8 Soit E un K - espace vectoriel , A et B deux parties de E , comparer : Vect(A B ) et Vect(A ) Vect(B ) Vect(A B ) et Vect(A ) Vect(B ) 1.2.9 Soit E un K - espace vectoriel tel que E 6 0E et soit ( Ei ) i1,n des sous-espaces vectoriels de E , tous distincts de E. Démontrer que : À quelle condition est -il un sous-espace vectoriel de E ? 1.2.10 Reprendre l' exercice précédent lorsque l' on considère une famille dénombrable de sous-espaces vectoriels ( En ) nN

**4192**: 1.2.6 Soit F un sous-espace vectoriel d' un K - espace vectoriel E , que dire de 1.2.7 Soit E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E tels que : Que peut -on en conclure ? 1.2.8 ***Soit*** E un K - espace vectoriel , A et B deux parties de E , comparer : Vect(A B ) et Vect(A ) Vect(B ) Vect(A B ) et Vect(A ) Vect(B ) 1.2.9 Soit E un K - espace vectoriel tel que E 6 0E et soit ( Ei ) i1,n des sous-espaces vectoriels de E , tous distincts de E. Démontrer que : À quelle condition est -il un sous-espace vectoriel de E ? 1.2.10 Reprendre l' exercice précédent lorsque l' on considère une famille dénombrable de sous-espaces vectoriels ( En ) nN

**4227**: 1.2.6 Soit F un sous-espace vectoriel d' un K - espace vectoriel E , que dire de 1.2.7 Soit E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E tels que : Que peut -on en conclure ? 1.2.8 Soit E un K - espace vectoriel , A et B deux parties de E , comparer : Vect(A B ) et Vect(A ) Vect(B ) Vect(A B ) et Vect(A ) Vect(B ) 1.2.9 ***Soit*** E un K - espace vectoriel tel que E 6 0E et soit ( Ei ) i1,n des sous-espaces vectoriels de E , tous distincts de E. Démontrer que : À quelle condition est -il un sous-espace vectoriel de E ? 1.2.10 Reprendre l' exercice précédent lorsque l' on considère une famille dénombrable de sous-espaces vectoriels ( En ) nN

**4240**: 1.2.6 Soit F un sous-espace vectoriel d' un K - espace vectoriel E , que dire de 1.2.7 Soit E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E tels que : Que peut -on en conclure ? 1.2.8 Soit E un K - espace vectoriel , A et B deux parties de E , comparer : Vect(A B ) et Vect(A ) Vect(B ) Vect(A B ) et Vect(A ) Vect(B ) 1.2.9 Soit E un K - espace vectoriel tel que E 6 0E et ***soit*** ( Ei ) i1,n des sous-espaces vectoriels de E , tous distincts de E. Démontrer que : À quelle condition est -il un sous-espace vectoriel de E ? 1.2.10 Reprendre l' exercice précédent lorsque l' on considère une famille dénombrable de sous-espaces vectoriels ( En ) nN

**4345**: 1.2.11 Donner un exemple d' une famille de sous-espaces ( Ei ) iI de Rp , distincts de Rp , tels que Sommes de sous-espaces vectoriels ***Soit*** E un K - espace vectoriel

**4355**: Somme finie ***Soit*** E1 et E2 deux sous-espaces vectoriels de E , on appelle somme de E1 et E2 et on note E1 E2 le sous-espace vectoriel : Somme quelconque Plus généralement , si ( Ei ) iI est une famille de sous-espaces vectoriels de E , on appelle somme des Ei et Ei le sous-espace vectoriel : Il est faux de penser : 1

**4485**: Si P1 est le plan d' équation x y z 0 et P2 est le plan d' équation x 2 y z 0 de R3 , alors ***Soit*** E un K - espace vectoriel

**4581**: En reprenant les notations de la définition 1.7 , page ci - contre , on a où xik iI Ei Eik pour tout k 1 , n. Le vecteur x s' écrit donc comme une combinaison linéaire d' éléments de iI Ei , donc x Vect ( ) ***Soit*** x Vect iI Ei

**4646**: 1.3.1 ***Soit*** E un K - espace vectoriel

**4654**: ***Soit*** E1 , E2 et E3 trois sous-espaces vectoriels de E. ( a ) Comparer pour l' inclusion les sous-espaces : ( b ) Comparer pour l' inclusion les sous-espaces : ( c ) Comparer pour l' inclusion les sous-espaces : 1.3.2 Soit E un K - espace vectoriel

**4696**: Soit E1 , E2 et E3 trois sous-espaces vectoriels de E. ( a ) Comparer pour l' inclusion les sous-espaces : ( b ) Comparer pour l' inclusion les sous-espaces : ( c ) Comparer pour l' inclusion les sous-espaces : 1.3.2 ***Soit*** E un K - espace vectoriel

**4704**: ***Soit*** E1 , E2 et E3 trois sous-espaces vectoriels de E. Démontrer que : Démontrer que ce ne est plus vrai , si l' on enlève une des hypothèses à gauche

**4729**: Soit E1 , E2 et E3 trois sous-espaces vectoriels de E. Démontrer que : Démontrer que ce ne est plus vrai , si l' on ***enlève*** une des hypothèses à gauche

**4738**: Sommes directes ***Soit*** E un K - espace vectoriel

**4746**: ***Soit*** E1 et E2 deux sous-espaces vectoriels de E , on dit que E1 et E2 sont en somme directe si tout élément de E1 E2 s' écrit , de manière unique sous la forme x1 x2 , où x1 E1 et x2 E2

**4803**: On écrit alors : E1 E2 à la place de E1 E2 ***Soit*** E un K - espace vectoriel

**4835**: Deux sous-espaces vectoriels E1 et E2 de E sont en somme directe si , et seulement si , Démonstration Supposons que E1 et E2 ***soient*** en somme directe

**4840**: ***Soit*** x E1 E2

**4892**: ***Soit*** x E , qu' on écrit sous la forme donc x1 y1 et x2 y2

**4921**: ***Soit*** E un K - espace vectoriel

**4968**: Deux sous-espaces vectoriels E1 et E2 de E sont en somme directe si , et seulement si , il y a écriture unique de 0E , c' est - à - dire : Démonstration Supposons que E1 et E2 ***soient*** en somme directe

**4973**: ***Soit*** ( x1 , x2 ) E1 E2 tels que x1 x2 0E

**4999**: ***Soit*** x E qu' on écrit sous la forme donc x1 y1 x2 y2 0E d' où x1 y1 et x2 y2

**5032**: On en déduit que E1 et E2 sont en somme ***Soit*** E un K - espace vectoriel , soit ( Ei ) iI une famille de sous-espaces vectoriels de E , on dit qu' ils sont en somme directe , si on a écriture unique de 0E , soit : distincts 2 à 2 On écrit alors Ei à la place de Ne pas oublier que l' on ne sait faire que des sommes finies de vecteurs ! ! Si I contient strictement plus de deux éléments , la condition iI Ei 0E ne suffit pas pour assurer que les Ei sont en somme directe , de même que les conditions Ei Ej 0E pour tout Pour s' en convaincre , on peut considérer les sous-espaces vectoriels E1 R.(1 , 0 ) , E2 R.(0 , 1 ) et 1

**5040**: On en déduit que E1 et E2 sont en somme Soit E un K - espace vectoriel , ***soit*** ( Ei ) iI une famille de sous-espaces vectoriels de E , on dit qu' ils sont en somme directe , si on a écriture unique de 0E , soit : distincts 2 à 2 On écrit alors Ei à la place de Ne pas oublier que l' on ne sait faire que des sommes finies de vecteurs ! ! Si I contient strictement plus de deux éléments , la condition iI Ei 0E ne suffit pas pour assurer que les Ei sont en somme directe , de même que les conditions Ei Ej 0E pour tout Pour s' en convaincre , on peut considérer les sous-espaces vectoriels E1 R.(1 , 0 ) , E2 R.(0 , 1 ) et 1

**5070**: On en déduit que E1 et E2 sont en somme Soit E un K - espace vectoriel , soit ( Ei ) iI une famille de sous-espaces vectoriels de E , on dit qu' ils sont en somme directe , si on a écriture unique de 0E , ***soit*** : distincts 2 à 2 On écrit alors Ei à la place de Ne pas oublier que l' on ne sait faire que des sommes finies de vecteurs ! ! Si I contient strictement plus de deux éléments , la condition iI Ei 0E ne suffit pas pour assurer que les Ei sont en somme directe , de même que les conditions Ei Ej 0E pour tout Pour s' en convaincre , on peut considérer les sous-espaces vectoriels E1 R.(1 , 0 ) , E2 R.(0 , 1 ) et 1

**5229**: 1.4.1 ***Soit*** E C 0 ( R , R ) , démontrer que le sous-espace vectoriel des fonctions paires et celui des fonctions impaires sont en somme directe

**5263**: Quelle est leur somme ? 1.4.2 ***Soit*** E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E. On suppose que ( a ) Démontrer que si E2 E3 , alors ( b ) Démontrer que le résultat devient faux lorsque E2 6 E3 et E1 6 E3

**5271**: Quelle est leur somme ? 1.4.2 Soit E un K - espace vectoriel , ***soit*** E1 , E2 et E3 trois sous-espaces vectoriels de E. On suppose que ( a ) Démontrer que si E2 E3 , alors ( b ) Démontrer que le résultat devient faux lorsque E2 6 E3 et E1 6 E3

**5314**: 1.4.3 ***Soit*** E un K - espace vectoriel , ( Ei ) iI et ( Ei0 ) iI deux familles de sous-espaces vectoriels de E , telles Démontrer que : 1.4.4 Soit E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E. Démontrer que : Supplémentaires Soit E un K - espace vectoriel

**5344**: 1.4.3 Soit E un K - espace vectoriel , ( Ei ) iI et ( Ei0 ) iI deux familles de sous-espaces vectoriels de E , telles Démontrer que : 1.4.4 ***Soit*** E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E. Démontrer que : Supplémentaires Soit E un K - espace vectoriel

**5352**: 1.4.3 Soit E un K - espace vectoriel , ( Ei ) iI et ( Ei0 ) iI deux familles de sous-espaces vectoriels de E , telles Démontrer que : 1.4.4 Soit E un K - espace vectoriel , ***soit*** E1 , E2 et E3 trois sous-espaces vectoriels de E. Démontrer que : Supplémentaires Soit E un K - espace vectoriel

**5367**: 1.4.3 Soit E un K - espace vectoriel , ( Ei ) iI et ( Ei0 ) iI deux familles de sous-espaces vectoriels de E , telles Démontrer que : 1.4.4 Soit E un K - espace vectoriel , soit E1 , E2 et E3 trois sous-espaces vectoriels de E. Démontrer que : Supplémentaires ***Soit*** E un K - espace vectoriel

**5376**: Supplémentaire ***Soit*** E1 et E2 des sous-espace vectoriels de E , on dit que E2 est un supplémentaire de E1 si : On dit aussi que les deux espaces E1 et E2 sont supplémentaires

**5548**: Dans E Cpm ( 0 , 1 , R ) , la droite engendrée par la fonction x 7 1 est supplémentaire de ***Soit*** E un K - espace vectoriel

**5688**: 1.5.2 Dans R3 , trouver un supplémentaire de la droite d' équations : 1.5.3 Dans E C 0 ( R , R ) , trouver des supplémentaires de : Vect(x 7 x ) 1.5.4 ***Soit*** E C ( R , R ) , soit n N , trouver un supplémentaire de 1.5.5 On considère ici R comme un Q - espace vectoriel ( on a ici K Q )

**5697**: 1.5.2 Dans R3 , trouver un supplémentaire de la droite d' équations : 1.5.3 Dans E C 0 ( R , R ) , trouver des supplémentaires de : Vect(x 7 x ) 1.5.4 Soit E C ( R , R ) , ***soit*** n N , trouver un supplémentaire de 1.5.5 On considère ici R comme un Q - espace vectoriel ( on a ici K Q )

**5762**: En prenant en considération un supplémentaire de Vect(1 , 2 ) dans R qu' il existe une fonction f : R R qui est 1-périodique et une fonction g : R R qui est 2-périodique telles que : ***Soit*** E un K - espace vectoriel

**5775**: Famille libre ( finie ) ***Soit*** ( x1 ,

**5895**: Proposition 1.2 ***Soit*** E un K - espace vectoriel et soit ( xi ) iI une famille de vecteurs de E. Il est équivalent de dire : 1

**5903**: Proposition 1.2 Soit E un K - espace vectoriel et ***soit*** ( xi ) iI une famille de vecteurs de E. Il est équivalent de dire : 1

**5941**: il existe une écriture de 0E non triviale , ***soit*** a : distincts 2 à 2 ik .xik 0E 3

**5999**: Notons la différence avec tous non nuls qui signifient que tous les coefficients sont non nuls , alors que non tous nuls ***signifie*** qu' il en existe au moins un non nul ! Démonstration 1

**6003**: Notons la différence avec tous non nuls qui signifient que tous les coefficients sont non nuls , alors que non tous nuls signifie qu' il en ***existe*** au moins un non nul ! Démonstration 1

**6226**: On en déduit que x ei , i I est une partie libre de E. ***Soit*** X ( xi ) iI une famille de vecteurs d' un K - espace vectoriel E. Alors : 1

**6423**: ***Soit*** E un K - espace vectoriel , une famille ( xi ) iI est appelée base de E , si elle est à la fois famille libre et famille génératrice

**6455**: ***Soit*** E un K - espace vectoriel

**6862**: 1.6.5 ***Soit*** E F ( R , R ) et F le sous-espace vectoriel de E engendré par les fonctions : Déterminer une base de F

**6907**: Démontrer que : ( f ) R est une famille libre de F ( R , R ) 1.6.7 ***Soit*** A un ensemble , f une application de A dans R , telle que f ( A ) est infini

**6948**: 1.6.8 ***Soit*** n N , et x1 xn des réels

**6964**: ***Soit*** E l' ensemble des fonctions f : R R , de classe C 1 , telles que la restriction de f à chaque intervalle xi , xi1 , ( i 0 , n ) est une fonction polynomiale de degré 2

**7049**: Dimension finie ***Soit*** E un K - espace vectoriel

**7149**: Théorème 1.1 Échange ***Soit*** E un K - espace vectoriel , soit ( g1 ,

**7157**: Théorème 1.1 Échange Soit E un K - espace vectoriel , ***soit*** ( g1 ,

**7213**: On peut échanger certains vecteurs de la famille génératrice avec des vecteurs de la famille libre tout en gardant la propriété d' être génératrice , ***soit*** : Démonstration Puisque ( g1 ,

**7443**: Théorème 1.2 ***Soit*** E un K - espace vectoriel de dimension finie , alors toutes les bases ont même cardinal

**7681**: Quelques espaces de dimensions infinies : le R - espace vectoriel des fonctions polynomiales , mais aussi : Théorème 1.3 Base incomplète ***Soit*** E un K - espace vectoriel de dimension finie n , soit ( 1 ,

**7693**: Quelques espaces de dimensions infinies : le R - espace vectoriel des fonctions polynomiales , mais aussi : Théorème 1.3 Base incomplète Soit E un K - espace vectoriel de dimension finie n , ***soit*** ( 1 ,

**7722**: On peut compléter la famille libre en une base , ***soit*** : Démonstration C' est une application immédiate du théorème de l' échange , en prenant comme famille génératrice une base de E ( qui a n éléments )

**7994**: ***Soit*** E un K - espace vectoriel de dimension finie

**8132**: ***Soit*** G une partie génératrice à n éléments

**8195**: ***Soit*** L une partie libre à n éléments

**8245**: ***Soit*** E un K - espace vectoriel de dimension finie

**8288**: ***Soit*** G une partie génératrice de E ( éventuellement infinie )

**8386**: Le théorème de la base incomplète permet alors de construire une base de E en complétant la famille ( x ) par des éléments de G. ***Soit*** E un K - espace vectoriel

**8446**: ***Soit*** E un K - espace vectoriel

**8506**: Alors E est de dimension infinie si , et seulement si , il existe des parties libres de cardinal quelconque n N. Démonstration Cela revient à démontrer que E est de dimension finie si , et seulement si , il existe n N tel que toute famille de E à n éléments ***soit*** liée

**8517**: ***Soit*** E un K - espace vectoriel

**8615**: ***Soit*** L une famille libre d' éléments de F de cardinal p. Pour tout x F , la famille ( L , x ) est liée ( car sinon cela contredit la définition de p ) , donc x est combinaison linéaire d' éléments de L , donc L est une famille génératrice de F , c' est donc une base de F

**8807**: Attention à une erreur courante : si B est une base de E et si F est un sous-espace vectoriel de E , il est faux en général qu' une sous-famille de B ***soit*** une base de F

**8833**: Par exemple , une base de F R.(1 , 1 ) ne est jamais une sous-famille de la base canonique ***Soit*** E un K - espace vectoriel de dimension finie

**9184**: Dans le cas général , on procède par récurrence sur p. Proposition 1.3 Formule de Grassman Si E est un K - espace vectoriel de dimension finie , si F et G sont deux sous-espaces vectoriels de E , alors : Démonstration ***Soit*** F1 un supplémentaire de F G dans F et soit G1 un supplémentaire de F G dans G : On a alors Pour conclure , il suffit de prendre une base adaptée à cette décomposition en somme directe

**9194**: Dans le cas général , on procède par récurrence sur p. Proposition 1.3 Formule de Grassman Si E est un K - espace vectoriel de dimension finie , si F et G sont deux sous-espaces vectoriels de E , alors : Démonstration Soit F1 un supplémentaire de F G dans F et ***soit*** G1 un supplémentaire de F G dans G : On a alors Pour conclure , il suffit de prendre une base adaptée à cette décomposition en somme directe

**9224**: ***Soit*** E un K - espace vectoriel de dimension finie

**9401**: Quelle est la dimension de F Ga ? Quelle est la dimension de F Ga ? 1.7.3 ***Soit*** E un K - espace vectoriel de dimension finie , on suppose qu' on a la somme directe E F1 F2

**9424**: ***Soit*** G un sous-espace vectoriel de E tel que : Démontrer que F2 G. 1.7.4 Soit E un K - espace vectoriel de dimension finie , soit F et G deux sous-espaces vectoriels de E tels que F G 0E

**9439**: Soit G un sous-espace vectoriel de E tel que : Démontrer que F2 G. 1.7.4 ***Soit*** E un K - espace vectoriel de dimension finie , soit F et G deux sous-espaces vectoriels de E tels que F G 0E

**9450**: Soit G un sous-espace vectoriel de E tel que : Démontrer que F2 G. 1.7.4 Soit E un K - espace vectoriel de dimension finie , ***soit*** F et G deux sous-espaces vectoriels de E tels que F G 0E

**9476**: Démontrer qu' il existe un supplémentaire de F contenant G. 1.7.5 ***Soit*** E un K - espace vectoriel de dimension finie et F un sous-espace vectoriel strict de E ( F 6 E )

**9510**: 1.7.6 ***Soit*** V un K - espace vectoriel de dimension n , k N et V1 , V2 ,

**9543**: , Vk des sous-espaces vectoriels de V tels que Démontrer que 1.7.7 ***Soit*** E un K - espace vectoriel de dimension finie n , soit F1 et F2 deux sous-espaces vectoriels de dimension p n. ( a ) Démontrer que l' on peut alors trouver un supplémentaire commun à F1 et F2

**9555**: , Vk des sous-espaces vectoriels de V tels que Démontrer que 1.7.7 Soit E un K - espace vectoriel de dimension finie n , ***soit*** F1 et F2 deux sous-espaces vectoriels de dimension p n. ( a ) Démontrer que l' on peut alors trouver un supplémentaire commun à F1 et F2

**9631**: Applications linéaires Généralités ***Soit*** E et E 0 deux K - espaces vectoriels , une application f : E E 0 est dite application linéaire si elle est compatible avec les structures d' espaces vectoriels , c' est - à - dire a : L' ensemble des applications linéaires de E dans E 0 se note : LK ( E , E 0 ) ou L ( E , E 0 ) lorsqu' il ne y a pas ambiguïté sur le corps K 1

**10098**: ***Soit*** E et E 0 deux K - espaces vectoriels et soit f L ( E , E 0 )

**10109**: Soit E et E 0 deux K - espaces vectoriels et ***soit*** f L ( E , E 0 )

**10433**: Si f est un automorphisme de E , alors f 1 est aussi un automorphisme de E ( en particulier c' est un endomorphisme de E ) et on définit de même : 1.8.1 ***Soit*** f un endomorphisme de E , calculer 1.8.2 Soit f L ( E ) tel qu' il existe n N tel que f n 0L ( E ) ( on dit que f est nilpotent )

**10442**: Si f est un automorphisme de E , alors f 1 est aussi un automorphisme de E ( en particulier c' est un endomorphisme de E ) et on définit de même : 1.8.1 Soit f un endomorphisme de E , calculer 1.8.2 ***Soit*** f L ( E ) tel qu' il existe n N tel que f n 0L ( E ) ( on dit que f est nilpotent )

**10481**: Images et noyaux ***Soit*** E et E 0 deux K - espaces vectoriels , et f L ( E , E 0 ) , alors : L' image de E par f est un sous-espace vectoriel de E 0 noté : L' image réciproque de 0E 0 par f est un sous-espace vectoriel de E appelé noyau de f et noté 1

**10565**: Pour tout endomorphisme p d' un K - espace vectoriel E En effet , un raisonnement par analyse - synthèse démontre que x se ***décompose*** de manière unique sous 2

**10668**: On peut utiliser les images et noyaux pour démontrer que des ensembles sont des sous-espaces vectoriels : ( a ) ( Image peu fréquent ) : est un sous-espace vectoriel de C 0 ( a , b , R ) en considérant l' endomorphisme de C 0 ( a , b , R ) : ( b ) ( Noyau très fréquent ) : est un sous-espace vectoriel de C 1 ( a , b , R ) en considérant la forme linéaire de C 1 ( a , b , R ) : Proposition 1.4 ***Soit*** E et E 0 deux K - espaces vectoriels , f L ( E , E 0 ) , alors : f est injective si , et seulement si , Ker(f ) 0E f est surjective si , et seulement si , Im(f ) E 0 Démonstration La caractérisation de la surjectivité est immédiate

**10839**: Plus généralement , pour tout ( xi ) iI E 0 , il existe une unique application linéaire f L ( E , E 0 ) ***Soit*** E un K - espace vectoriel

**10950**: , ip ) une sous-famille finie quelconque de I. ***Soit*** ( 1 ,

**11031**: ***Soit*** y E 0

**11245**: ***Soit*** E , E 0 et E 00 des K - espaces vectoriels

**11263**: On a : Démonstration ***Soit*** f et g deux endomorphismes d' un K - espace vectoriel E. Si f g g f , alors : Démonstration Si f est un endomorphisme d' un K - espace vectoriel E , alors : Démonstration On utilise les deux premiers points de la propriété 1.26 , de la présente page avec f n à la place de f et f à la place de g. Soit E un K - espace vectoriel et f L ( E ) , soit F un sous-espace vectoriel de E , on dit que F est f -stable ou stable par f si : f ( F ) F , c' est - à - dire que , pour tout x F , f ( x ) F 1

**11331**: On a : Démonstration Soit f et g deux endomorphismes d' un K - espace vectoriel E. Si f g g f , alors : Démonstration Si f est un endomorphisme d' un K - espace vectoriel E , alors : Démonstration On utilise les deux premiers points de la propriété 1.26 , de la présente page avec f n à la place de f et f à la place de g. ***Soit*** E un K - espace vectoriel et f L ( E ) , soit F un sous-espace vectoriel de E , on dit que F est f -stable ou stable par f si : f ( F ) F , c' est - à - dire que , pour tout x F , f ( x ) F 1

**11345**: On a : Démonstration Soit f et g deux endomorphismes d' un K - espace vectoriel E. Si f g g f , alors : Démonstration Si f est un endomorphisme d' un K - espace vectoriel E , alors : Démonstration On utilise les deux premiers points de la propriété 1.26 , de la présente page avec f n à la place de f et f à la place de g. Soit E un K - espace vectoriel et f L ( E ) , ***soit*** F un sous-espace vectoriel de E , on dit que F est f -stable ou stable par f si : f ( F ) F , c' est - à - dire que , pour tout x F , f ( x ) F 1

**11438**: Si f est un automorphisme et F de dimension finie , alors F est stable par f F est stable par f 1 1.9.1 ***Soit*** f , g et h trois endomorphismes d' un K - espace vectoriel E tels que : Démontrer que ces trois endomorphismes ont même image et même noyau

**11469**: 1.9.2 ***Soit*** f un endomorphisme d' un K - espace vectoriel E , démontrer que : 1.9.3 Soit f et g deux endomorphismes d' un K - espace vectoriel E , démontrer que : Projecteurs et symétries Soit E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. On appelle projection de E sur F parallèlement à G l' endomorphisme de E défini par : x 7 xF où x xF xG avec xF F et xG G Puisque E F G , xF et xG sont uniques donc pF kG est bien définie

**11485**: 1.9.2 Soit f un endomorphisme d' un K - espace vectoriel E , démontrer que : 1.9.3 ***Soit*** f et g deux endomorphismes d' un K - espace vectoriel E , démontrer que : Projecteurs et symétries Soit E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. On appelle projection de E sur F parallèlement à G l' endomorphisme de E défini par : x 7 xF où x xF xG avec xF F et xG G Puisque E F G , xF et xG sont uniques donc pF kG est bien définie

**11505**: 1.9.2 Soit f un endomorphisme d' un K - espace vectoriel E , démontrer que : 1.9.3 Soit f et g deux endomorphismes d' un K - espace vectoriel E , démontrer que : Projecteurs et symétries ***Soit*** E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. On appelle projection de E sur F parallèlement à G l' endomorphisme de E défini par : x 7 xF où x xF xG avec xF F et xG G Puisque E F G , xF et xG sont uniques donc pF kG est bien définie

**11580**: De plus , c' est un endomorphisme ***Soit*** E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. Alors : pF kG pGkF idE On a de plus : G Ker(pF kG ) et , pour tout x G , pF kG ( x ) 0E F Im(pF kG ) Ker(pF kG idE ) et , pour tout x F , pF kG ( x ) x Démonstration Soit x E qu' on écrit de manière unique x xF xG avec xF pF kG ( x ) F et xG pGkF ( x ) G. donc pF kG pGkF idE

**11651**: De plus , c' est un endomorphisme Soit E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. Alors : pF kG pGkF idE On a de plus : G Ker(pF kG ) et , pour tout x G , pF kG ( x ) 0E F Im(pF kG ) Ker(pF kG idE ) et , pour tout x F , pF kG ( x ) x Démonstration ***Soit*** x E qu' on écrit de manière unique x xF xG avec xF pF kG ( x ) F et xG pGkF ( x ) G. donc pF kG pGkF idE

**11733**: ***Soit*** E un espace vectoriel , on appelle projecteur de E tout endomorphisme p de E tel que p p p. Proposition 1.5 Soit E un K - espace vectoriel

**11756**: Soit E un espace vectoriel , on appelle projecteur de E tout endomorphisme p de E tel que p p p. Proposition 1.5 ***Soit*** E un K - espace vectoriel

**11896**: Si p est un projecteur , on a alors : E Im p Ker p d' après l' exemple 1.18 , page 49 , donc p est la projection de E sur son image Im p parallèlement à son noyau Ker p. ***Soit*** E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. On peut définir de même la notion de symétrie de E par rapport à F , parallèlement à G. C' est l' automorphisme de E défini x xF xG 7 xF xG , où x xF xG avec xF F et xG G Soit E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. On a alors : sF kG sF kG idE De plus , on a sF kG 2.pF kG idE et pF kG

**11960**: Si p est un projecteur , on a alors : E Im p Ker p d' après l' exemple 1.18 , page 49 , donc p est la projection de E sur son image Im p parallèlement à son noyau Ker p. Soit E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. On peut définir de même la notion de symétrie de E par rapport à F , parallèlement à G. C' est l' automorphisme de E défini x xF xG 7 xF xG , où x xF xG avec xF F et xG G ***Soit*** E un K - espace vectoriel , F et G deux sous-espaces vectoriels de E tels que E F G. On a alors : sF kG sF kG idE De plus , on a sF kG 2.pF kG idE et pF kG

**12203**: Réciproquement , si s est une symétrie de E , alors p 21 .(s idE ) est un projecteur de E. 1.10.1 ***Soit*** p est une projection d' un K - espace vectoriel E , et soit K 0 , 1

**12217**: Réciproquement , si s est une symétrie de E , alors p 21 .(s idE ) est un projecteur de E. 1.10.1 Soit p est une projection d' un K - espace vectoriel E , et ***soit*** K 0 , 1

**12247**: 1.10.3 ***Soit*** l' application : Démontrer que est une symétrie ( par rapport à quoi ? parallèlement à quoi ? )

**12269**: 1.10.4 ***Soit*** p et q deux projecteurs d' un K - espace vectoriel E. Démontrer l' équivalence des trois propriétés suivantes : ( a ) p q est un projecteur

**12384**: 1.10.7 ***Soit*** f un endomorphisme d' un K - espace vectoriel E et p un projecteur de E , démontrer que : Cas particulier de la dimension finie Soit E et E 0 deux K - espaces vectoriels

**12411**: 1.10.7 Soit f un endomorphisme d' un K - espace vectoriel E et p un projecteur de E , démontrer que : Cas particulier de la dimension finie ***Soit*** E et E 0 deux K - espaces vectoriels

**12580**: ***Soit*** E et E 0 deux K - espaces vectoriels , f L ( E , E 0 ) telle que Im(f ) soit de dimension finie , on appelle rang de f et on note : rang(f ) dim(Im(f ) ) Lorsque E est de dimension finie , Im(f ) est de dimension finie

**12603**: Soit E et E 0 deux K - espaces vectoriels , f L ( E , E 0 ) telle que Im(f ) ***soit*** de dimension finie , on appelle rang de f et on note : rang(f ) dim(Im(f ) ) Lorsque E est de dimension finie , Im(f ) est de dimension finie

**12636**: ***Soit*** E et E 0 deux K - espaces vectoriels et f L ( E , E 0 ) , alors : E 0 de dimension finie rang(f ) dim E 0 et rang(f ) dim E 0 f surjective E de dimension finie rang(f ) dim E et rang(f ) dim E f injective Démonstration Im f est un sous-espace vectoriel de E 0 qui est de dimension finie donc Im f est de dimension finie et rang f dim Im f dim E 0

**12791**: ***Soit*** E et E 0 deux K - espaces vectoriels

**12912**: Démonstration Si n p , on peut définir l' application linéaire f L ( E , E 0 ) telle que f ( ei ) e0i pour tout i 1 , n. elle est donc libre , ce qui ***démontre*** que f est injective ( voir la remarque 1.19 , page 51 )

**13166**: Réciproquement , si il existe f L ( E , E 0 ) bijective , alors d' après ce qui précède n p et p n , donc Ces propriétés sont très importantes pour démontrer des égalités ou des inégalités de dimensions ! Proposition 1.6 Rang d' une composition ***Soit*** E , E 0 et E 00 trois K - espaces vectoriels de dimensions finies , u L ( E , E 0 ) et v L ( E 0 , E 00 ) , alors : rang(v u ) dim E 0 rang(v ) rang(u ) Démonstration On peut déjà remarquer que : donc , en introduisant des supplémentaires : l' inégalité demandée devient : Or , il existe une application naturelle qui va de F 0 dans F 00 , l' application : L' énoncé devient : La démonstration ne est alors qu' une vérification : soit x00 F 00 , alors x00 Im(v ) , donc , il existe Théorème 1.4 Théorème du rang Soit E et E 0 des K - espace vectoriels et f L ( E , E 0 )

**13265**: Réciproquement , si il existe f L ( E , E 0 ) bijective , alors d' après ce qui précède n p et p n , donc Ces propriétés sont très importantes pour démontrer des égalités ou des inégalités de dimensions ! Proposition 1.6 Rang d' une composition Soit E , E 0 et E 00 trois K - espaces vectoriels de dimensions finies , u L ( E , E 0 ) et v L ( E 0 , E 00 ) , alors : rang(v u ) dim E 0 rang(v ) rang(u ) Démonstration On peut déjà remarquer que : donc , en introduisant des supplémentaires : l' inégalité demandée devient : Or , il existe une application naturelle qui va de F 0 dans F 00 , l' application : L' énoncé devient : La démonstration ne est alors qu' une vérification : ***soit*** x00 F 00 , alors x00 Im(v ) , donc , il existe Théorème 1.4 Théorème du rang Soit E et E 0 des K - espace vectoriels et f L ( E , E 0 )

**13284**: Réciproquement , si il existe f L ( E , E 0 ) bijective , alors d' après ce qui précède n p et p n , donc Ces propriétés sont très importantes pour démontrer des égalités ou des inégalités de dimensions ! Proposition 1.6 Rang d' une composition Soit E , E 0 et E 00 trois K - espaces vectoriels de dimensions finies , u L ( E , E 0 ) et v L ( E 0 , E 00 ) , alors : rang(v u ) dim E 0 rang(v ) rang(u ) Démonstration On peut déjà remarquer que : donc , en introduisant des supplémentaires : l' inégalité demandée devient : Or , il existe une application naturelle qui va de F 0 dans F 00 , l' application : L' énoncé devient : La démonstration ne est alors qu' une vérification : soit x00 F 00 , alors x00 Im(v ) , donc , il existe Théorème 1.4 Théorème du rang ***Soit*** E et E 0 des K - espace vectoriels et f L ( E , E 0 )

**13350**: ***Soit*** E un K - espace vectoriel de dimension finie , F un sous-espace vectoriel de E et f L ( E , E 0 ) , 2

**13379**: ***Soit*** E un K - espace vectoriel de dimension finie et f L ( E ) , alors : ( a ) En posant f 0 idE , on a : ( b ) De plus , ( c ) On peut alors poser : Proposition 1.7 Caractérisation des automorphismes en dimension finie Soit E un K - espace vectoriel de dimension finie et f L ( E ) , alors : f injective f surjective f bijective C' est faux en dimension infinie

**13432**: Soit E un K - espace vectoriel de dimension finie et f L ( E ) , alors : ( a ) En posant f 0 idE , on a : ( b ) De plus , ( c ) On peut alors poser : Proposition 1.7 Caractérisation des automorphismes en dimension finie ***Soit*** E un K - espace vectoriel de dimension finie et f L ( E ) , alors : f injective f surjective f bijective C' est faux en dimension infinie

**13534**: En dimension infinie , on peut considérer , par exemple , la dérivation sur C ( R , R ) qui est surjective , mais pas injective ! Proposition 1.8 ***Soit*** E et E 0 deux K - espaces vectoriels de dimensions finies , alors L ( E E 0 ) est de dimension finie , égale à dim E dim E 0 Démonstration Si E 0E ou E 0 0E 0 , il ne y a rien à démontrer

**13597**: ***Soit*** ( e1 ,

**13763**: 1.11.1 ***Soit*** E , E 0 , F et F 0 des K - espaces vectoriels de dimensions finies et soit u L ( E , F )

**13782**: 1.11.1 Soit E , E 0 , F et F 0 des K - espaces vectoriels de dimensions finies et ***soit*** u L ( E , F )

**13833**: 1.11.3 ***Soit*** E un K - espace vectoriel de dimension n et f L ( E ) tel que : ( a ) Démontrer que : ( b ) Démontrer que , si f n1 6 0L ( E ) , alors 1.11.4 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer qu' il existe un automorphisme g GL ( E ) et p un projecteur de E tel que : 1.11.5 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , on considère les applications : ( a ) Démontrer que et sont dans L ( L ( E ) )

**13875**: 1.11.3 Soit E un K - espace vectoriel de dimension n et f L ( E ) tel que : ( a ) Démontrer que : ( b ) Démontrer que , si f n1 6 0L ( E ) , alors 1.11.4 ***Soit*** E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer qu' il existe un automorphisme g GL ( E ) et p un projecteur de E tel que : 1.11.5 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , on considère les applications : ( a ) Démontrer que et sont dans L ( L ( E ) )

**13913**: 1.11.3 Soit E un K - espace vectoriel de dimension n et f L ( E ) tel que : ( a ) Démontrer que : ( b ) Démontrer que , si f n1 6 0L ( E ) , alors 1.11.4 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer qu' il existe un automorphisme g GL ( E ) et p un projecteur de E tel que : 1.11.5 ***Soit*** E un K - espace vectoriel de dimension finie et f L ( E ) , on considère les applications : ( a ) Démontrer que et sont dans L ( L ( E ) )

**13964**: 1.11.6 ***Soit*** E un K - espace vectoriel et u L ( E )

**13993**: ( b ) ***Soit*** v0 F , démontrer que v0 F v v0 , v F est un sous-espace vectoriel de L ( E ) On suppose dorénavant que E est de dimension finie n. ( c ) Calculer la dimension de v0 F. ( d ) Que peut -on dire du rang de v lorsque v F ? 1.11.7 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : rang f k rang f k2 1.11.8 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : 1.11.9 Soit E , E 0 , E 00 et E 000 quatre K - espaces vectoriels de dimensions finies , f L ( E , E 0 ) , g L ( E 0 , E 00 ) 1.11.10 Soit E un K - espace vectoriel de dimension finie , f L ( E ) GL ( E )

**14050**: ( b ) Soit v0 F , démontrer que v0 F v v0 , v F est un sous-espace vectoriel de L ( E ) On suppose dorénavant que E est de dimension finie n. ( c ) Calculer la dimension de v0 F. ( d ) Que peut -on dire du rang de v lorsque v F ? 1.11.7 ***Soit*** E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : rang f k rang f k2 1.11.8 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : 1.11.9 Soit E , E 0 , E 00 et E 000 quatre K - espaces vectoriels de dimensions finies , f L ( E , E 0 ) , g L ( E 0 , E 00 ) 1.11.10 Soit E un K - espace vectoriel de dimension finie , f L ( E ) GL ( E )

**14077**: ( b ) Soit v0 F , démontrer que v0 F v v0 , v F est un sous-espace vectoriel de L ( E ) On suppose dorénavant que E est de dimension finie n. ( c ) Calculer la dimension de v0 F. ( d ) Que peut -on dire du rang de v lorsque v F ? 1.11.7 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : rang f k rang f k2 1.11.8 ***Soit*** E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : 1.11.9 Soit E , E 0 , E 00 et E 000 quatre K - espaces vectoriels de dimensions finies , f L ( E , E 0 ) , g L ( E 0 , E 00 ) 1.11.10 Soit E un K - espace vectoriel de dimension finie , f L ( E ) GL ( E )

**14098**: ( b ) Soit v0 F , démontrer que v0 F v v0 , v F est un sous-espace vectoriel de L ( E ) On suppose dorénavant que E est de dimension finie n. ( c ) Calculer la dimension de v0 F. ( d ) Que peut -on dire du rang de v lorsque v F ? 1.11.7 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : rang f k rang f k2 1.11.8 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : 1.11.9 ***Soit*** E , E 0 , E 00 et E 000 quatre K - espaces vectoriels de dimensions finies , f L ( E , E 0 ) , g L ( E 0 , E 00 ) 1.11.10 Soit E un K - espace vectoriel de dimension finie , f L ( E ) GL ( E )

**14137**: ( b ) Soit v0 F , démontrer que v0 F v v0 , v F est un sous-espace vectoriel de L ( E ) On suppose dorénavant que E est de dimension finie n. ( c ) Calculer la dimension de v0 F. ( d ) Que peut -on dire du rang de v lorsque v F ? 1.11.7 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : rang f k rang f k2 1.11.8 Soit E un K - espace vectoriel de dimension finie et f L ( E ) , démontrer que : 1.11.9 Soit E , E 0 , E 00 et E 000 quatre K - espaces vectoriels de dimensions finies , f L ( E , E 0 ) , g L ( E 0 , E 00 ) 1.11.10 ***Soit*** E un K - espace vectoriel de dimension finie , f L ( E ) GL ( E )

**14338**: De plus , est une application linéaire Démonstration Notation 1.1 Par abus de notation , si F est un sous-espace vectoriel d' un K - espace vectoriel E , F 0 un sous-espace vectoriel d' un K - espace vectoriel E 0 et f L ( E , E 0 ) tels que , nous noterons : ***Soit*** E , E 0 et E 00 des K - espaces vectoriels

**14432**: Si F est un sous-espace vectoriel de E , si f L ( E , E 0 ) et g L ( E 0 , E 00 ) alors : De même , si F 00 est un sous-espace vectoriel de E 00 contenant g(E 0 ) , alors : Si F est un sous-espace vectoriel d' un K - espace vectoriel E et f une application linéaire de E dans E 0 , Ker fF F Ker(f ) Démonstration ***Soit*** x Ker fF

**14477**: Notation 1.2 Inclusion canonique ***Soit*** E un K - espace vectoriel , F un sous-espace vectoriel de E , on peut définir l' inclusion canonique de F dans E par : On a donc : iF E ( idE ) F Si G est un supplémentaire de F dans E ( E F G ) , on a : iF E idF Ce ne sont pas des réciproques ! Pour connaître une application linéaire définie sur un K - espace vectoriel dont on connaît une décomposition en somme directe , il faut et il suffit d' en connaître ses restrictions à chaque sous-espace vectoriel composant la décomposition

**14652**: , in ) de I et des vecteurs xik Eik , quelque ***soit*** k 1 , n tels que : On a alors : Une autre façon de dire est que : Ei L ( E , E 0 ) est isomorphe à grâce à l' application ( clairement linéaire ) : Soit E F G , alors il existe un endomorphisme f L ( E ) , tel que On construit a : a. Remarquons que l' on obtient bien sûr la projection sur G parallèlement à F

**14692**: , in ) de I et des vecteurs xik Eik , quelque soit k 1 , n tels que : On a alors : Une autre façon de dire est que : Ei L ( E , E 0 ) est isomorphe à grâce à l' application ( clairement linéaire ) : ***Soit*** E F G , alors il existe un endomorphisme f L ( E ) , tel que On construit a : a. Remarquons que l' on obtient bien sûr la projection sur G parallèlement à F

**14736**: Théorème 1.5 Factorisation des applications linéaires ***Soit*** E et E 0 deux K - espaces vectoriels , f L ( E , E 0 ) , F un supplémentaire de Ker(f ) dans E ( E Ker(f ) F ) , alors est un isomorphisme entre F et Im(f ) Démonstration Posons fe f F 1

**14803**: En effet , ***soit*** x0 Im(f ) , on sait alors qu' il existe x E , tel que f ( x ) x0

**14894**: Mais , par décomposition en somme directe , on a : En appliquant f , il vient : Dans le cas de la dimension finie ( dim E ) , on obtient que Im(f ) est de dimension finie et que dim Im(f ) dim F Or , la formule de Grasmann ( proposition 1.3 , page 44 ) nous donne que dim F dim E dim Ker(f ) ***soit*** , le théorème du rang ! ( théorème 1.4 , page 57 ) Pourquoi appelle -t -on ce résultat théorème de factorisation des applications linéaires ? Si on regarde le diagramme 1.3 , de la présente page

**15015**: On a donc obtenu une factorisation de f à l' aide d' applications linéaires simples et d' un isomorphisme : f iIm(f ) E0 fe pF kKer(f ) Figure 1.3 Factorisation d' une application linéaire À quoi cela sert -il ? À faire apparaître un isomorphisme , ce qui permet d' utiliser sa réciproque ! Ainsi , sur le schéma précédent , il apparaît une application linéaire naturelle permettant d' aller de E 0 dans E ( sans pour autant que f ***soit*** inversible ) , en introduisant un supplémentaire F 0 de Im(f ) dans E 0

**15047**: Notons cette application : regardons ce que ***deviennent*** g f et f g. Soit un élément x E , que l' on décompose suivant la somme directe F Ker(f ) , alors iF E fe1 pIm(f ) kF 0 fe(xF ) iF E fe1 fe(xF ) De même , si x0 E 0 que l' on décompose sous la forme x0 xF 0 f ( x ) xF 0 fe(xF ) , alors : Finalement , on obtient : Figure 1.4 Utilisation de la factorisation g dépend du choix de F 0 ( et bien sûr de F )

**15053**: Notons cette application : regardons ce que deviennent g f et f g. ***Soit*** un élément x E , que l' on décompose suivant la somme directe F Ker(f ) , alors iF E fe1 pIm(f ) kF 0 fe(xF ) iF E fe1 fe(xF ) De même , si x0 E 0 que l' on décompose sous la forme x0 xF 0 f ( x ) xF 0 fe(xF ) , alors : Finalement , on obtient : Figure 1.4 Utilisation de la factorisation g dépend du choix de F 0 ( et bien sûr de F )

**15062**: Notons cette application : regardons ce que deviennent g f et f g. Soit un élément x E , que l' on ***décompose*** suivant la somme directe F Ker(f ) , alors iF E fe1 pIm(f ) kF 0 fe(xF ) iF E fe1 fe(xF ) De même , si x0 E 0 que l' on décompose sous la forme x0 xF 0 f ( x ) xF 0 fe(xF ) , alors : Finalement , on obtient : Figure 1.4 Utilisation de la factorisation g dépend du choix de F 0 ( et bien sûr de F )

**15096**: Notons cette application : regardons ce que deviennent g f et f g. Soit un élément x E , que l' on décompose suivant la somme directe F Ker(f ) , alors iF E fe1 pIm(f ) kF 0 fe(xF ) iF E fe1 fe(xF ) De même , si x0 E 0 que l' on ***décompose*** sous la forme x0 xF 0 f ( x ) xF 0 fe(xF ) , alors : Finalement , on obtient : Figure 1.4 Utilisation de la factorisation g dépend du choix de F 0 ( et bien sûr de F )

**15494**: ) Si v est inversible , alors u v 1 w. Dans le cas contraire , nous allons essayer de nous y ramener : ( Analyse ) Si u existe , alors b w v u donc w Pour pouvoir restreindre v à F 0 ( supplémentaire de Ker(v ) ) , nous allons imposer une condition supplémentaire à u permettant la co-restriction à F 0 de u : e inversible ! donc , dans ce cas , on a la condition nécessaire : ( Synthèse ) ***Soit*** u L ( E , E 0 ) défini par : ou , si l' on préfère : Alors , si x E , on a Le candidat ne est parfois pas celui dont on a besoin ! La vérification est indispensable ! b. La co-restriction est possible d' après l' hypothèse

**15568**: Figure 1.5 Relèvement linéaire : position du problème Figure 1.6 Relèvement linéaire : construction des chemins Théorème 1.7 Extension linéaire ***Soit*** E , E 0 et E 00 trois K - espaces vectoriels , w L ( E , E 00 ) et u L ( E , E 0 ) , alors Démonstration Laissé en exercice

**15620**: Proposition 1.9 Surjectivité ***Soit*** E et E 0 deux K - espaces vectoriels , v L ( E 0 , E ) , alors : u L ( E , E 0 ) , idE v u v surjective Démonstration Prendre w idE dans le théorème de relèvement

**15669**: Proposition 1.10 Injectivité ***Soit*** E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) , alors : Démonstration Prendre w idE dans le théorème d' extension

**15710**: 1.12.2 ***Soit*** E0 , E1 et E2 trois sous-espaces vectoriels d' un K - espace vectoriel E tels que : démontrer que E1 et E2 sont isomorphes

**15738**: 1.12.3 ***Soit*** E1 , E2 , E3 et E4 quatre sous-espaces vectoriels d' un K - espace vectoriel E tels que : démontrer que E3 et E4 sont isomorphes

**15768**: 1.12.4 ***Soit*** E un K - espace vectoriel et soit ( u , v , w ) L ( E)3

**15776**: 1.12.4 Soit E un K - espace vectoriel et ***soit*** ( u , v , w ) L ( E)3

**15812**: ( a ) Démontrer que ( b ) Donner une CNS pour que : ( c ) Donner une CNS pour que : 1.12.5 ***Soit*** E un K - espace vectoriel et soit f L ( E ) , démontrer que Étude du dual Soit E un K - espace vectoriel , on appelle dual de E et on note : Les éléments de E ? s' appellent des formes linéaires a

**15820**: ( a ) Démontrer que ( b ) Donner une CNS pour que : ( c ) Donner une CNS pour que : 1.12.5 Soit E un K - espace vectoriel et ***soit*** f L ( E ) , démontrer que Étude du dual Soit E un K - espace vectoriel , on appelle dual de E et on note : Les éléments de E ? s' appellent des formes linéaires a

**15832**: ( a ) Démontrer que ( b ) Donner une CNS pour que : ( c ) Donner une CNS pour que : 1.12.5 Soit E un K - espace vectoriel et soit f L ( E ) , démontrer que Étude du dual ***Soit*** E un K - espace vectoriel , on appelle dual de E et on note : Les éléments de E ? s' appellent des formes linéaires a

**15890**: On aura des formes linéaires , des formes bilinéaires , etc. ***Soit*** E un K - espace vectoriel

**16186**: ***Soit*** E un K - espace vectoriel et soit ( ei ) iI une base de E. La famille duale associée est une partie libre Démonstration Soit ( i1 ,

**16194**: Soit E un K - espace vectoriel et ***soit*** ( ei ) iI une base de E. La famille duale associée est une partie libre Démonstration Soit ( i1 ,

**16212**: Soit E un K - espace vectoriel et soit ( ei ) iI une base de E. La famille duale associée est une partie libre Démonstration ***Soit*** ( i1 ,

**16233**: , ip ) une sous-famille quelconque finie de I d' éléments distincts deux-à-deux et ***soit*** ( 1 ,

**16244**: , p ) Kp ***Soit*** j 1 , p. Par définition de la famille duale , on a donc 1 p 0 , ce qui montre que la famille duale ( e?i ) iI est libre

**16277**: ***Soit*** E un K - espace vectoriel

**16367**: ***Soit*** E un K - espace vectoriel et soit ( ei ) iI une base de E. Si E est de dimension infinie , alors la famille duale associée ne est jamais génératrice

**16375**: Soit E un K - espace vectoriel et ***soit*** ( ei ) iI une base de E. Si E est de dimension infinie , alors la famille duale associée ne est jamais génératrice

**16497**: , ip ( possible car E est de dimension infinie donc I est infini ) , on a Proposition 1.11 Base ante - duale ***Soit*** E un K - espace vectoriel de dimension finie n , ( 1 ,

**16551**: Démonstration ***Soit*** l' application définie par : Cette application a les propriétés suivantes : est linéaire

**16704**: , en ) , ( ou la famille que l' on ***imagine*** être la base ante - duale ) , c' est alors facile : soit ( 1 ,

**16718**: , en ) , ( ou la famille que l' on imagine être la base ante - duale ) , c' est alors facile : ***soit*** ( 1 ,

**16843**: 1.13.3 Trouver les formes linéaires définies sur E C 0 ( R , R ) telles que : 1.13.4 ***Soit*** E un K - espace vectoriel de dimension finie , soit E1 , E2 , ... , Ep des sous-espaces vectoriels de E , donner une CNS pour que : Hyperplans Soit E un K - espace vectoriel , on appelle hyperplan de E , tout sous-espace vectoriel H tel que : L' écriture : s' appelle équation de l' hyperplan H. Il ne y a pas unicité de l' équation , car , si convient , alors , quelque soit K ,

**16854**: 1.13.3 Trouver les formes linéaires définies sur E C 0 ( R , R ) telles que : 1.13.4 Soit E un K - espace vectoriel de dimension finie , ***soit*** E1 , E2 , ... , Ep des sous-espaces vectoriels de E , donner une CNS pour que : Hyperplans Soit E un K - espace vectoriel , on appelle hyperplan de E , tout sous-espace vectoriel H tel que : L' écriture : s' appelle équation de l' hyperplan H. Il ne y a pas unicité de l' équation , car , si convient , alors , quelque soit K ,

**16875**: 1.13.3 Trouver les formes linéaires définies sur E C 0 ( R , R ) telles que : 1.13.4 Soit E un K - espace vectoriel de dimension finie , soit E1 , E2 , ... , Ep des sous-espaces vectoriels de E , donner une CNS pour que : Hyperplans ***Soit*** E un K - espace vectoriel , on appelle hyperplan de E , tout sous-espace vectoriel H tel que : L' écriture : s' appelle équation de l' hyperplan H. Il ne y a pas unicité de l' équation , car , si convient , alors , quelque soit K ,

**16924**: 1.13.3 Trouver les formes linéaires définies sur E C 0 ( R , R ) telles que : 1.13.4 Soit E un K - espace vectoriel de dimension finie , soit E1 , E2 , ... , Ep des sous-espaces vectoriels de E , donner une CNS pour que : Hyperplans Soit E un K - espace vectoriel , on appelle hyperplan de E , tout sous-espace vectoriel H tel que : L' écriture : s' appelle équation de l' hyperplan H. Il ne y a pas unicité de l' équation , car , si convient , alors , quelque ***soit*** K ,

**16930**: ***Soit*** E un K - espace vectoriel , F un sous-espace vectoriel de E , on dit que F est de codimension finie , si F possède un supplémentaire de dimension finie

**17135**: Proposition 1.12 Caractérisation des hyperplans ***Soit*** E un K - espace vectoriel , H un sous-espace vectoriel de E , alors : H hyperplan de E codim H 1 Démonstration ( ) Soit ( x ) 0 une équation de H , comme est non nulle , on peut trouver un vecteur a E , tel ( ) Si E H K.a , a E 0E , alors , on peut prendre comme forme linéaire associée à H : Si E est de dimension finie , les hyperplans de E sont les sous-espaces vectoriels de dimension dim E1

**17162**: Proposition 1.12 Caractérisation des hyperplans Soit E un K - espace vectoriel , H un sous-espace vectoriel de E , alors : H hyperplan de E codim H 1 Démonstration ( ) ***Soit*** ( x ) 0 une équation de H , comme est non nulle , on peut trouver un vecteur a E , tel ( ) Si E H K.a , a E 0E , alors , on peut prendre comme forme linéaire associée à H : Si E est de dimension finie , les hyperplans de E sont les sous-espaces vectoriels de dimension dim E1

**17324**: Dans C 0 ( R , R ) , un supplémentaire de la droite engendrée par x 7 x , pourrait être donné par une équation du type : Théorème 1.8 Faisceaux d' hyperplans ***Soit*** E un K - espace vectoriel , soit n N , soit ( 1 ,

**17332**: Dans C 0 ( R , R ) , un supplémentaire de la droite engendrée par x 7 x , pourrait être donné par une équation du type : Théorème 1.8 Faisceaux d' hyperplans Soit E un K - espace vectoriel , ***soit*** n N , soit ( 1 ,

**17336**: Dans C 0 ( R , R ) , un supplémentaire de la droite engendrée par x 7 x , pourrait être donné par une équation du type : Théorème 1.8 Faisceaux d' hyperplans Soit E un K - espace vectoriel , soit n N , ***soit*** ( 1 ,

**17437**: Alors : Il suffit de le vérifier pour x h .a , où h Ker ( ) et K. ( Hérédité ) : supposons le résultat vrai au rang p 1 , ***soit*** ( 1 ,

**17552**: Notons H1 Ker(1 ) , H2 Ker(2 ) , si 1 et 2 sont indépendantes , les deux plans se coupent suivant la droite D. ***Soit*** K un plan contenant D ( comme sur le dessin ) , où K Ker ( ) , le théorème nous assure alors Le plan K a donc pour équation : Cette équation est définie à un coefficient de proportionnalité près , donc Figure 1.7 Hyperplans de R3 Le résultat de cette proposition est particulièrement intéressant en géométrie affine

**17639**: Ainsi si H1 , ... , Hp sont des hyperplans affines ( espaces affines ayant pour directions des hyperplans vectoriels ) d' intersection non vide ( ***soit*** A un point de l' intersection ) , d' équations : alors , pour tout hyperplan H d' équation ( AM ) 0 , contenant cette intersection , Soit V R3 , l' espace usuel muni de sa structure affine euclidienne usuelle

**17668**: Ainsi si H1 , ... , Hp sont des hyperplans affines ( espaces affines ayant pour directions des hyperplans vectoriels ) d' intersection non vide ( soit A un point de l' intersection ) , d' équations : alors , pour tout hyperplan H d' équation ( AM ) 0 , contenant cette intersection , ***Soit*** V R3 , l' espace usuel muni de sa structure affine euclidienne usuelle

**17683**: ***Soit*** D une droite affine et A un point , cherchons les plans tangents à la sphère de centre A de rayon 1 , contenant D. Par exemple : Soit D la droite définie par : 4 x y z 0 , 2 x 5 y 3 z 4 0

**17712**: Soit D une droite affine et A un point , cherchons les plans tangents à la sphère de centre A de rayon 1 , contenant D. Par exemple : ***Soit*** D la droite définie par : 4 x y z 0 , 2 x 5 y 3 z 4 0

**17743**: Cherchons le plan P contenant D tel que P ***soit*** à une distance 1 du point ( 1 , 1 , 1 )

**17796**: Théorème 1.9 Mise en équation des sous-espaces de codimensions finies ***Soit*** E un K - espace vectoriel , soit E1 un sous-espace de E , alors , pour p N , on a Démonstration ( ) Si codim(E1 ) p , on peut , par définition trouver un supplémentaire F de dimension p , et une base de F : ( e1 ,

**17804**: Théorème 1.9 Mise en équation des sous-espaces de codimensions finies Soit E un K - espace vectoriel , ***soit*** E1 un sous-espace de E , alors , pour p N , on a Démonstration ( ) Si codim(E1 ) p , on peut , par définition trouver un supplémentaire F de dimension p , et une base de F : ( e1 ,

**17938**: ( Hérédité ) Supposons le résultat vrai au rang p et prenons p 1 formes linéaires indépendantes , D' après l' hypothèse de récurrence , nous savons que E2 est de codimension p. ***Soit*** F un supplémentaire de E2 dans E de dimension p. On peut donc trouver un vecteur a E2 E1

**17995**: Il reste à montrer que : de dimension p1 donc , en utilisant la première question de l' exercice 1.4.2 , page 32 , on obtient , puisque a E2 C' est ainsi que l' on ***retrouve*** que dans l' espace , les droites sont définies par 2 équations

**18160**: Proposition 1.13 ***Soit*** V un espace affine de direction un K - espace vectoriel E. Si ( 1 ,

**18221**: 1.14.1 ***Soit*** E un K - espace vectoriel , soit ( x1 ,

**18229**: 1.14.1 Soit E un K - espace vectoriel , ***soit*** ( x1 ,

**18273**: 1.14.3 ***Soit*** E un K - espace vectoriel de dimension finie , soit V un sous-espace vectoriel de E ?

**18284**: 1.14.3 Soit E un K - espace vectoriel de dimension finie , ***soit*** V un sous-espace vectoriel de E ?

**18319**: 1.14.4 ***Soit*** E un K - espace vectoriel

**18403**: ( f ) Si E est de dimension finie , alors dim A codim A. 1.14.5 ***Soit*** E un K - espace vectoriel , et B P(E ? ) , on appelle orthogonal ( indirect ) de B et on note : Démontrer que : ( a ) B est un sous-espace vectoriel de E. Dans la suite , A et B sont des sous-espaces vectoriels de E ?

**18545**: ( h ) Si A est un sous-espace vectoriel de E , comparer : ( i ) Si B est un sous-espace vectoriel de E ? , comparer : 1.14.6 ***Soit*** E et E 0 deux K - espaces vectoriels et soit u L ( E , E 0 )

**18556**: ( h ) Si A est un sous-espace vectoriel de E , comparer : ( i ) Si B est un sous-espace vectoriel de E ? , comparer : 1.14.6 Soit E et E 0 deux K - espaces vectoriels et ***soit*** u L ( E , E 0 )

**18622**: On définit l' application transposée de u et on note : ( a ) Démontrer que t ( u v ) t u t v. ( b ) Démontrer que : ( c ) Démontrer que : Applications Systèmes linéaires Ce paragraphe , très simple , est fondamental ! Nous nous en servirons très souvent ! ***Soit*** E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) et e0 E 0 , on appelle système linéaire l' équation d' inconnue x E : L' ensemble : est appelé ensemble des solutions de ( S )

**18670**: ***Soit*** E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) et e0 E 0

**18756**: ***Soit*** E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) et e0 E 0

**18811**: ***Soit*** E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) et e0 E 0

**18853**: ***Soit*** E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) et e0 E 0

**18896**: Démonstration ***Soit*** x0 Sol(S )

**18911**: ***Soit*** E et E 0 deux K - espaces vectoriels , u L ( E , E 0 ) et e0 E 0

**19100**: Les équations récurrentes : un1 an un bn , où ( an ) nN et ( bn ) nN sont dans KN 1.15.1 ***Soit*** l' équation récurrente : ( a ) Démontrer que c' est bien un système linéaire en précisant E , E 0 et u. ( b ) Justifier l' existence de solutions

**19168**: 1.15.2 ***Soit*** l' équation différentielle : ( a ) Démontrer que c' est bien un système linéaire en précisant E , E 0 et u. ( b ) Justifier l' existence de solutions

**19244**: ( e ) Comparer aux solutions du système récurrent obtenu par discrétisation : Interpolation Proposition 1.14 Interpolation de Lagrange ***Soit*** f : I K , où I est un intervalle de R. Soit x1 xn des réels dans I , on appelle fonction polynomiale d' interpolation de Lagrange l' unique fonction polynomiale P de degré n , telle que Elle est égale à : Démonstration E f polynomiale de degré n Cet espace vectoriel est clairement de dimension n , de base La famille de E ? définie par : étant une base de E ? , on sait qu' il existe une base ante - duale ( Pk ) k1,n qui vérifie : Un calcul simple nous démontre que : On cherche ensuite une solution sous la forme : en évaluant sur les xj , on trouve l' unique solution de l' énoncé

**19257**: ( e ) Comparer aux solutions du système récurrent obtenu par discrétisation : Interpolation Proposition 1.14 Interpolation de Lagrange Soit f : I K , où I est un intervalle de R. ***Soit*** x1 xn des réels dans I , on appelle fonction polynomiale d' interpolation de Lagrange l' unique fonction polynomiale P de degré n , telle que Elle est égale à : Démonstration E f polynomiale de degré n Cet espace vectoriel est clairement de dimension n , de base La famille de E ? définie par : étant une base de E ? , on sait qu' il existe une base ante - duale ( Pk ) k1,n qui vérifie : Un calcul simple nous démontre que : On cherche ensuite une solution sous la forme : en évaluant sur les xj , on trouve l' unique solution de l' énoncé

**19370**: ***Soit*** la fonction sin sur l' intervalle 0 , 2 , pour un p N , prenons et regardons les interpolations pour différentes valeurs de p. Voir la session Wxmaxima 1.3 , de la présente 1.16.1 Redémontrer l' existence et l' unicité des fonctions polynomiales d' interpolation de Lagrange en utilisant un raisonnement sur les systèmes linéaires

**19429**: 1.16.2 ***Soit*** f : I K de classe C 1 , soit x1 xn des points de I. Démontrer l' existence et l' unicité d' une fonction polynomiale P de degré 2 n , telle que : 1.16.3 Soit f : a , b K , de classe C

**19439**: 1.16.2 Soit f : I K de classe C 1 , ***soit*** x1 xn des points de I. Démontrer l' existence et l' unicité d' une fonction polynomiale P de degré 2 n , telle que : 1.16.3 Soit f : a , b K , de classe C

**19466**: 1.16.2 Soit f : I K de classe C 1 , soit x1 xn des points de I. Démontrer l' existence et l' unicité d' une fonction polynomiale P de degré 2 n , telle que : 1.16.3 ***Soit*** f : a , b K , de classe C

**19509**: Pour p N , on pose Lp ( f ) la fonction polynomiale d' interpolation de Lagrange de f pour les points : On suppose que : Démontrer que : 1.16.4 ***Soit*** f : x 7 x , définie sur 1 , 1

**19604**: C' est pourquoi , il a fallu faire appel à d' autres classes de fonctions telles que : elles ***soient*** faciles à calculer elles approximent bien la fonction initiale elles soient insensibles à ce phénomène de divergence

**19609**: C' est pourquoi , il a fallu faire appel à d' autres classes de fonctions telles que : elles soient faciles à calculer elles ***approximent*** bien la fonction initiale elles soient insensibles à ce phénomène de divergence

**19615**: C' est pourquoi , il a fallu faire appel à d' autres classes de fonctions telles que : elles soient faciles à calculer elles approximent bien la fonction initiale elles ***soient*** insensibles à ce phénomène de divergence

**19651**: Voici ce que ***donne*** l' approximation avec 30 points ( pour Lagrange , cela diverge )

**19674**: ***Soit*** E un K - espace vectoriel de dimension finie , E ( e1 ,

**19723**: ***Soit*** E et E 0 deux espaces vectoriels de dimension finie , E ( e1 ,

**20359**: Si E R2 et f est la symétrie par rapport à y x , parallèlement à y x et si E ( 1 , 0 ) , ( 0 , 1 ) , On définit les deux opérations suivantes sur Mn , p ( K ) : L' addition a : si A Mn , p ( K ) et si B Mn , p ( K ) , on définit A B Mn , p ( K ) par an , p bn , p La multiplication externe : si K et si A Mn , p ( K ) , on définit .A Mn , p ( K ) par Il faut que les dimensions des matrices A et B ***soient*** les mêmes ! L' élément neutre pour l' addition de Mn , p ( K ) est appelée la matrice nulle , notée 0n , p et définie par Cette matrice correspond à l' application linéaire nulle 0L ( E , E 0 )

**20535**: ***Soit*** f Ker

**20762**: ***Soit*** A Mn , p ( K ) et B Mp , q ( K ) , on définit le produit de A par B comme la matrice A B Mn , q ( K ) définie par Voir la figure 2.1 , page ci - contre a

**20831**: a. Tiré de http : www.texample.nettikzexamplesmatrix - multiplication Il faut bien faire attention à ce que les dimensions des matrices ***soient*** compatibles : lorsque l' on veut faire le produit A B , le nombre de colonnes de A doit être égal au nombre de lignes de B. Soit E et E 0 deux K - espaces vectoriels de dimension finie ( avec p dim E et n dim E 0 ) , soit E une base de E et E 0 une base de E 0 , soit f L ( E , E 0 ) et soit x E. Alors Autrement dit , le produit matriciel MatE , E 0 ( f ) MatE ( x ) traduit le calcul de f ( x )

**20859**: a. Tiré de http : www.texample.nettikzexamplesmatrix - multiplication Il faut bien faire attention à ce que les dimensions des matrices soient compatibles : lorsque l' on veut faire le produit A B , le nombre de colonnes de A doit être égal au nombre de lignes de B. ***Soit*** E et E 0 deux K - espaces vectoriels de dimension finie ( avec p dim E et n dim E 0 ) , soit E une base de E et E 0 une base de E 0 , soit f L ( E , E 0 ) et soit x E. Alors Autrement dit , le produit matriciel MatE , E 0 ( f ) MatE ( x ) traduit le calcul de f ( x )

**20884**: a. Tiré de http : www.texample.nettikzexamplesmatrix - multiplication Il faut bien faire attention à ce que les dimensions des matrices soient compatibles : lorsque l' on veut faire le produit A B , le nombre de colonnes de A doit être égal au nombre de lignes de B. Soit E et E 0 deux K - espaces vectoriels de dimension finie ( avec p dim E et n dim E 0 ) , ***soit*** E une base de E et E 0 une base de E 0 , soit f L ( E , E 0 ) et soit x E. Alors Autrement dit , le produit matriciel MatE , E 0 ( f ) MatE ( x ) traduit le calcul de f ( x )

**20899**: a. Tiré de http : www.texample.nettikzexamplesmatrix - multiplication Il faut bien faire attention à ce que les dimensions des matrices soient compatibles : lorsque l' on veut faire le produit A B , le nombre de colonnes de A doit être égal au nombre de lignes de B. Soit E et E 0 deux K - espaces vectoriels de dimension finie ( avec p dim E et n dim E 0 ) , soit E une base de E et E 0 une base de E 0 , ***soit*** f L ( E , E 0 ) et soit x E. Alors Autrement dit , le produit matriciel MatE , E 0 ( f ) MatE ( x ) traduit le calcul de f ( x )

**20909**: a. Tiré de http : www.texample.nettikzexamplesmatrix - multiplication Il faut bien faire attention à ce que les dimensions des matrices soient compatibles : lorsque l' on veut faire le produit A B , le nombre de colonnes de A doit être égal au nombre de lignes de B. Soit E et E 0 deux K - espaces vectoriels de dimension finie ( avec p dim E et n dim E 0 ) , soit E une base de E et E 0 une base de E 0 , soit f L ( E , E 0 ) et ***soit*** x E. Alors Autrement dit , le produit matriciel MatE , E 0 ( f ) MatE ( x ) traduit le calcul de f ( x )

**21064**: Proposition 2.2 Correspondance entre composition et produit matriciel ***Soit*** E , E 0 et E 00 des K - espaces vectoriels de dimension finie ( p dim E , n dim E 0 et q dim E 00 ) , soit Autrement dit , le produit matriciel MatE 0 , E 00 ( g ) MatE , E 0 ( f ) traduit le calcul de g f

**21096**: Proposition 2.2 Correspondance entre composition et produit matriciel Soit E , E 0 et E 00 des K - espaces vectoriels de dimension finie ( p dim E , n dim E 0 et q dim E 00 ) , ***soit*** Autrement dit , le produit matriciel MatE 0 , E 00 ( g ) MatE , E 0 ( f ) traduit le calcul de g f

**21138**: ***Soit*** j 1 , p. La j - ième colonne de MatE , E 00 ( g f ) est donnée par en remarquant que MatE ( ej ) Mp,1 ( K ) a des zéros partout sauf en position j et en utilisant plusieurs fois la propriété 2.1 , page 98

**21550**: 2.1.4 ***Soit*** ( a , b ) R2 et soit A Mn ( R ) définie par : ai , j a si i j Trouver toutes les matrices qui commutent avec A , c' est - à - dire déterminer l' ensemble 2.1.5 On suppose que a , b et c sont trois nombrs complexes tels que a2 b2 c2 1

**21558**: 2.1.4 Soit ( a , b ) R2 et ***soit*** A Mn ( R ) définie par : ai , j a si i j Trouver toutes les matrices qui commutent avec A , c' est - à - dire déterminer l' ensemble 2.1.5 On suppose que a , b et c sont trois nombrs complexes tels que a2 b2 c2 1

**21619**: On pose : Démontrer que : 2.1.6 ***Soit*** A , B et C trois matrices de Mn ( R ) telles que : Démontrer que : Transposition Soit A un ensemble , ( n , p ) N 2 , alors l' application définie par : est appelée transposition

**21639**: On pose : Démontrer que : 2.1.6 Soit A , B et C trois matrices de Mn ( R ) telles que : Démontrer que : Transposition ***Soit*** A un ensemble , ( n , p ) N 2 , alors l' application définie par : est appelée transposition

**21833**: Il y deux manières de considérer les formes linéaires d' un K - espace vectoriel E de dimension finie : comme des applications linéaires de E dans K elles sont alors représentées par des matrices de M1,p ( K ) en fixant une base de E ( avec p dim E ) comme des vecteurs de E ? elles sont alors représentées dans une base de E ? par des matrices de Y a -t -il un lien entre ces deux représentations ? ***Soit*** E ( e1 ,

**21900**: ***Soit*** : On a donc , avec cet abus de notation , Soit E ? la base duale de E , notons : de sorte que : Finalement : Autrement dit , 2

**21912**: Soit : On a donc , avec cet abus de notation , ***Soit*** E ? la base duale de E , notons : de sorte que : Finalement : Autrement dit , 2

**21940**: En Wxmaxima , on obtient : ***Soit*** M Mp ( K )

**22208**: Il est indispensable que A ***soit*** une matrice carrée ! ( a ) Démontrer que Dp ( K ) , T p ( K ) et Tp ( K ) sont des sous-espaces vectoriels de Mp ( K )

**22274**: Trace d' une matrice ***Soit*** a A ai , j ( i , j)1,n Mp ( K )

**22314**: On définit la trace de A , notée trace(A ) , comme la somme des éléments diagonaux de A : Il est indispensable que A ***soit*** une matrice carrée ! 1

**22405**: Matrices inversibles ***Soit*** a A Mp ( K )

**22453**: On dit que A est inversible si : On dit alors que B est l' inverse de A et on note GLp ( K ) l' ensemble des matrices inversibles de Mp ( K ) Il est indispensable que A ***soit*** une matrice carrée ! Si il existe , l' inverse est unique

**22484**: En effet , si B et B 0 sont deux inverses de A , on a : ***Soit*** A Dp ( K ) une matrice diagonale : Alors A est inversible si , et seulement si , pour tout k 1 , p , k 6 0

**22531**: Si c' est le cas , on a Proposition 2.3 Lien entre automorphismes et matrices inversibles ***Soit*** E un K - espace vectoriel de dimension finie , soit E une base de E et soit f L ( E )

**22542**: Si c' est le cas , on a Proposition 2.3 Lien entre automorphismes et matrices inversibles Soit E un K - espace vectoriel de dimension finie , ***soit*** E une base de E et soit f L ( E )

**22549**: Si c' est le cas , on a Proposition 2.3 Lien entre automorphismes et matrices inversibles Soit E un K - espace vectoriel de dimension finie , soit E une base de E et ***soit*** f L ( E )

**22685**: ***Soit*** A GLp ( K ) et B GLp ( K )

**22820**: Il est cependant stable par Changement de bases K(matrice de passage ) ***Soit*** E un K - espace vectoriel de dimension finie et E ( e1 ,

**22852**: ***Soit*** X ( x1 ,

**23010**: , ep ) une base de E ( avec ***Soit*** E un K - espace vectoriel de dimension finie , E ( e1 ,

**23102**: On a ( attention à l' ordre des bases ! ) : PE MatB , E ( idE ) ***Soit*** E un K - espace vectoriel de dimension finie , E et B deux bases de E. Alors la matrice de passage PE est inversible et Démonstration PB MatB , E ( idE ) MatE , B ( idE ) MatB , B ( idE idE ) MatB , B ( idE ) Ip et de même PB PE Ip , d' où le résultat

**23169**: ***Soit*** E un K - espace vectoriel de dimension finie , E , B et C trois bases de E. Alors : Démonstration Analogue à la démonstration de la propriété 2.6 , page ci - contre ( en exercice )

**23290**: Proposition 2.4 Changement de base pour les vecteurs ***Soit*** E un K - espace vectoriel de dimension finie , E et B deux bases de E , x E. Alors : MatE ( x ) PE Autrement dit , en multipliant à gauche par PE , on obtient les anciennes coordonnées en fonction des nouvelles coordonnées

**23372**: Démonstration idE ( x ) MatE ( x ) MatB ( x ) MatB , E ( idE ) MatB ( x ) MatE Proposition 2.5 Changement de base pour les applications linéaires ***Soit*** E et E 0 des K - espaces vectoriels de dimension finie , E et B deux base de E , E 0 et B 0 deux bases de E 0 , f L ( E , E 0 )

**23557**: Figure 2.2 Changement de base pour les applications linéaires Le noyau de A est le sous-espace vectoriel de Mp,1 ( K ) défini par : L' image de A est le sous-espace vectoriel de Mn,1 ( K ) défini par : Le rang de A , noté rang(A ) , est la dimension de Im(A ) : rang(A ) dim Im(A ) a. On notera aussi Ker A , Im A et rang A. ***Soit*** A Mn , p ( K )

**23614**: , Cp les colonnes de A ( vues comme des matrices colonnes de En particulier , rang A min(n , p ) car Im A est un sous-espace vectoriel de Mn,1 ( K ) engendré par les p colonnes de A. ***Soit*** E et E 0 deux K - espaces vectoriels de dimension finie , soit E une base de E , soit E 0 une base de E 0 1

**23628**: , Cp les colonnes de A ( vues comme des matrices colonnes de En particulier , rang A min(n , p ) car Im A est un sous-espace vectoriel de Mn,1 ( K ) engendré par les p colonnes de A. Soit E et E 0 deux K - espaces vectoriels de dimension finie , ***soit*** E une base de E , soit E 0 une base de E 0 1

**23635**: , Cp les colonnes de A ( vues comme des matrices colonnes de En particulier , rang A min(n , p ) car Im A est un sous-espace vectoriel de Mn,1 ( K ) engendré par les p colonnes de A. Soit E et E 0 deux K - espaces vectoriels de dimension finie , soit E une base de E , ***soit*** E 0 une base de E 0 1

**23838**: La multiplication par une matrice inversible conserve le rang : si A Mn , p ( K ) , alors P GLp ( K ) , Q GLn ( K ) , rang(A P ) rang(Q A ) rang A 2.4.1 ***Soit*** A Mn ( K ) , existe -t -il B Mn ( K ) telle que : 2.4.2 Soit A et B dans Mn ( R ) , telles que : Démontrer que A ou B est la matrice nulle

**23857**: La multiplication par une matrice inversible conserve le rang : si A Mn , p ( K ) , alors P GLp ( K ) , Q GLn ( K ) , rang(A P ) rang(Q A ) rang A 2.4.1 Soit A Mn ( K ) , existe -t -il B Mn ( K ) telle que : 2.4.2 ***Soit*** A et B dans Mn ( R ) , telles que : Démontrer que A ou B est la matrice nulle

**23917**: 2.4.5 ***Soit*** A et B dans Mn , p ( K ) , démontrer que : rang(A ) rang(B ) Relations d' équivalence et matrices Relations d' équivalence Soit E un ensemble non vide , R une relation a sur E. On dit que : R est réflexive si : R est symétrique si : R est transitive si : On dit que R est une relation d' équivalence sur E si R est réflexive , symétrique et transitive

**23944**: 2.4.5 Soit A et B dans Mn , p ( K ) , démontrer que : rang(A ) rang(B ) Relations d' équivalence et matrices Relations d' équivalence ***Soit*** E un ensemble non vide , R une relation a sur E. On dit que : R est réflexive si : R est symétrique si : R est transitive si : On dit que R est une relation d' équivalence sur E si R est réflexive , symétrique et transitive

**24148**: Pour tout n N , avoir le même reste dans la division euclidienne par n est une relation d' équivalence sur Z. ***Soit*** E un ensemble non vide , on appelle partition de E , la donnée d' une famille ( Ei ) iI de sous-ensembles de E tels que : tous les Ei sont non vides : ils sont disjoints deux-à-deux : ils recouvrent E : 1

**24269**: Plus généralement , si n N , n 2 , on peut s' intéresser aux ensembles : ( Ek ) k0,n1 est une partition de N ***Soit*** ( Ei ) iI une partition d' un ensemble E non vide et soit R la relation sur E définie par : ( autrement dit , x et y sont en relation lorsque x et y appartiennent à un même Ei )

**24283**: Plus généralement , si n N , n 2 , on peut s' intéresser aux ensembles : ( Ek ) k0,n1 est une partition de N Soit ( Ei ) iI une partition d' un ensemble E non vide et ***soit*** R la relation sur E définie par : ( autrement dit , x et y sont en relation lorsque x et y appartiennent à un même Ei )

**24356**: Alors R est une relation d' équivalence sur E. Démonstration C' est immédiat , une fois qu' on a remarqué que pour tout x E , il existe i I tel que x Ei car la partition ( Ei ) iI recouvre E. ***Soit*** R une relation d' équivalence sur un ensemble E non vide et soit x E. La classe d' équivalence de x modulo R est le sous-ensemble de E défini par : Classe(x , R ) y E , xRy Un élément d' une classe d' équivalence est appelé un représentant de cette classe d' équivalence

**24369**: Alors R est une relation d' équivalence sur E. Démonstration C' est immédiat , une fois qu' on a remarqué que pour tout x E , il existe i I tel que x Ei car la partition ( Ei ) iI recouvre E. Soit R une relation d' équivalence sur un ensemble E non vide et ***soit*** x E. La classe d' équivalence de x modulo R est le sous-ensemble de E défini par : Classe(x , R ) y E , xRy Un élément d' une classe d' équivalence est appelé un représentant de cette classe d' équivalence

**24441**: ***Soit*** R une relation d' équivalence sur un ensemble E non vide

**24460**: ***Soit*** z Classe(x , R )

**24559**: ***Soit*** R une relation d' équivalence sur un ensemble E non vide

**24682**: On en déduit que ( Ei ) iI recouvre E ***Soit*** ( i , j ) I 2 tel que i 6 j. Supposons que Ei Ej 6

**24810**: 2.5.2 ***Soit*** E un ensemble non vide et A E , on définit une relation sur P(E ) par : ( a ) Démontrer que c' est une relation d' équivalence

**24896**: 2.5.3 ***Soit*** E un ensemble non vide , on définit la relation sur P(E ) par : f F ( X , Y ) , injective Cette relation est-elle réflexive ? Symétrique ? Transitive ? 2.5.4 Soit E un ensemble non vide muni d' une relation R réflexive et transitive

**24931**: 2.5.3 Soit E un ensemble non vide , on définit la relation sur P(E ) par : f F ( X , Y ) , injective Cette relation est-elle réflexive ? Symétrique ? Transitive ? 2.5.4 ***Soit*** E un ensemble non vide muni d' une relation R réflexive et transitive

**24971**: On définit les deux relations suivantes : xRy ou yRx Les relations S et T sont - elles réflexives ? Symétriques ? Transitives ? 2.5.5 ***Soit*** E un ensemble non vide muni d' une relation d' équivalence R , on pose : Classe(a , R ) Soit A une partie de E. ( a ) Démontrer que A s(A )

**24992**: On définit les deux relations suivantes : xRy ou yRx Les relations S et T sont - elles réflexives ? Symétriques ? Transitives ? 2.5.5 Soit E un ensemble non vide muni d' une relation d' équivalence R , on pose : Classe(a , R ) ***Soit*** A une partie de E. ( a ) Démontrer que A s(A )

**25021**: ( d ) ***Soit*** ( Ai ) iI une famille de sous-ensembles de E. Comparer pour l' inclusion les ensembles : s(Ai ) , puis s Équivalence et similitudes 1

**25287**: Démonstration ***Soit*** M et N deux matrices de Mn , p ( K )

**25401**: ***Soit*** ( e1 ,

**25683**: 2.6.2 ***Soit*** E un K - espace vectoriel de dimension finie et soit f L ( E )

**25694**: 2.6.2 Soit E un K - espace vectoriel de dimension finie et ***soit*** f L ( E )

**25756**: On définit alors la trace de f , notée trace(f ) , comme la valeur de trace(MatE ( f ) ) dans ne importe quelle base E de E. ( b ) ***Soit*** p un projecteur de E. Démontrer que trace(p ) rang(p )

**25829**: Systèmes linéaires Algorithme du pivot de Gauss Notation 2.3 ***Soit*** ( k , ) 1 , p , k 6 et K , on appelle matrice de transvection la matrice de Mp ( K ) définie par : Cette matrice est inversible et son inverse est : Démonstration Un calcul direct donne Notation 2.4 Soit k 1 , p , K , on appelle matrice de dilatation la matrice de Mp ( K ) définie par : à la k - ième place Cette matrice est inversible et son inverse est : Démonstration Un calcul immédiat démontre que Notation 2.5 Soit une permutation a de 1 , p , on appelle matrice de permutation la matrice de Mp ( K ) définie par : Cette matrice est inversible et son inverse est : a. C' est - à - dire une bijection de de 1 , p dans 1 , p. Démonstration Si et 0 sont deux permutations de 1 , p alors on remarque que : On prend alors 0 1 en remarquant que si id1,p , alors P Ip

**25874**: Systèmes linéaires Algorithme du pivot de Gauss Notation 2.3 Soit ( k , ) 1 , p , k 6 et K , on appelle matrice de transvection la matrice de Mp ( K ) définie par : Cette matrice est inversible et son inverse est : Démonstration Un calcul direct donne Notation 2.4 ***Soit*** k 1 , p , K , on appelle matrice de dilatation la matrice de Mp ( K ) définie par : à la k - ième place Cette matrice est inversible et son inverse est : Démonstration Un calcul immédiat démontre que Notation 2.5 Soit une permutation a de 1 , p , on appelle matrice de permutation la matrice de Mp ( K ) définie par : Cette matrice est inversible et son inverse est : a. C' est - à - dire une bijection de de 1 , p dans 1 , p. Démonstration Si et 0 sont deux permutations de 1 , p alors on remarque que : On prend alors 0 1 en remarquant que si id1,p , alors P Ip

**25920**: Systèmes linéaires Algorithme du pivot de Gauss Notation 2.3 Soit ( k , ) 1 , p , k 6 et K , on appelle matrice de transvection la matrice de Mp ( K ) définie par : Cette matrice est inversible et son inverse est : Démonstration Un calcul direct donne Notation 2.4 Soit k 1 , p , K , on appelle matrice de dilatation la matrice de Mp ( K ) définie par : à la k - ième place Cette matrice est inversible et son inverse est : Démonstration Un calcul immédiat démontre que Notation 2.5 ***Soit*** une permutation a de 1 , p , on appelle matrice de permutation la matrice de Mp ( K ) définie par : Cette matrice est inversible et son inverse est : a. C' est - à - dire une bijection de de 1 , p dans 1 , p. Démonstration Si et 0 sont deux permutations de 1 , p alors on remarque que : On prend alors 0 1 en remarquant que si id1,p , alors P Ip

**26002**: ***Soit*** A ai , j ( i , j)1,n1,p Mn , p ( K )

**26157**: Permutation Cela revient donc à faire la transformation ( dite opération élémentaire ) : ***Soit*** A ai , j ( i , j)1,n1,p Mn , p ( K )

**26383**: ***Soit*** la matrice : Théorème 2.1 du pivot généralisé de Gauss Soit A Mn , p ( K ) , de rang r , alors il existe des matrices de transvection - dilatation - permutation de Mn ( K ) , notées R1 ,

**26394**: Soit la matrice : Théorème 2.1 du pivot généralisé de Gauss ***Soit*** A Mn , p ( K ) , de rang r , alors il existe des matrices de transvection - dilatation - permutation de Mn ( K ) , notées R1 ,

**26841**: Hérédité ***Soit*** p N. Supposons le résultat vrai au rang p. Soit une permutation de 1 , p 1

**26851**: Hérédité Soit p N. Supposons le résultat vrai au rang p. ***Soit*** une permutation de 1 , p 1

**26891**: ***Soit*** P une matrice de permutation de Mp ( K )

**26958**: On peut procéder de la manière suivante : ***Soit*** A GLp ( K ) , alors il existe des matrices de transvection - dilatation - permutation de Mp ( K ) , notées R1 ,

**27030**: , Ss telles que : Autrement dit , quand A est inversible , on peut se contenter de travailler ***soit*** uniquement sur les lignes , soit uniquement sur les colonnes

**27036**: , Ss telles que : Autrement dit , quand A est inversible , on peut se contenter de travailler soit uniquement sur les lignes , ***soit*** uniquement sur les colonnes

**27353**: 2.7.1 ***Soit*** la matrice : ( a ) Calculer son rang r. ( b ) Trouver deux matrices P et Q inversibles telles que : 2.7.2 Déterminer les a K tels que la matrice : soit inversible Démontrer que A est inversible et calculer son inverse

**27387**: 2.7.1 Soit la matrice : ( a ) Calculer son rang r. ( b ) Trouver deux matrices P et Q inversibles telles que : 2.7.2 Déterminer les a K tels que la matrice : ***soit*** inversible Démontrer que A est inversible et calculer son inverse

**27400**: 2.7.4 ***Soit*** la matrice : ( a ) Déterminer le rang de A. ( b ) Déterminer une base de l' image de A. ( c ) Donner des équations de Im(A )

**27475**: ( b ) Calculer le rang de en fonction de celui de A. 2.7.6 ***Soit*** A une matrice de Mn ( R ) tri-diagonale ( c' est - à - dire vérifiant ai , j 0 dès que i j 2 )

**27534**: n ( K ) , ***soit*** 0 , démontrer qu' il existe une matrice P Dn ( K ) GLn ( K ) telle que : Systèmes linéaires On a déjà vu au chapitre précédent ( section 1.4.1 , page 78 ) qu' en toute généralité , un système linéaire est une équation de la forme : où u L ( E , E 0 ) et b E 0 sont fixés et x est l' inconnue ( E et E 0 sont des K - espaces vectoriels )

**27718**: Dans le cas de la dimension finie et une fois des bases fixées , ce système linéaire est équivalent à un système de n équations à n inconnues , que l' on peut écrire sous forme matricielle : où A est la matrice n p de u , X la matrice p 1 de x et B la matrice n 1 de b ( avec p dim E et Lorsque l' on a un système de n équations à p inconnues , la condition de compatibilité ( c' est - à - dire la condition pour que le système ***admette*** des solutions ) s' écrit ( voir la partie suivante sur les matrices - blocs ) : rang(A ) rang A B ) ce qui se vérifie facilement à l' aide d' une méthode de pivot sur les lignes , où l' on ne prend jamais le pivot sur la colonne constituée des éléments de B. La matrice A B Mn , p1 ( K ) s' appelle la matrice augmentée du système A X B. Un système de n équations à n inconnues : est dit de Cramer , lorsque A est inversible

**27857**: En ce cas , il y a existence et unicité de la solution , donnée par Pour résoudre un système de Cramer , on ne calcule jamais l' inverse de la matrice A , on utilise l' algorithme du pivot de Gauss ! ***Soit*** à résoudre le système : Appliquons l' algorithme du pivot de Gauss à la matrice augmentée A B : La deuxième ligne permet de discerner trois cas : 1

**27937**: 6 , le système est compatible car rang(A ) rangA B 2 : Comme on a travaillé sur les lignes , les solutions du système sont les solutions du système réduit , ***soit*** : 3

**28095**: 2.8.1 ***Soit*** ( a , b , c ) C2

**28125**: Résoudre le système et donner une condition nécessaire et suffisante sur a , b et c pour que les solutions ***soient*** réelles

**28389**: Proposition 2.7 Correspondance matrices - blocs et décomposition en somme directe ***Soit*** E et E 0 deux K - espaces vectoriels de dimensions finies , avec ( E1 , E2 ) une base de E adaptée à la somme directe E E1 E2 ( E10 , E20 ) une base de E 0 adaptée à la somme directe E 0 E10 E20

**28698**: De plus , n ( K ) GLn ( K ) est stable par M 7 M où A GLn1 ( K ) et D GLn2 ( K ) , alors M GLn1 n2 ( K ) et son inverse est de la forme : On rencontre souvent des transvections - blocs , des dilatations - blocs et des permutations - blocs , ainsi : vérifie clairement ( en choisissant k et pour avoir des dimensions compatibles ) : ***soit*** une opération élémentaire sur les blocs : ( produit à gauche ) ( produit à droite ) De même avec les dilatations : ( produit à gauche ) ( produit à droite ) La permutation - bloc serait par exemple : Cela permet ( avec quelques précautions de calcul ) de faire des manipulations sur les matrices - blocs comme sur des matrices usuelles

**28838**: On peut en déduire que si A GLn ( K ) , alors il existe une matrice de permutation P , une matrice T1 triangulaire inférieure avec des 1 sur la diagonale et une matrice T2 triangulaire supérieure telles Produit de Kronecker ***Soit*** A ai , j Mn1 , p1 ( K ) et B Mn2 , p2 ( K ) , on définit le produit de Kronecker de A et B comme la matrice - blocs : alors pour toute matrice B à coefficients dans K , on a 2

**29023**: 2.9.4 ***Soit*** A et B dans Mn ( R ) et Soit E R A .B inversible

**29033**: 2.9.4 Soit A et B dans Mn ( R ) et ***Soit*** E R A .B inversible

**29051**: Trouver une condition nécessaire et suffisante sur E pour que M ***soit*** inversible et , dans ce cas , calculer M 1

**29064**: 2.9.5 ***Soit*** A1 Mn1 , p1 ( K ) , ... Aq Mnq , pq ( K )

**29147**: Chapitre 3 Déterminant Permutations et groupe symétrique ***Soit*** E un ensemble non vide

**29292**: On l' appelle le groupe symétrique de E et Sp s' appelle le groupe symétrique de degré p. ***Soit*** p N

**29448**: La démonstration peut se faire plus rigoureusement par récurrence sur p. ***Soit*** p N , p 2 , et soit ( i , j ) 1 , p , i 6 j. La transposition i , j est la permutation de Sp qui échange i et j et qui laisse stable les autres entiers : Soit p N , p 2

**29456**: La démonstration peut se faire plus rigoureusement par récurrence sur p. Soit p N , p 2 , et ***soit*** ( i , j ) 1 , p , i 6 j. La transposition i , j est la permutation de Sp qui échange i et j et qui laisse stable les autres entiers : Soit p N , p 2

**29492**: La démonstration peut se faire plus rigoureusement par récurrence sur p. Soit p N , p 2 , et soit ( i , j ) 1 , p , i 6 j. La transposition i , j est la permutation de Sp qui échange i et j et qui laisse stable les autres entiers : ***Soit*** p N , p 2

**29555**: ***Soit*** p N , soit Sp , on appelle signature de et on note a : a. On fait le produit sur tous les couples ( i , j ) 1 , p2 tels que i j. Pour p 1 , on obtient un produit vide qui vaut 1 par convention

**29559**: Soit p N , ***soit*** Sp , on appelle signature de et on note a : a. On fait le produit sur tous les couples ( i , j ) 1 , p2 tels que i j. Pour p 1 , on obtient un produit vide qui vaut 1 par convention

**29661**: ***Soit*** p N

**29864**: ***Soit*** la permutation de 1 , 9 donnée par a : alors sa signature vaut : 1

**29977**: Bien retenir qu' il suffit de regarder ce qui se passe avec les transpositions ! Formes p - linéaires sur un espace vectoriel de dimension n ***Soit*** E un K - espace vectoriel de dimension finie , soit p N

**29988**: Bien retenir qu' il suffit de regarder ce qui se passe avec les transpositions ! Formes p - linéaires sur un espace vectoriel de dimension n Soit E un K - espace vectoriel de dimension finie , ***soit*** p N

**30006**: On appelle forme p - linéaire sur E toute application : telle que : ***soit*** linéaire Lp ( E , K ) l' ensemble des formes p - linéaires sur E L' ensemble Lp ( E , K ) est un K - espace vectoriel pour les opérations usuelles

**30178**: , fp sont des formes linéaires sur E , alors est une forme p - linéaire sur E. ***Soit*** E un K - espace vectoriel de dimension finie , soit p N , p 2 , et soit Lp ( E , K )

**30189**: , fp sont des formes linéaires sur E , alors est une forme p - linéaire sur E. Soit E un K - espace vectoriel de dimension finie , ***soit*** p N , p 2 , et soit Lp ( E , K )

**30197**: , fp sont des formes linéaires sur E , alors est une forme p - linéaire sur E. Soit E un K - espace vectoriel de dimension finie , soit p N , p 2 , et ***soit*** Lp ( E , K )

**30427**: En particulier : est symétrique si , et seulement si , échanger deux vecteurs ne change pas le signe ( ci-dessous seules les i - èmes et j - ièmes variables sont explicitées ) : est antisymétrique si , et seulement si , échanger deux vecteurs change le signe ( ci-dessous seules les i - èmes et j - ièmes variables sont explicitées ) : ***Soit*** Lp ( E , K )

**30456**: Alors est antisymétrique si , et seulement si , elle est alternée , c' est - à - dire : Démonstration ***Soit*** ( x1 ,

**30469**: , xp ) E p et ***soit*** ( i , j ) 1 , p2 tel que i 6 j ( ci-dessous , seules les i - èmes et j - ièmes variables sont explicitées )

**30598**: Par exemple , Z2 Z. ***Soit*** E un K - espace vectoriel , soit p N , p 2 , soit Ap ( E , K ) et soit ( x1 ,

**30606**: Par exemple , Z2 Z. Soit E un K - espace vectoriel , ***soit*** p N , p 2 , soit Ap ( E , K ) et soit ( x1 ,

**30613**: Par exemple , Z2 Z. Soit E un K - espace vectoriel , soit p N , p 2 , ***soit*** Ap ( E , K ) et soit ( x1 ,

**30621**: Par exemple , Z2 Z. Soit E un K - espace vectoriel , soit p N , p 2 , soit Ap ( E , K ) et ***soit*** ( x1 ,

**30636**: ***Soit*** i 1 ,

**30713**: , xp ) est liée , cela veut dire qu' il existe i 1 , p tel que xi ***soit*** une combinaison linéaire des Puisque est linéaire par rapport à sa i - ème variable : puisque xk apparaît deux fois dans (

**30776**: i - ème variable : Théorème 3.1 Dimension de l' espace des formes n - linéaires alternées ***Soit*** E un K - espace vectoriel de dimension finie avec n dim E 1

**30908**: Le fait que D ***soit*** une forme n - linéaire est une simple vérification ( en exercice )

**31141**: Déterminant d' une famille de vecteurs ***Soit*** E un K - espace vectoriel de dimension finie avec n dim E 1 , soit E ( e1 ,

**31157**: Déterminant d' une famille de vecteurs Soit E un K - espace vectoriel de dimension finie avec n dim E 1 , ***soit*** E ( e1 ,

**31264**: Considérons E K2 muni de la base canonique E ( e1 , e2 ) ainsi que deux vecteurs u ( a , b ) a.e1 b.e2 et v ( c , d ) c.e1 d.e2 de E. Le groupe symétrique S2 a 2 ! 2 éléments , l' identité id1,2 et la transposition ***Soit*** E un K - espace vectoriel de dimension finie avec n dim E 1 , soit E ( e1 ,

**31280**: Considérons E K2 muni de la base canonique E ( e1 , e2 ) ainsi que deux vecteurs u ( a , b ) a.e1 b.e2 et v ( c , d ) c.e1 d.e2 de E. Le groupe symétrique S2 a 2 ! 2 éléments , l' identité id1,2 et la transposition Soit E un K - espace vectoriel de dimension finie avec n dim E 1 , ***soit*** E ( e1 ,

**31315**: ***Soit*** i 1 ,

**31395**: ***Soit*** E un K - espace vectoriel de dimension finie avec n dim E 1 et soit E ( e1 ,

**31411**: Soit E un K - espace vectoriel de dimension finie avec n dim E 1 et ***soit*** E ( e1 ,

**31465**: Supposons que C ***soit*** une base de E. D' après le résultat précédent , nous avons Par contraposition , si la famille C ne est pas une base de E alors elle est liée donc detE ( c1 ,

**31522**: Déterminant d' une matrice carrée ***Soit*** a A ai , j ( i , j)1,n2 Mn ( K ) , on appelle déterminant de A et on note Autrement dit , c' est le déterminant de la famille des n colonnes de A dans la base canonique de Mn,1 ( K )

**31578**: a. Attention , il faut que la matrice ***soit*** carrée

**31695**: ***Soit*** A Mn ( K )

**31766**: ***Soit*** A Mn ( K )

**31962**: Déterminant d' un endomorphisme ***Soit*** E un K - espace vectoriel de dimension finie et soit u L ( E )

**31973**: Déterminant d' un endomorphisme Soit E un K - espace vectoriel de dimension finie et ***soit*** u L ( E )

**32045**: det idE det In 1 ***Soit*** E un K - espace vectoriel de dimension finie , soit E une base de E et soit u L ( E )

**32056**: det idE det In 1 Soit E un K - espace vectoriel de dimension finie , ***soit*** E une base de E et soit u L ( E )

**32063**: det idE det In 1 Soit E un K - espace vectoriel de dimension finie , soit E une base de E et ***soit*** u L ( E )

**32073**: Alors : Démonstration ***Soit*** E un K - espace vectoriel de dimension finie et soit ( u , v ) L ( E)2

**32084**: Alors : Démonstration Soit E un K - espace vectoriel de dimension finie et ***soit*** ( u , v ) L ( E)2

**32274**: Ainsi , pour calculer un déterminant d' une matrice carrée d' ordre 5 , il faut effectuer Pire encore , 60 ! ' 1082 est supérieur au nombre d' atomes observables dans l' univers , alors que les problèmes de mathématiques appliquées et d' ingénierie moderne ***nécessitent*** de traiter des matrices qui ont des centaines de milliers voire des millions de lignes ... Il faut donc trouver des méthodes plus efficaces

**32336**: Déterminant d' une matrice triangulaire ***Soit*** A ai , j ( i , j)1,n2 Mn ( K )

**32369**: Si A est triangulaire supérieure ( ou triangulaire inférieure , ou diagonale ) , alors Démonstration Supposons que A ***soit*** triangulaire supérieure

**32444**: Supposons que s1,k ***soit*** l' identité pour un k 1 , n. On a d' une part ( k 1 ) k 1 mais comme est injective , ( k 1 ) 1 , k d' où ( k 1 ) k 1 , c' est - à - dire que 1,k1 est l' identité

**32951**: On peut démontrer que le calcul du déterminant d' une matrice carrée de taille n par la méthode du pivot de Gauss nécessite un nombre d' opération de l' ordre de n3 , ce qui est bien meilleur que n!. ***Soit*** à calculer ( n 2 ) : En faisant les transvections successives ( qui conservent le déterminant ) : On fait apparaître deux lignes identiques , donc : Si a , b , c , d , e , f , g , h et i sont dans K , alors e f aei dhc gbf gec ahf dbi que l' on peut mémoriser par la règle de Sarrus : On remarque , qu' avant développement , Wxmaxima nous proposait une formule non développée , qu' on peut ré-écrire : Que se passe -t -il pour n plus grand ? On reconnaît l' expression : Soit A Mn ( K ) , soit ( k , ) 1 , n , on note a Ak , la matrice de Mn1 ( K ) obtenue à partir de A en supprimant sa k - ième ligne et sa -ième colonne

**33057**: On peut démontrer que le calcul du déterminant d' une matrice carrée de taille n par la méthode du pivot de Gauss nécessite un nombre d' opération de l' ordre de n3 , ce qui est bien meilleur que n!. Soit à calculer ( n 2 ) : En faisant les transvections successives ( qui conservent le déterminant ) : On fait apparaître deux lignes identiques , donc : Si a , b , c , d , e , f , g , h et i sont dans K , alors e f aei dhc gbf gec ahf dbi que l' on peut mémoriser par la règle de Sarrus : On remarque , qu' avant développement , Wxmaxima nous proposait une formule non développée , qu' on peut ré-écrire : Que se passe -t -il pour n plus grand ? On reconnaît l' expression : ***Soit*** A Mn ( K ) , soit ( k , ) 1 , n , on note a Ak , la matrice de Mn1 ( K ) obtenue à partir de A en supprimant sa k - ième ligne et sa -ième colonne

**33064**: On peut démontrer que le calcul du déterminant d' une matrice carrée de taille n par la méthode du pivot de Gauss nécessite un nombre d' opération de l' ordre de n3 , ce qui est bien meilleur que n!. Soit à calculer ( n 2 ) : En faisant les transvections successives ( qui conservent le déterminant ) : On fait apparaître deux lignes identiques , donc : Si a , b , c , d , e , f , g , h et i sont dans K , alors e f aei dhc gbf gec ahf dbi que l' on peut mémoriser par la règle de Sarrus : On remarque , qu' avant développement , Wxmaxima nous proposait une formule non développée , qu' on peut ré-écrire : Que se passe -t -il pour n plus grand ? On reconnaît l' expression : Soit A Mn ( K ) , ***soit*** ( k , ) 1 , n , on note a Ak , la matrice de Mn1 ( K ) obtenue à partir de A en supprimant sa k - ième ligne et sa -ième colonne

**33350**: ***Soit*** j 1 , n. Comme le déterminant est une forme n - linéaire par rapport aux colonnes : En échangeant la j - ième colonne avec la j 1-ième , puis la j 1-ième avec la j 1-ième jusqu' à ce que la première colonne soit Ci , puisqu' il y a au total j 1 échanges : En échangeant la i - ème ligne avec la i 1-ième , puis la i 1-ième avec la i 1-ième jusqu' à ce que la première ligne soit 1 0 0 , puisqu' il y a au total i1 échanges , on a par la formule du déterminant d' une matrice - blocs ( 1)ij ai , j det(1 ) det Ai , j ai , j Cofacteuri , j ( A ) La formule du développement selon une colonne se démontre de la même façon ( ou en utilisant la transposée )

**33396**: Soit j 1 , n. Comme le déterminant est une forme n - linéaire par rapport aux colonnes : En échangeant la j - ième colonne avec la j 1-ième , puis la j 1-ième avec la j 1-ième jusqu' à ce que la première colonne ***soit*** Ci , puisqu' il y a au total j 1 échanges : En échangeant la i - ème ligne avec la i 1-ième , puis la i 1-ième avec la i 1-ième jusqu' à ce que la première ligne soit 1 0 0 , puisqu' il y a au total i1 échanges , on a par la formule du déterminant d' une matrice - blocs ( 1)ij ai , j det(1 ) det Ai , j ai , j Cofacteuri , j ( A ) La formule du développement selon une colonne se démontre de la même façon ( ou en utilisant la transposée )

**33436**: Soit j 1 , n. Comme le déterminant est une forme n - linéaire par rapport aux colonnes : En échangeant la j - ième colonne avec la j 1-ième , puis la j 1-ième avec la j 1-ième jusqu' à ce que la première colonne soit Ci , puisqu' il y a au total j 1 échanges : En échangeant la i - ème ligne avec la i 1-ième , puis la i 1-ième avec la i 1-ième jusqu' à ce que la première ligne ***soit*** 1 0 0 , puisqu' il y a au total i1 échanges , on a par la formule du déterminant d' une matrice - blocs ( 1)ij ai , j det(1 ) det Ai , j ai , j Cofacteuri , j ( A ) La formule du développement selon une colonne se démontre de la même façon ( ou en utilisant la transposée )

**33596**: ***Soit*** ( a , b , c ) K3 , calculer : On développe suivant la première colonne , puis le cofacteur d' indice ( 2 , 1 ) suivant la première ligne

**33819**: Théorème 3.2 Propriété de la comatrice ***Soit*** A Mn ( K ) , alors : En particulier , si A est inversible : Démonstration Pour i j , le coefficient en ( i , i ) de A t Com(A ) vaut , en utilisant la formule du développement suivant la i - ième ligne : ai , k Cofacteuri , k ( A ) det A Pour i 6 j , posons B la matrice obtenue à partir de A en remplaçant la j - ième ligne par la i - ème ligne de A. Puisque B a deux lignes égales , det B 0

**34198**: ***Soit*** E ( e1 ,

**34587**: Autrement dit , c' est un système de Cramer si , et seulement si , A est inversible si , et seulement si , Proposition 3.3 ***Soit*** A GLn ( K ) de colonnes A1 ,

**34757**: Elle a cependant un intérêt théorique , elle permet d' obtenir que la solution X dépend de manière continue ( et même C ) des coefficients de A et B : une petite variation sur les coefficients de A ou de B provoque une petite variation sur les coefficients de X : on peut donc faire un calcul approché de X ! Démontrer que A est inversible et que : 3.1.2 ***Soit*** V un K - espace vectoriel de dimension finie et soit p1 N , p2 N , p2 n. On considère l' ensemble des formes ( p1 p2 ) -linéaires vérifiant pour tout ( x1 ,

**34768**: Elle a cependant un intérêt théorique , elle permet d' obtenir que la solution X dépend de manière continue ( et même C ) des coefficients de A et B : une petite variation sur les coefficients de A ou de B provoque une petite variation sur les coefficients de X : on peut donc faire un calcul approché de X ! Démontrer que A est inversible et que : 3.1.2 Soit V un K - espace vectoriel de dimension finie et ***soit*** p1 N , p2 N , p2 n. On considère l' ensemble des formes ( p1 p2 ) -linéaires vérifiant pour tout ( x1 ,

**34867**: , xp1 p2 ) V p1 p2 , toute 1 Sp1 et toute 2 Sp2 : Quelle est la dimension du sous-espace vectoriel des formes p - linéaires vérifiant cette propriété ? det(A B ) det(A)p det(B)n 3.1.4 Démontrer que le volume d' un tétraèdre de sommets A , B , C et D , vaut : det(AB , AC , AD ) 3.1.5 Calculer les déterminants suivants : 3.1.6 ***Soit*** A Mn ( K ) , démontrer que : ( a ) On suppose D inversible démontrer que Démontrer par un exemple que ce ne est pas toujours vrai si D est non inversible

**35070**: 3.1.10 ***Soit*** A et B dans Mn ( R )

**35084**: Démontrer que : 3.1.11 ***Soit*** A Mn ( K ) avec n 2

**35111**: Démontrer que : rang(A ) n 3.1.12 Démontrer que : rang ( Com(A ) ) n 3.1.13 ***Soit*** A et B dans Mn ( R )

**35219**: Chapitre 4 Réduction des endomorphismes Éléments propres ***Soit*** E un K - espace vectoriel de dimension finie et soit u L ( E )

**35230**: Chapitre 4 Réduction des endomorphismes Éléments propres Soit E un K - espace vectoriel de dimension finie et ***soit*** u L ( E )

**35743**: Polynôme caractéristique ***Soit*** E un K - espace vectoriel de dimension finie , soit u L ( E ) et soit K. Les propositions suivantes sont équivalentes : 3

**35754**: Polynôme caractéristique Soit E un K - espace vectoriel de dimension finie , ***soit*** u L ( E ) et soit K. Les propositions suivantes sont équivalentes : 3

**35761**: Polynôme caractéristique Soit E un K - espace vectoriel de dimension finie , soit u L ( E ) et ***soit*** K. Les propositions suivantes sont équivalentes : 3

**35866**: ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u L ( E )

**35879**: Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u L ( E )

**36072**: ***Soit*** E un K - espace vectoriel de dimension finie n 1 et soit u L ( E )

**36085**: Soit E un K - espace vectoriel de dimension finie n 1 et ***soit*** u L ( E )

**36120**: ***Soit*** A ai , j ( i , j)1,n2 Mn ( K ) la matrice de u dans une base quelconque de E ( donc u A )

**36202**: idE ) det u. ***Soit*** E un K - espace vectoriel de dimension finie non nulle , soit u L ( E ) et soit K. Alors est une valeur propre de u si , et seulement si , u ( ) 0

**36215**: idE ) det u. Soit E un K - espace vectoriel de dimension finie non nulle , ***soit*** u L ( E ) et soit K. Alors est une valeur propre de u si , et seulement si , u ( ) 0

**36222**: idE ) det u. Soit E un K - espace vectoriel de dimension finie non nulle , soit u L ( E ) et ***soit*** K. Alors est une valeur propre de u si , et seulement si , u ( ) 0

**36438**: Ainsi : i1 Ei , i1 Mk ( K ) sont telles que toutes les Ak ( k 1 , n ) ont même polynôme caractéristique alors que les espaces propres associés ont des dimensions allant de 1 à n. ***Soit*** E un K - espace vectoriel de dimension finie non nulle , soit u L ( E ) et soit Sp(u )

**36451**: Ainsi : i1 Ei , i1 Mk ( K ) sont telles que toutes les Ak ( k 1 , n ) ont même polynôme caractéristique alors que les espaces propres associés ont des dimensions allant de 1 à n. Soit E un K - espace vectoriel de dimension finie non nulle , ***soit*** u L ( E ) et soit Sp(u )

**36458**: Ainsi : i1 Ei , i1 Mk ( K ) sont telles que toutes les Ak ( k 1 , n ) ont même polynôme caractéristique alors que les espaces propres associés ont des dimensions allant de 1 à n. Soit E un K - espace vectoriel de dimension finie non nulle , soit u L ( E ) et ***soit*** Sp(u )

**36530**: ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u L ( E )

**36543**: Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u L ( E )

**36574**: Démonstration ***Soit*** Sp(u )

**36609**: ***Soit*** ( e1 ,

**36675**: Diagonalisation Proposition 4.1 ***Soit*** E un K - espace vectoriel de dimension finie , soit u L ( E ) et soit 1 ,

**36686**: Diagonalisation Proposition 4.1 Soit E un K - espace vectoriel de dimension finie , ***soit*** u L ( E ) et soit 1 ,

**36693**: Diagonalisation Proposition 4.1 Soit E un K - espace vectoriel de dimension finie , soit u L ( E ) et ***soit*** 1 ,

**36746**: ***Soit*** k 2 , n. Supposons le résultat vrai au rang k. Prenons pour tout j 1 , k 1 , xj Eu ( j ) tel que ( écriture de 0E ) : D' après ces deux égalités : donc , par hypothèse de récurrence , x1 xk 0E et donc xk1 0E

**36826**: Par principe de récurrence , le résultat est vrai pour tout k 2 , n. ***Soit*** E un K - espace vectoriel de dimension finie et soit u L ( E )

**36837**: Par principe de récurrence , le résultat est vrai pour tout k 2 , n. Soit E un K - espace vectoriel de dimension finie et ***soit*** u L ( E )

**37027**: Cependant , pour une matrice , il est fondamental de préciser le corps K dans lequel on travaille ( il est possible qu' une matrice Mn ( R ) ne ***soit*** pas diagonalisable mais qu' elle soit diagonalisable si on la voit comme une matrice de Mn ( C ) )

**37033**: Cependant , pour une matrice , il est fondamental de préciser le corps K dans lequel on travaille ( il est possible qu' une matrice Mn ( R ) ne soit pas diagonalisable mais qu' elle ***soit*** diagonalisable si on la voit comme une matrice de Mn ( C ) )

**37072**: ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u L ( E )

**37085**: Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u L ( E )

**37159**: , k et supposons que dim Eu ( i ) dim E Pour tout i 1 , k , ***soit*** Ei une base de Eu ( i )

**37242**: Théorème 4.1 Caractérisation des endomorphismes diagonalisables ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u L ( E )

**37255**: Théorème 4.1 Caractérisation des endomorphismes diagonalisables Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u L ( E )

**37332**: Démonstration Supposons que u ***soit*** diagonalisable

**37429**: De plus , il est de degré n ( propriété 4.2 , page 194 ) donc multu ( i ) Mais pour tout i 1 , k , 1 di multu ( i ) ( propriété 4.4 , page 195 ) , ce qui implique que , pour tout Supposons que u ***soit*** scindé et que , pour tout i 1 , k , di multu ( i )

**37736**: 4.1.2 Diagonaliser ( c' est - à - dire démontrer qu' elle est diagonalisable et l' écrire sous la forme P D P 1 avec P GL3 ( R ) et D M3 ( R ) diagonale ) la matrice suivante : 4.1.3 Démontrer que les matrices suivantes sont semblables : 4.1.4 Diagonaliser l' endomorphisme de Kn X défini par ( pour n N ) : 4.1.5 ***Soit*** A Mn ( K ) diagonalisable et B Mp ( K ) diagonalisable , démontrer que A B est diagonalisable et préciser les éléments propres de A B en fonction de ceux de A et de B. 4.1.6 Trouver une condition nécessaire et suffisante sur A Mn ( C ) pour que soit diagonalisable 4.1.7 Démontrer que toute matrice circulante , c' est - à - dire de la forme : est diagonalisable dans Mn ( C ) et donner ses éléments propres

**37789**: 4.1.2 Diagonaliser ( c' est - à - dire démontrer qu' elle est diagonalisable et l' écrire sous la forme P D P 1 avec P GL3 ( R ) et D M3 ( R ) diagonale ) la matrice suivante : 4.1.3 Démontrer que les matrices suivantes sont semblables : 4.1.4 Diagonaliser l' endomorphisme de Kn X défini par ( pour n N ) : 4.1.5 Soit A Mn ( K ) diagonalisable et B Mp ( K ) diagonalisable , démontrer que A B est diagonalisable et préciser les éléments propres de A B en fonction de ceux de A et de B. 4.1.6 Trouver une condition nécessaire et suffisante sur A Mn ( C ) pour que ***soit*** diagonalisable 4.1.7 Démontrer que toute matrice circulante , c' est - à - dire de la forme : est diagonalisable dans Mn ( C ) et donner ses éléments propres

**37844**: 4.1.8 La matrice suivante est-elle diagonalisable ( n 2 ) ? 4.1.9 La matrice suivante est-elle diagonalisable ( n 2 ) ? 4.1.10 ***Soit*** ( a1 ,

**37881**: À quelle condition nécessaire et suffisante la matrice M suivante est-elle diagonalisable ? 4.1.11 Trouver une condition nécessaire et suffisante pour que la matrice suivante ***soit*** diagonalisable : 4.1.12 Soit E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**37885**: À quelle condition nécessaire et suffisante la matrice M suivante est-elle diagonalisable ? 4.1.11 Trouver une condition nécessaire et suffisante pour que la matrice suivante soit diagonalisable : 4.1.12 ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**37948**: Démontrer l' équivalence de : ( a ) u diagonalisable ( b ) tout sous-espace de E stable par u admet un supplémentaire stable par u. 4.1.13 Trouver les valeurs propres et vecteurs propres de l' endomorphisme de Rn X défini par : Trigonalisation ***Soit*** E un K - espace vectoriel de dimension finie n 1 et soit u L ( E )

**37961**: Démontrer l' équivalence de : ( a ) u diagonalisable ( b ) tout sous-espace de E stable par u admet un supplémentaire stable par u. 4.1.13 Trouver les valeurs propres et vecteurs propres de l' endomorphisme de Rn X défini par : Trigonalisation Soit E un K - espace vectoriel de dimension finie n 1 et ***soit*** u L ( E )

**37977**: On dit que u est dit trigonalisable si il ***existe*** un drapeau stable pour u , c' est - à - dire des sous-espaces vectoriels V1 ,

**38159**: Théorème 4.2 Caractérisation des endomorphismes trigonalisables ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u L ( E )

**38172**: Théorème 4.2 Caractérisation des endomorphismes trigonalisables Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u L ( E )

**38196**: Alors u est trigonalisable si , et seulement si , u est scindé Démonstration Supposons que u ***soit*** trigonalisable

**38230**: Il existe une base E de E telle que A MatE ( u ) ai , j ( i , j)1,n2 Mn ( K ) ( avec n dim E ) ***soit*** triangulaire supérieure

**38264**: ***Soit*** n N

**38275**: Supposons le résultat vrai au rang n. ***Soit*** u L ( E ) avec dim E n 1 tel que u soit scindé

**38289**: Supposons le résultat vrai au rang n. Soit u L ( E ) avec dim E n 1 tel que u ***soit*** scindé

**38429**: , hn1 ) de H telle que la matrice de H u H dans cette base ***soit*** triangulaire supérieure

**38539**: ***Soit*** u L ( R ) tel que A MatC ( u ) où C ( c1 , c2 , c3 ) est la base canonique de R3

**38795**: On a alors : Finalement : Vérifions en Wxmaxima : ***Soit*** E un K - espace vectoriel de dimension finie non nulle , soit u E et soit F 6 0E un sous-espace vectoriel de E stable par u ( c' est - à - dire u(F ) F )

**38808**: On a alors : Finalement : Vérifions en Wxmaxima : Soit E un K - espace vectoriel de dimension finie non nulle , ***soit*** u E et soit F 6 0E un sous-espace vectoriel de E stable par u ( c' est - à - dire u(F ) F )

**38812**: On a alors : Finalement : Vérifions en Wxmaxima : Soit E un K - espace vectoriel de dimension finie non nulle , soit u E et ***soit*** F 6 0E un sous-espace vectoriel de E stable par u ( c' est - à - dire u(F ) F )

**39031**: On peut donc écrire : Puisque que ceci est vrai pour toute forme linéaire E ? et en remarquant que les i , j ne ***dépendent*** pas de ( formules de Cramer ) , on a : en utilisant le fait que F est stable par tous les uj

**39120**: Supposons F 6 E. ***Soit*** F une base de F que l' on complète en une base E de E. On a alors ( n dim E et p dim F ) : On en déduit que u v D

**39327**: Si elles existent , les solutions s' écrivent sous la forme : Comme ceci est vrai pour toute forme linéaire E ? et les i , j ne dépendent pas de , on a ***Soit*** E un K - espace vectoriel de dimension finie et soit u et v deux endomorphismes de E qui commutent Démonstration Soit Sp(u ) et soit x Eu ( )

**39338**: Si elles existent , les solutions s' écrivent sous la forme : Comme ceci est vrai pour toute forme linéaire E ? et les i , j ne dépendent pas de , on a Soit E un K - espace vectoriel de dimension finie et ***soit*** u et v deux endomorphismes de E qui commutent Démonstration Soit Sp(u ) et soit x Eu ( )

**39349**: Si elles existent , les solutions s' écrivent sous la forme : Comme ceci est vrai pour toute forme linéaire E ? et les i , j ne dépendent pas de , on a Soit E un K - espace vectoriel de dimension finie et soit u et v deux endomorphismes de E qui commutent Démonstration ***Soit*** Sp(u ) et soit x Eu ( )

**39353**: Si elles existent , les solutions s' écrivent sous la forme : Comme ceci est vrai pour toute forme linéaire E ? et les i , j ne dépendent pas de , on a Soit E un K - espace vectoriel de dimension finie et soit u et v deux endomorphismes de E qui commutent Démonstration Soit Sp(u ) et ***soit*** x Eu ( )

**39401**: Théorème 4.3 Critère de co-diagonalisation ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u et v deux endomorphismes de E qui sont diagonalisables

**39414**: Théorème 4.3 Critère de co-diagonalisation Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u et v deux endomorphismes de E qui sont diagonalisables

**39471**: Démonstration Supposons que u et v ***soient*** co-diagonalisables

**39536**: En particulier , elles commutent donc : MatE ( u v ) MatE ( u ) MatE ( v ) MatE ( v ) MatE ( u ) MatE ( v u ) Supposons que u v v u. ***Soit*** Sp(u )

**39690**: Théorème 4.4 Critère de co-trigonalisation ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u et v deux endomorphismes de E qui sont trigonalisables

**39703**: Théorème 4.4 Critère de co-trigonalisation Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u et v deux endomorphismes de E qui sont trigonalisables

**39770**: ***Soit*** n N

**40127**: 4.2.2 ***Soit*** E est C - espace vectoriel de dimension finie non nulle et u et v sont deux endomorphismes de E qui vérifient : Démontrer que u et v possèdent au moins un vecteur propre commun

**40156**: 4.2.2 Soit E est C - espace vectoriel de dimension finie non nulle et u et v sont deux endomorphismes de E qui vérifient : Démontrer que u et v ***possèdent*** au moins un vecteur propre commun

**40165**: 4.2.3 ***Soit*** E est C - espace vectoriel de dimension finie non nulle et u , v et w trois endomorphismes de E qui vérifient : Démontrer que u et v possèdent au moins rang(w ) valeurs propres communes ( en comptant les multiplicités )

**40195**: 4.2.3 Soit E est C - espace vectoriel de dimension finie non nulle et u , v et w trois endomorphismes de E qui vérifient : Démontrer que u et v ***possèdent*** au moins rang(w ) valeurs propres communes ( en comptant les multiplicités )

**40211**: 4.2.4 ***Soit*** E un C - espace vectoriel de dimension finie non nulle et soit u et v deux endomorphismes de E tels que u v 0L ( E )

**40224**: 4.2.4 Soit E un C - espace vectoriel de dimension finie non nulle et ***soit*** u et v deux endomorphismes de E tels que u v 0L ( E )

**40328**: La recherche d' une solution particulière , ***soit*** évidente , soit par variation de la constante a : Nous sommes donc ramenés au calcul de An

**40331**: La recherche d' une solution particulière , soit évidente , ***soit*** par variation de la constante a : Nous sommes donc ramenés au calcul de An

**41114**: 4.4.1 Résoudre 4.4.2 Résoudre 4.4.3 Résoudre le système différentiel : 4.4.4 ***Soit*** A M3 ( R ) non inversible

**41151**: 4.4.5 Résoudre le système différentiel 4.4.6 Déterminer les a R tels que le système ***admette*** au moins une solution non nulle bornée au voisinage de

**41313**: En effet , ***soit*** ( e1 ,

**41439**: ide ) H. I Ces résultats suffisent en général lorsque l' on est en dimension 3 , car il ne y a que les droites dirigées par un vecteur propre et les hyperplans qui peuvent être stables ( avec en plus , bien évidemment , 0E ***Soit*** la matrice a : Le polynôme caractéristique est bien X 3

**41495**: 4.5.1 ***Soit*** u un endomorphisme de Rn ( n 2 )

**41509**: Démontrer que u ***laisse*** un plan stable

**41515**: 4.5.2 ***Soit*** E Rn , Sn , on note T l' application de E dans E définie par Démontrer que T est dans GL ( E )

**41565**: Trouver les sous-espaces vectoriels F de E tels que , pour tout 4.5.3 Trouver tous les sous-espaces stables de la matrice : 4.5.4 ***Soit*** E un K - espace vectoriel de dimension finie n 1 et f L ( E ) telle que f n 0L ( E ) et f n1 6 0L ( E )

**41619**: Démontrer que les sous espaces stables par f sont les Ker(f k ) pour k 0 , n. 4.5.5 ***Soit*** E un C - espace vectoriel de dimension finie n 1 et u L(E )

**41694**: 4.5.6 ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**41792**: Chapitre 5 Compléments sur la réduction des endomorphismes Polynômes d' endomorphisme Polynômes d' endomorphisme et polynômes annulateurs ***Soit*** E un K - espace vectoriel et soit ak X k KX Si u L ( E ) , on définit alors l' endomorphisme P ( u ) L ( E ) par a : On dit que P ( u ) est un polynôme d' endomorphisme en u. On note : Ku P ( u ) , P KX l' ensemble des polynômes en u On définit de même la notion de polynôme de matrice : Attention , il faut que la matrice soit carrée

**41800**: Chapitre 5 Compléments sur la réduction des endomorphismes Polynômes d' endomorphisme Polynômes d' endomorphisme et polynômes annulateurs Soit E un K - espace vectoriel et ***soit*** ak X k KX Si u L ( E ) , on définit alors l' endomorphisme P ( u ) L ( E ) par a : On dit que P ( u ) est un polynôme d' endomorphisme en u. On note : Ku P ( u ) , P KX l' ensemble des polynômes en u On définit de même la notion de polynôme de matrice : Attention , il faut que la matrice soit carrée

**41877**: Chapitre 5 Compléments sur la réduction des endomorphismes Polynômes d' endomorphisme Polynômes d' endomorphisme et polynômes annulateurs Soit E un K - espace vectoriel et soit ak X k KX Si u L ( E ) , on définit alors l' endomorphisme P ( u ) L ( E ) par a : On dit que P ( u ) est un polynôme d' endomorphisme en u. On note : Ku P ( u ) , P KX l' ensemble des polynômes en u On définit de même la notion de polynôme de matrice : Attention , il faut que la matrice ***soit*** carrée

**41943**: De plus , P ( u ) et Q(u ) commutent car : ***Soit*** E un K - espace vectoriel , soit P KX et soit u L ( E )

**41951**: De plus , P ( u ) et Q(u ) commutent car : Soit E un K - espace vectoriel , ***soit*** P KX et soit u L ( E )

**41955**: De plus , P ( u ) et Q(u ) commutent car : Soit E un K - espace vectoriel , soit P KX et ***soit*** u L ( E )

**41970**: On dit que P est un polynôme annulateur ***Soit*** E un K - espace vectoriel de dimension finie , soit u L ( E ) et soit P KX un polynôme annulateur de u. Alors : Autrement dit , les valeurs propres de sont racines de tout polynôme annulateur de P

**41981**: On dit que P est un polynôme annulateur Soit E un K - espace vectoriel de dimension finie , ***soit*** u L ( E ) et soit P KX un polynôme annulateur de u. Alors : Autrement dit , les valeurs propres de sont racines de tout polynôme annulateur de P

**41988**: On dit que P est un polynôme annulateur Soit E un K - espace vectoriel de dimension finie , soit u L ( E ) et ***soit*** P KX un polynôme annulateur de u. Alors : Autrement dit , les valeurs propres de sont racines de tout polynôme annulateur de P

**42015**: Démonstration ***Soit*** Sp(u ) et soit x un vecteur propre associé : u(x ) .x

**42019**: Démonstration Soit Sp(u ) et ***soit*** x un vecteur propre associé : u(x ) .x

**42139**: Ainsi , connaître les racines d' un polynôme annulateur de u ne donne que des candidats potentiels pour les valeurs propres de u. Le lemme des noyaux Théorème 5.1 dit lemme des noyaux ***Soit*** E un K - espace vectoriel et u L ( E )

**42199**: Si ( P , Q ) KX2 sont premiers deux à deux , alors : premiers deux à deux Démonstration Puisque P et Q sont premiers deux à deux , il existe ( U , V ) KX2 tel que ( identité de Bézout ) : ***Soit*** x Ker P ( u ) Ker Q(u )

**42224**: On en déduit ***Soit*** x Ker ( P Q)(u )

**42308**: , Pk des polynômes premiers deux à deux , alors : Ker Pi ( u ) Théorème 5.2 Caractérisation des endomorphismes diagonalisables ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**42391**: Démonstration Supposons u ***soit*** diagonalisable et notons Sp(u ) 1 ,

**42405**: ***Soit*** Le polynôme P est scindé à racines simples

**42843**: Polynôme minimal ***Soit*** E un K - espace vectoriel , soit P KX et soit u L ( E )

**42851**: Polynôme minimal Soit E un K - espace vectoriel , ***soit*** P KX et soit u L ( E )

**42855**: Polynôme minimal Soit E un K - espace vectoriel , soit P KX et ***soit*** u L ( E )

**42871**: L' idéal annulateur de u est défini par : ***Soit*** E un K - espace vectoriel et soit u L ( E )

**42879**: L' idéal annulateur de u est défini par : Soit E un K - espace vectoriel et ***soit*** u L ( E )

**42953**: c' est - à - dire que ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u L ( E )

**42966**: c' est - à - dire que Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u L ( E )

**43080**: ***Soit*** P Iu

**43211**: Si E est une base de E ( en dimension finie ) et si A est la matrice de u dans la base E , alors : ***Soit*** E un K - espace vectoriel de dimension finie non nulle et soit u L ( E )

**43224**: Si E est une base de E ( en dimension finie ) et si A est la matrice de u dans la base E , alors : Soit E un K - espace vectoriel de dimension finie non nulle et ***soit*** u L ( E )

**43356**: Proposition 5.1 ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**43423**: Supposons que u ***soit*** diagonalisable

**43510**: On en déduit que u est scindé à racines simples car il ***divise*** P qui est lui-même scindé à racines simples

**43525**: Théorème de Cayley - Hamilton ***Soit*** P un polynôme unitaire : ak X k X p KX La matrice compagnon du polynôme P est définie par : Soit P KX un polynôme unitaire

**43547**: Théorème de Cayley - Hamilton Soit P un polynôme unitaire : ak X k X p KX La matrice compagnon du polynôme P est définie par : ***Soit*** P KX un polynôme unitaire

**43578**: Alors : Démonstration Reprenons les notations de la définition 5.5 , page précédente et effectuons l' opération élémentaire : de sorte que ( on ***développe*** ensuite selon la première ligne et on reconnaît le déterminant d' une matrice triangulaire ) : Théorème 5.3 Cayley - Hamilton Soit E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**43600**: Alors : Démonstration Reprenons les notations de la définition 5.5 , page précédente et effectuons l' opération élémentaire : de sorte que ( on développe ensuite selon la première ligne et on reconnaît le déterminant d' une matrice triangulaire ) : Théorème 5.3 Cayley - Hamilton ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**43634**: Alors Autrement dit , le polynôme caractéristique u de u est annulateur de u. Démonstration ***Soit*** x E , x 6 0E ( possible car n dim E 1 )

**43677**: , up ( x ) ) ***soit*** liée , donc la famille ( x , u(x ) ,

**43939**: Théorème 5.4 ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**44105**: 5.1.2 ***Soit*** E l' ensemble des matrices 2 2 à coefficients dans Z de déterminant égal à 1

**44149**: 5.1.4 ***Soit*** E un K - espace vectoriel de dimension finie n 1 , x E et f L ( E )

**44195**: ( b ) ***Soit*** mx et my premiers deux à deux , démontrer que mxy mx my

**44221**: ( c ) Démontrer que le polynôme minimal f de f ***vérifie*** : iii

**44236**: 5.1.5 ***Soit*** E un C - espace vectoriel de dimension finie non nulle et u L ( E ) , donner une condition nécessaire et suffisante pour que : u2 diagonalisable u diagonalisable Que devient ce résultat lorsque le corps est R ? 5.1.6 Soit A Mn ( R ) telle que A3 3 A 2 In 0n

**44279**: 5.1.5 Soit E un C - espace vectoriel de dimension finie non nulle et u L ( E ) , donner une condition nécessaire et suffisante pour que : u2 diagonalisable u diagonalisable Que devient ce résultat lorsque le corps est R ? 5.1.6 ***Soit*** A Mn ( R ) telle que A3 3 A 2 In 0n

**44307**: A est-elle diagonalisable ? Calculer Ap pour p Z. Topologie sur les endomorphismes ***Soit*** ( E , k k ) un espace vectoriel normé a , on peut munir Lc ( E ) ( l' espace des endomorphismes continus de E ) de la norme subordonnée donnée par : On a alors : De plus , est une norme d' algèbre : Si E est de dimension finie , tous les endomorphismes sont continues : Lc ( E ) L ( E ) ( c' est faux en dimension infinie )

**44435**: a. Dans cette partie , quand on parle d' un espace vectoriel normé ( E , k k ) , on se place toujours dans le corps K R ou C. Proposition 5.2 Densité des endomorphismes inversibles et diagonalisables ***Soit*** ( E , k k ) un espace vectoriel normé de dimension finie non nulle

**44528**: GL ( E ) est un ouvert de L ( E ) car GL ( E ) det1 ( K ) avec det : L ( E ) K continue et K ouvert de K. ***Soit*** u L ( E )

**44565**: Son polynôme caractéristique u ne a qu' un nombre fini de racines ( car deg u dim E 1 ) donc il existe r 0 tel que u ne s' ***annule*** pas sur B(0 , r ) 0

**44828**: ***Soit*** ( E , k k ) un espace vectoriel normé et u Lc ( E )

**44893**: ***Soit*** A Mn ( C )

**44931**: Le rayon spectral de A est défini par : D' après la propriété précédente , pour ne importe quelle norme d' algèbre sur Mn ( C ) , on a : ***Soit*** A Mn ( C ) et soit 0

**44938**: Le rayon spectral de A est défini par : D' après la propriété précédente , pour ne importe quelle norme d' algèbre sur Mn ( C ) , on a : Soit A Mn ( C ) et ***soit*** 0

**45135**: Il est souvent crucial que la suite ( Uk ) kN ***soit*** bornée ( par exemple pour garantir la stabilité du schéma numérique considéré )

**45159**: Comme : il faut que ( Ak ) kN ***soit*** borné

**45223**: ***Soit*** ( E , k k ) un espace vectoriel normé de dimension finie et soit k ak z kPune série entière de rayon de convergence R 0 ,

**45238**: Soit ( E , k k ) un espace vectoriel normé de dimension finie et ***soit*** k ak z kPune série entière de rayon de convergence R 0 ,

**45496**: En particulier , k0 ak .uk commute avec ***Soit*** u L ( E ) tel que u 1

**45538**: Alors idE u est inversible et En effet , cette somme existe d' après la propriété ci - dessus et : et de même : uk ( idE u ) idE ***Soit*** ( E , k k ) un espace vectoriel normé de dimension finie et soit u L ( E )

**45553**: Alors idE u est inversible et En effet , cette somme existe d' après la propriété ci - dessus et : et de même : uk ( idE u ) idE Soit ( E , k k ) un espace vectoriel normé de dimension finie et ***soit*** u L ( E )

**45569**: L' exponentielle de u est défini exp(u ) eu ***Soit*** ( E , k k ) un espace vectoriel normé de dimension finie et soit ( u , v ) L ( E)2

**45584**: L' exponentielle de u est défini exp(u ) eu Soit ( E , k k ) un espace vectoriel normé de dimension finie et ***soit*** ( u , v ) L ( E)2

**45657**: ***Soit*** N N , posons : Comme u et v commutent : d' où le résultat puisque N exp(u ) exp(v ) exp(u v ) quand N

**45890**: 5.2.1 ***Soit*** ( E , k k ) un espace vectoriel normé de dimension finie n 1

**45916**: ( a ) Démontrer que u 7 u est ***continue*** de L ( E ) dans Kn X. ( b ) En déduire par un argument de densité que : ( c ) Démontrer que le résultat est encore vrai dans ne importe quel corps K et ne importe quel K - espace vectoriel E ( par un argument algébrique )

**45949**: ( a ) Démontrer que u 7 u est continue de L ( E ) dans Kn X. ( b ) En déduire par un argument de densité que : ( c ) Démontrer que le résultat est encore vrai dans ne ***importe*** quel corps K et ne importe quel K - espace vectoriel E ( par un argument algébrique )

**45987**: 5.2.3 ***Soit*** ( E , k k ) un espace vectoriel normé de dimension finie n 1

**46101**: 5.2.5 ***Soit*** ( E , k k ) un espace vectoriel normé de dimension finie

**46138**: Démontrer que : 5.2.6 Démontrer que : A Mn ( C ) , det(exp(A ) ) exp(trace(A ) ) Décomposition de Dunford ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E ) nilpotent a

**46205**: ***Soit*** N , on suppose que le résultat est vrai au rang n. Soit u L ( E ) nilpotent ( avec dim E n 1 ) , soit p N tel que up 0L ( E )

**46218**: Soit N , on suppose que le résultat est vrai au rang n. ***Soit*** u L ( E ) nilpotent ( avec dim E n 1 ) , soit p N tel que up 0L ( E )

**46233**: Soit N , on suppose que le résultat est vrai au rang n. Soit u L ( E ) nilpotent ( avec dim E n 1 ) , ***soit*** p N tel que up 0L ( E )

**46346**: ***Soit*** E un K - espace vectoriel de dimension finie n 1 et u L ( E )

**46392**: Si le polynôme caractéristique u de u est scindé : où les k sont distincts , on appelle espace caractéristique associé à la valeur propre k : ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E ) tel que u soit scindé : où les k sont distincts 1

**46413**: Si le polynôme caractéristique u de u est scindé : où les k sont distincts , on appelle espace caractéristique associé à la valeur propre k : Soit E un K - espace vectoriel de dimension finie non nulle et u L ( E ) tel que u ***soit*** scindé : où les k sont distincts 1

**46504**: ***Soit*** k 1 , p. Notons uk la restriction de u à Fu ( k )

**46821**: Le point 2 démontre que si u est scindé , alors dans une base E de E adaptée à la décomposition E Fu ( 1 ) Fu ( p ) , la matrice de u est diagonale par blocs : Théorème 5.5 Décomposition de Dunford ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E ) tel que u soit scindé

**46842**: Le point 2 démontre que si u est scindé , alors dans une base E de E adaptée à la décomposition E Fu ( 1 ) Fu ( p ) , la matrice de u est diagonale par blocs : Théorème 5.5 Décomposition de Dunford Soit E un K - espace vectoriel de dimension finie non nulle et u L ( E ) tel que u ***soit*** scindé

**46863**: Il existe un unique couple ( d , n ) L ( E)2 tel que : et qui ***commutent*** ( d n n d )

**47253**: On peut se servir de la décomposition de Dunford pour calculer les puissances An ou l' exponentielle exp(A ) d' une matrice carrée A. ***Soit*** A D N avec D diagonalisable et N nilpotent la décomposition de Dunford de A. On note q l' indice de nilpotence de N ( le plus petit entier q N tel que N q 0n )

**47455**: Commutant et réduction de Jordan ***Soit*** E un K - espace vectoriel et u L ( E )

**47526**: ***Soit*** E un K - espace vectoriel de dimension finie n 1 et u L ( E ) diagonalisable

**47805**: Proposition 5.3 Réduction de Jordan d' un endomorphisme nilpotent ***Soit*** E un K - espace vectoriel de dimension finie n 1 et soit u L ( E ) nilpotent

**47818**: Proposition 5.3 Réduction de Jordan d' un endomorphisme nilpotent Soit E un K - espace vectoriel de dimension finie n 1 et ***soit*** u L ( E ) nilpotent

**47848**: Alors il existe une base E de E pour laquelle : où les blocs Bk , appelés blocs de Jordan , sont ***soit*** nuls , soit de la forme : Démonstration On passe par les invariants de similitude ( voir la dernière partie ) : si ( P1 ,

**47851**: Alors il existe une base E de E pour laquelle : où les blocs Bk , appelés blocs de Jordan , sont soit nuls , ***soit*** de la forme : Démonstration On passe par les invariants de similitude ( voir la dernière partie ) : si ( P1 ,

**47978**: Théorème 5.6 Réduction de Jordan ***Soit*** E un K - espace vectoriel de dimension finie n 1 et soit u L ( E ) tel que son polynôme caractéristique u soit scindé

**47991**: Théorème 5.6 Réduction de Jordan Soit E un K - espace vectoriel de dimension finie n 1 et ***soit*** u L ( E ) tel que son polynôme caractéristique u soit scindé

**48003**: Théorème 5.6 Réduction de Jordan Soit E un K - espace vectoriel de dimension finie n 1 et soit u L ( E ) tel que son polynôme caractéristique u ***soit*** scindé

**48028**: Alors il existe une base E de E pour laquelle : où les blocs Bk , appelés blocs de Jordan , sont ***soit*** diagonales , soit de la forme : Démonstration On reprend les notations de la définition 5.8 , page 245

**48031**: Alors il existe une base E de E pour laquelle : où les blocs Bk , appelés blocs de Jordan , sont soit diagonales , ***soit*** de la forme : Démonstration On reprend les notations de la définition 5.8 , page 245

**48143**: Lorsque les valeurs propres sont confondues , il y a de mauvaises surprises , ainsi : 5.3.1 Trouver le commutant de la matrice : 5.3.2 ***Soit*** E un C - espace vectoriel de dimension finie n 1 et soit u L(E )

**48156**: Lorsque les valeurs propres sont confondues , il y a de mauvaises surprises , ainsi : 5.3.1 Trouver le commutant de la matrice : 5.3.2 Soit E un C - espace vectoriel de dimension finie n 1 et ***soit*** u L(E )

**48184**: , np ( avec p à déterminer ) tels que : 5.3.3 ***Soit*** E un C - espace vectoriel de dimension finie de dimension n , soit f1 ,

**48198**: , np ( avec p à déterminer ) tels que : 5.3.3 Soit E un C - espace vectoriel de dimension finie de dimension n , ***soit*** f1 ,

**48219**: Démontrer que 5.3.4 ***Soit*** E un K - espace vectoriel de dimension n 1 et f L(E ) telle que f n1 6 0L ( E ) et f n 0L ( E )

**48261**: ( b ) Démontrer que l' ensemble des endomorphismes qui ***commutent*** avec f est un sous-espace vectoriel de L ( E ) de base 5.3.5 Soit E un K - espace vectoriel de dimension 2 et u L ( E ) qui ne est pas une homothétie

**48276**: ( b ) Démontrer que l' ensemble des endomorphismes qui commutent avec f est un sous-espace vectoriel de L ( E ) de base 5.3.5 ***Soit*** E un K - espace vectoriel de dimension 2 et u L ( E ) qui ne est pas une homothétie

**48307**: Déterminer la dimension du commutant de u. 5.3.6 ***Soit*** ( a , b , c ) K3

**48324**: Calculer la dimension du commutant de 5.3.7 ***Soit*** A une matrice réelle triangulaire supérieure

**48464**: ( a ) Démontrer que est de dimension au moins n. ( b ) Démontrer que si A Mn ( C ) alors son commutant est de dimension au moins n. ( c ) Que dire d' une matrice A de Mn ( C ) dont le commutant est égal à l' ensemble CA ? 5.3.9 Pour quels entiers n le groupe GLn ( R ) admet -il un sous-groupe isomorphe à Z4 Z ? ( a ) Démontrer que A est semblable à : ( b ) Trouver les matrices réelles qui commutent avec A. 5.3.11 ***Soit*** E un K - espace vectoriel et u L ( E ) un endomorphisme nilpotent de E. Soit q l' indice de nilpotence de u : Soit x E tel que : ( a ) Démontrer que la famille x , u(x ) ,

**48482**: ( a ) Démontrer que est de dimension au moins n. ( b ) Démontrer que si A Mn ( C ) alors son commutant est de dimension au moins n. ( c ) Que dire d' une matrice A de Mn ( C ) dont le commutant est égal à l' ensemble CA ? 5.3.9 Pour quels entiers n le groupe GLn ( R ) admet -il un sous-groupe isomorphe à Z4 Z ? ( a ) Démontrer que A est semblable à : ( b ) Trouver les matrices réelles qui commutent avec A. 5.3.11 Soit E un K - espace vectoriel et u L ( E ) un endomorphisme nilpotent de E. ***Soit*** q l' indice de nilpotence de u : Soit x E tel que : ( a ) Démontrer que la famille x , u(x ) ,

**48491**: ( a ) Démontrer que est de dimension au moins n. ( b ) Démontrer que si A Mn ( C ) alors son commutant est de dimension au moins n. ( c ) Que dire d' une matrice A de Mn ( C ) dont le commutant est égal à l' ensemble CA ? 5.3.9 Pour quels entiers n le groupe GLn ( R ) admet -il un sous-groupe isomorphe à Z4 Z ? ( a ) Démontrer que A est semblable à : ( b ) Trouver les matrices réelles qui commutent avec A. 5.3.11 Soit E un K - espace vectoriel et u L ( E ) un endomorphisme nilpotent de E. Soit q l' indice de nilpotence de u : ***Soit*** x E tel que : ( a ) Démontrer que la famille x , u(x ) ,

**48569**: , uq1 ( x ) et on suppose que E est de dimension finie n p. I Par ailleurs , ***soit*** E ? une forme linéaire telle que : On pose alors : I Finalement , on pose : ( c ) Justifier l' existence de

**48666**: Extraction de racine : ***soit*** A Mn ( K ) et p N , existe -t -il des matrices B telles que B p A ? Et si c' est le cas , comment les trouver toutes ? 2

**48704**: Logarithme : ***soit*** A Mn ( K ) ( K R ou C ) , existe -t -il des matrices B telles que B p A ? Et si c' est le cas , comment les trouver toutes ? L' extraction de racine possède deux propriétés immédiates : 1

**48770**: Si B existe , alors det(B)p det(A ) donc une condition nécessaire d' existence est que det(A ) ***admette*** une racine p - ième dans le corps K. 2

**48853**: ***Soit*** la matrice : résolvons B A , pour p 2 , 3 , d' inconnue B M3 ( R )

**49119**: ***Soit*** A la matrice : Elle est de déterminant 2 0

**49241**: Avec Wxmaxima : ***Soit*** n N , existe -t -il h L ( RX ) tel que hn T ? Si oui , déterminer h. 5.4.2 Quelles sont les A GL2 ( R ) telles qu' il existe X GL2 ( R ) telle que A X 3 ? 5.4.3 Démontrer que exp Mn ( C ) GLn ( C ) 5.4.4 ( a ) Démontrer que si A Mn ( C ) vérifie exp(A ) In , alors A est diagonalisable

**49336**: 5.4.5 Résoudre l' équation 5.4.6 ***Soit*** n N , résoudre l' équation 5.4.7 Soit A Mn ( R ) , donner une condition nécessaire et suffisante pour que l' équation suivante ait une solution dans Mn ( R ) : 5.4.8 Soit A la matrice de l' exemple 5.5 , page 252

**49344**: 5.4.5 Résoudre l' équation 5.4.6 Soit n N , résoudre l' équation 5.4.7 ***Soit*** A Mn ( R ) , donner une condition nécessaire et suffisante pour que l' équation suivante ait une solution dans Mn ( R ) : 5.4.8 Soit A la matrice de l' exemple 5.5 , page 252

**49362**: 5.4.5 Résoudre l' équation 5.4.6 Soit n N , résoudre l' équation 5.4.7 Soit A Mn ( R ) , donner une condition nécessaire et suffisante pour que l' équation suivante ***ait*** une solution dans Mn ( R ) : 5.4.8 Soit A la matrice de l' exemple 5.5 , page 252

**49372**: 5.4.5 Résoudre l' équation 5.4.6 Soit n N , résoudre l' équation 5.4.7 Soit A Mn ( R ) , donner une condition nécessaire et suffisante pour que l' équation suivante ait une solution dans Mn ( R ) : 5.4.8 ***Soit*** A la matrice de l' exemple 5.5 , page 252

**49398**: Trouver toutes les solutions dans M3 ( R ) de l' équation : 5.4.9 ***Soit*** A la matrice de l' exemple 5.7 , page 259

**49456**: ***Soit*** ( A , B ) Mn ( K)2 tel que A B. Alors : 1

**49745**: Les matrices suivantes sont semblables : ***Soit*** E un K - espace vectoriel de dimension finie non nulle , u L ( E ) et x E. On définit : Ix l' idéal des polynômes annulateurs x , c' est - à - dire le noyau de : KX E définie par ( P ) x le polynôme minimal de x ( le polynôme unitaire engendrant l' idéal Ix )

**49915**: Théorème 5.7 Théorème de Frobenius ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**49958**: Alors il existe r N et hxi i et , pour tout i 1 , r 1 , xi xi1 et xr u Démonstration ***Soit*** x E tel que x u ( voir la remarque précédente )

**50304**: ***Soit*** E un K - espace vectoriel de dimension finie non nulle et u L ( E )

**51345**: Cet exercice a été posé à un oral de concours dans les années 70 ... ***Soit*** ( a , b , u0 , u1 ) Z2 , on construit successivement les suites récurrentes : Nous allons démontrer que 1

**51732**: Dans Z5 Z ( Nous noterons toujours les classes sous la forme a ) Le même raisonnement nous conduit , lorsque le polynôme caractéristique est scindé aux matrices ( ( , ) Z5 Z2 ) impossible de période 1 , 5 ou 20 de période 1 , 2 ou 4 En effet , on sait d' après le petit théorème de Fermat que ce qui ***justifie*** la période 1 , 2 ou 4 pour la troisième forme de matrice