145

**738**: Signifie x E , y E L' écriture x , y E ne est pas correcte ! Opérations Signification Multiplication externe Multiplication des matrices Notations de définitions ***Introduit*** une nouvelle notation Introduit une nouvelle définition Espaces vectoriels dim E ou dim(E ) ou dimK E ou Ensemble des fonctions définies sur l' ensemble X à valeurs dans l' ensemble Y Ensemble des fonctions continues définies sur l' intervalle I R à valeurs dans Ensemble des fonctions continues par morceaux définies sur l' intervalle I R à valeurs dans K R ou C Ensemble des fonctions de classe C k où k N , définies sur l' intervalle I R à valeurs dans K R ou C Droite vectorielle engendrée par x Sous-espace vectoriel de l' espace vectoriel E engendré par la partie A Somme des sous-espaces vectoriels E1 et E2 d' un même espace vectoriel E Somme des Ei , où ( Ei ) iI est une famille de sous-espaces vectoriels d' un même espace vectoriel E et où I est un ensemble quelconque Somme directe des sous-espaces vectoriels E1 et E2 d' un même espace vectoriel Somme directe des Ei , où ( Ei ) iI est une famille de sous-espaces vectoriels d' un même espace vectoriel E et où I est un ensemble quelconque La dimension du K - espace vectoriel E Ensemble des applications linéaires de l' espace vectoriel E dans l' espace vectoriel L ( E , E ) , ensemble des endomorphismes de l' espace vectoriel E Ensemble des automorphismes de l' espace vectoriel E L ( E , K ) , où E est un K - espace vectoriel c' est l' ensemble des formes linéaires sur l' espace vectoriel E ( noter le ? et non pas ) Noyau d' une application linéaire f L ( E , F ) Image d' une application linéaire f L ( E , F ) Application linéaire identité de l' espace vectoriel E Restriction d' une application linéaire f L ( E , F ) à un sous-espace vectoriel Co-restriction d' une application linéaire f L ( E , F ) à un sous-espace vectoriel F 0 de F contenant Im(f ) Projection sur F parallèlement à G , où E F G Symétrie par rapport à F parallèlement à G Rang de l' application linéaire f Famille duale de la base ( ei ) iI d' un espace vectoriel E Dimension d' un supplémentaire de F Ensemble des solutions du système linéaire S Matrice n p dont les coefficients sont les ( ai , j ) ( i , j)1,n1,p Im(A ) , Ker(A ) , rang(A ) Déterminants Signification Nous utiliserons systématiquement les crochets pour noter les matrices ! Ensemble des matrices à coefficients dans l' ensemble A ayant n lignes et p colonnes Matrice identité de Mp ( K ) Matrice nulle de Mn , p ( K ) Matrice du vecteur x E dans la base E de l' espace vectoriel E Matrice de l' application linéaire f L ( E , E 0 ) dans les bases E de E et E 0 de Matrice de l' endomorphisme f L ( E ) dans la base E de E ( correspond à Matrice ne contenant que des 0 sauf sur la k - ième ligne et la l - ième colonne où il y a un 1 ( Attention : les dimensions de ces matrices ne sont pas précisées ... ) Transposée de A , où A Mn , p ( K ) Ensemble des matrices symétriques de Mp ( K ) Ensemble des matrices antisymétriques de Mp ( K ) Matrice diagonale Ensemble des matrices diagonales de Mp ( K ) Matrice du système de vecteurs X ( x1 ,

par_pas ind_pre

**742**: Signifie x E , y E L' écriture x , y E ne est pas correcte ! Opérations Signification Multiplication externe Multiplication des matrices Notations de définitions Introduit une nouvelle notation ***Introduit*** une nouvelle définition Espaces vectoriels dim E ou dim(E ) ou dimK E ou Ensemble des fonctions définies sur l' ensemble X à valeurs dans l' ensemble Y Ensemble des fonctions continues définies sur l' intervalle I R à valeurs dans Ensemble des fonctions continues par morceaux définies sur l' intervalle I R à valeurs dans K R ou C Ensemble des fonctions de classe C k où k N , définies sur l' intervalle I R à valeurs dans K R ou C Droite vectorielle engendrée par x Sous-espace vectoriel de l' espace vectoriel E engendré par la partie A Somme des sous-espaces vectoriels E1 et E2 d' un même espace vectoriel E Somme des Ei , où ( Ei ) iI est une famille de sous-espaces vectoriels d' un même espace vectoriel E et où I est un ensemble quelconque Somme directe des sous-espaces vectoriels E1 et E2 d' un même espace vectoriel Somme directe des Ei , où ( Ei ) iI est une famille de sous-espaces vectoriels d' un même espace vectoriel E et où I est un ensemble quelconque La dimension du K - espace vectoriel E Ensemble des applications linéaires de l' espace vectoriel E dans l' espace vectoriel L ( E , E ) , ensemble des endomorphismes de l' espace vectoriel E Ensemble des automorphismes de l' espace vectoriel E L ( E , K ) , où E est un K - espace vectoriel c' est l' ensemble des formes linéaires sur l' espace vectoriel E ( noter le ? et non pas ) Noyau d' une application linéaire f L ( E , F ) Image d' une application linéaire f L ( E , F ) Application linéaire identité de l' espace vectoriel E Restriction d' une application linéaire f L ( E , F ) à un sous-espace vectoriel Co-restriction d' une application linéaire f L ( E , F ) à un sous-espace vectoriel F 0 de F contenant Im(f ) Projection sur F parallèlement à G , où E F G Symétrie par rapport à F parallèlement à G Rang de l' application linéaire f Famille duale de la base ( ei ) iI d' un espace vectoriel E Dimension d' un supplémentaire de F Ensemble des solutions du système linéaire S Matrice n p dont les coefficients sont les ( ai , j ) ( i , j)1,n1,p Im(A ) , Ker(A ) , rang(A ) Déterminants Signification Nous utiliserons systématiquement les crochets pour noter les matrices ! Ensemble des matrices à coefficients dans l' ensemble A ayant n lignes et p colonnes Matrice identité de Mp ( K ) Matrice nulle de Mn , p ( K ) Matrice du vecteur x E dans la base E de l' espace vectoriel E Matrice de l' application linéaire f L ( E , E 0 ) dans les bases E de E et E 0 de Matrice de l' endomorphisme f L ( E ) dans la base E de E ( correspond à Matrice ne contenant que des 0 sauf sur la k - ième ligne et la l - ième colonne où il y a un 1 ( Attention : les dimensions de ces matrices ne sont pas précisées ... ) Transposée de A , où A Mn , p ( K ) Ensemble des matrices symétriques de Mp ( K ) Ensemble des matrices antisymétriques de Mp ( K ) Matrice diagonale Ensemble des matrices diagonales de Mp ( K ) Matrice du système de vecteurs X ( x1 ,

par_pas ind_pre

**3767**: ( ) A est ***inclus*** dans Vect(A ) ( par définition ) qui est stable par combinaisons linéaires , donc Vect(A ) contient toutes les combinaisons linéaires de vecteurs de A. Soit E un K - espace vectoriel

par_pas ind_pre

**4564**: En reprenant les notations de la définition 1.7 , page ci - contre , on a où xik iI Ei Eik pour tout k 1 , n. Le vecteur x s' ***écrit*** donc comme une combinaison linéaire d' éléments de iI Ei , donc x Vect ( ) Soit x Vect iI Ei

par_pas ind_pre

**4729**: Soit E1 , E2 et E3 trois sous-espaces vectoriels de E. Démontrer que : Démontrer que ce ne est plus vrai , si l' on ***enlève*** une des hypothèses à gauche

ind_pre sub_pre

**4773**: Soit E1 et E2 deux sous-espaces vectoriels de E , on dit que E1 et E2 sont en somme directe si tout élément de E1 E2 s' ***écrit*** , de manière unique sous la forme x1 x2 , où x1 E1 et x2 E2

par_pas ind_pre

**4911**: On en ***déduit*** que E1 et E2 sont en somme directe

par_pas ind_pre

**5024**: On en ***déduit*** que E1 et E2 sont en somme Soit E un K - espace vectoriel , soit ( Ei ) iI une famille de sous-espaces vectoriels de E , on dit qu' ils sont en somme directe , si on a écriture unique de 0E , soit : distincts 2 à 2 On écrit alors Ei à la place de Ne pas oublier que l' on ne sait faire que des sommes finies de vecteurs ! ! Si I contient strictement plus de deux éléments , la condition iI Ei 0E ne suffit pas pour assurer que les Ei sont en somme directe , de même que les conditions Ei Ej 0E pour tout Pour s' en convaincre , on peut considérer les sous-espaces vectoriels E1 R.(1 , 0 ) , E2 R.(0 , 1 ) et 1

par_pas ind_pre

**5878**: Famille libre Plus généralement , une famille ( xi ) iI est dite libre ( vecteurs indépendants ) , si ( écriture unique de 0E ) : distincts 2 à 2 Autrement ***dit*** , ( xi ) iI est libre si toute sous-famille finie est libre

par_pas ind_pre

**5929**: la famille ( xi ) iI est ***liée*** 2

par_pas pas_cop

**5999**: Notons la différence avec tous non nuls qui signifient que tous les coefficients sont non nuls , alors que non tous nuls ***signifie*** qu' il en existe au moins un non nul ! Démonstration 1

ind_pre sub_pre

**6003**: Notons la différence avec tous non nuls qui signifient que tous les coefficients sont non nuls , alors que non tous nuls signifie qu' il en ***existe*** au moins un non nul ! Démonstration 1

ind_pre sub_pre

**6084**: Dans C en tant que R - espace vectoriel les parties 1 , i , 1 , j et i , j sont libres , alors que la partie 1 , i , j est ***liée***

par_pas pas_cop

**6112**: Dans C en tant que C - espace vectoriel , les parties 1 , i , 1 , j et i , j sont ***liées***

par_pas pas_cop

**6173**: Alors .xik Vect(ei , i I ) ce qui ***contredit*** x 6 Vect(ei , i I )

par_pas ind_pre

**6213**: On en ***déduit*** que x ei , i I est une partie libre de E. Soit X ( xi ) iI une famille de vecteurs d' un K - espace vectoriel E. Alors : 1

par_pas ind_pre

**6260**: si il existe i0 I tel que xi0 0E , alors X est ***liée*** 2

par_pas pas_cop

**6285**: si il existe ( i , j ) I 2 tel que i 6 j et xi xj , alors X est ***liée*** 3

par_pas pas_cop

**6299**: si une sous-famille ( xi ) iJ où J I est ***liée*** , alors X est liée 4

par_pas pas_cop

**6304**: si une sous-famille ( xi ) iJ où J I est liée , alors X est ***liée*** 4

par_pas pas_cop

**6339**: Il existe une écriture de 0E non trivial , car 0E 1.xi0 , donc X est ***liée***

par_pas pas_cop

**6364**: Il existe une écriture de 0 K non trivial , car 0E xi xj 1.xi ( 1).xj , donc X est ***liée***

par_pas pas_cop

**6490**: Si B ( ei ) iI est une base de E , alors a : distincts 2 à 2 Cela signifie que tout vecteur de E s' ***écrit*** de manière unique comme une combinaison linéaire d' éléments a. Notons que dans cette écriture , lorsque x 0E , on a n 0

par_pas ind_pre

**6521**: Démonstration Immédiat : x s' ***écrit*** comme une combinaison linéaire d' éléments de B car B est génératrice et cette combinaison linéaire est unique car B est libre

par_pas ind_pre

**7081**: Dans le cas contraire , il est ***dit*** de dimension infinie

par_pas ind_pre

**7382**: , n1 ) serait ***liée*** , ce qui contredit le fait que ( 1 ,

par_pas con_pas

**7386**: , n1 ) serait liée , ce qui ***contredit*** le fait que ( 1 ,

par_pas ind_pre

**7836**: , ep ) , cela ***fait*** un nouveau vecteur

par_pas ind_pre

**8023**: toute famille de plus de n 1 éléments est ***liée*** 2

par_pas pas_cop

**8099**: Si une famille de plus de n 1 éléments est libre , on pourrait la compléter en une base qui contiendrait au moins n 1 éléments , ce qui ***contredit*** dim E n. 2

par_pas ind_pre

**8507**: Alors E est de dimension infinie si , et seulement si , il existe des parties libres de cardinal quelconque n N. Démonstration Cela revient à démontrer que E est de dimension finie si , et seulement si , il existe n N tel que toute famille de E à n éléments soit ***liée***

par_pas sub_pas

**8640**: Soit L une famille libre d' éléments de F de cardinal p. Pour tout x F , la famille ( L , x ) est ***liée*** ( car sinon cela contredit la définition de p ) , donc x est combinaison linéaire d' éléments de L , donc L est une famille génératrice de F , c' est donc une base de F

par_pas pas_cop

**8645**: Soit L une famille libre d' éléments de F de cardinal p. Pour tout x F , la famille ( L , x ) est liée ( car sinon cela ***contredit*** la définition de p ) , donc x est combinaison linéaire d' éléments de L , donc L est une famille génératrice de F , c' est donc une base de F

par_pas ind_pre

**9305**: , en ) est une base de E , tout élément x E s' ***écrit*** de manière unique sous la forme 2

par_pas ind_pre

**10252**: On en ***déduit*** que f 1 ( F 0 ) est stable par combinaison linéaire

par_pas ind_pre

**10565**: Pour tout endomorphisme p d' un K - espace vectoriel E En effet , un raisonnement par analyse - synthèse démontre que x se ***décompose*** de manière unique sous 2

ind_pre sub_pre

**11072**: Puisque X est génératrice , il On a alors par linéarité de f ce qui démontre que y s' ***écrit*** comme une combinaison linéaire finie d' éléments de ( f ( xi ) ) iI

par_pas ind_pre

**12912**: Démonstration Si n p , on peut définir l' application linéaire f L ( E , E 0 ) telle que f ( ei ) e0i pour tout i 1 , n. elle est donc libre , ce qui ***démontre*** que f est injective ( voir la remarque 1.19 , page 51 )

ind_pre sub_pre

**15047**: Notons cette application : regardons ce que ***deviennent*** g f et f g. Soit un élément x E , que l' on décompose suivant la somme directe F Ker(f ) , alors iF E fe1 pIm(f ) kF 0 fe(xF ) iF E fe1 fe(xF ) De même , si x0 E 0 que l' on décompose sous la forme x0 xF 0 f ( x ) xF 0 fe(xF ) , alors : Finalement , on obtient : Figure 1.4 Utilisation de la factorisation g dépend du choix de F 0 ( et bien sûr de F )

ind_pre sub_pre

**15062**: Notons cette application : regardons ce que deviennent g f et f g. Soit un élément x E , que l' on ***décompose*** suivant la somme directe F Ker(f ) , alors iF E fe1 pIm(f ) kF 0 fe(xF ) iF E fe1 fe(xF ) De même , si x0 E 0 que l' on décompose sous la forme x0 xF 0 f ( x ) xF 0 fe(xF ) , alors : Finalement , on obtient : Figure 1.4 Utilisation de la factorisation g dépend du choix de F 0 ( et bien sûr de F )

ind_pre sub_pre

**15096**: Notons cette application : regardons ce que deviennent g f et f g. Soit un élément x E , que l' on décompose suivant la somme directe F Ker(f ) , alors iF E fe1 pIm(f ) kF 0 fe(xF ) iF E fe1 fe(xF ) De même , si x0 E 0 que l' on ***décompose*** sous la forme x0 xF 0 f ( x ) xF 0 fe(xF ) , alors : Finalement , on obtient : Figure 1.4 Utilisation de la factorisation g dépend du choix de F 0 ( et bien sûr de F )

ind_pre sub_pre

**15370**: On obtient un candidat au rôle de u. Il s' ***écrit*** : ( Synthèse ) Il suffit alors de vérifier qu' il convient a , si x E , alors : or w(x ) Im(v ) par hypothèse 2

par_pas ind_pre

**16704**: , en ) , ( ou la famille que l' on ***imagine*** être la base ante - duale ) , c' est alors facile : soit ( 1 ,

ind_pre sub_pre

**17995**: Il reste à montrer que : de dimension p1 donc , en utilisant la première question de l' exercice 1.4.2 , page 32 , on obtient , puisque a E2 C' est ainsi que l' on ***retrouve*** que dans l' espace , les droites sont définies par 2 équations

ind_pre sub_pre

**18153**: Cependant , l' intersection d' hyperplans affines peut-être vide , aussi faut -il , avant toutes choses , s' assurer qu' elle ne l' est pas ! Puis , en s' appuyant sur un point trouvé de l' intersection , on est ***ramené*** au cas vectoriel

par_pas pas_cop

**18787**: Si e0 0E0 , le système est ***dit*** homogène

par_pas ind_pre

**18844**: Si e0 6 0E0 , le système : est ***dit*** système homogène associé de ( S )

par_pas ind_pre

**18938**: Si e0 s' ***écrit*** comme une somme : Si pour tout k 1 , p , xk est une solution du système linéaire : alors une solution de ( S ) est Démonstration C' est immédiat par linéarité de u : donc x Sol(S )

par_pas ind_pre

**19609**: C' est pourquoi , il a fallu faire appel à d' autres classes de fonctions telles que : elles soient faciles à calculer elles ***approximent*** bien la fonction initiale elles soient insensibles à ce phénomène de divergence

ind_pre sub_pre

**19651**: Voici ce que ***donne*** l' approximation avec 30 points ( pour Lagrange , cela diverge )

ind_pre sub_pre

**19703**: , ep ) une base de E , alors : Autrement ***dit*** , en utilisant la dualité , pour tout k 1 , p , xk e?k ( x )

par_pas ind_pre

**19762**: , e0n ) des bases de E Autrement ***dit*** , en utilisant la dualité , pour tout ( i , j ) 1 , n 1 , p , ai , j ( e0i ) ? ( u(ej ) )

par_pas ind_pre

**20554**: Autrement ***dit*** , pour tout i 1 , n et en notant E ( e1 ,

par_pas ind_pre

**20604**: On a donc u 0L ( E , E 0 ) et on en ***déduit*** que Ker 0L ( E , E 0 ) donc est injective

par_pas ind_pre

**20729**: Il existe une base naturelle de Mn , p ( K ) , appelée base canonique , donnée par Autrement ***dit*** , le coefficient en ( i , j ) de Ek , est nul , sauf pour ( i , j ) ( k , ) en lequel il vaut 1

par_pas ind_pre

**20914**: a. Tiré de http : www.texample.nettikzexamplesmatrix - multiplication Il faut bien faire attention à ce que les dimensions des matrices soient compatibles : lorsque l' on veut faire le produit A B , le nombre de colonnes de A doit être égal au nombre de lignes de B. Soit E et E 0 deux K - espaces vectoriels de dimension finie ( avec p dim E et n dim E 0 ) , soit E une base de E et E 0 une base de E 0 , soit f L ( E , E 0 ) et soit x E. Alors Autrement ***dit*** , le produit matriciel MatE , E 0 ( f ) MatE ( x ) traduit le calcul de f ( x )

par_pas ind_pre

**20930**: a. Tiré de http : www.texample.nettikzexamplesmatrix - multiplication Il faut bien faire attention à ce que les dimensions des matrices soient compatibles : lorsque l' on veut faire le produit A B , le nombre de colonnes de A doit être égal au nombre de lignes de B. Soit E et E 0 deux K - espaces vectoriels de dimension finie ( avec p dim E et n dim E 0 ) , soit E une base de E et E 0 une base de E 0 , soit f L ( E , E 0 ) et soit x E. Alors Autrement dit , le produit matriciel MatE , E 0 ( f ) MatE ( x ) ***traduit*** le calcul de f ( x )

par_pas ind_pre

**20983**: On a Autrement ***dit*** , ai , j xj .e0i j1 ai , j xj est le i - ième coefficient de f ( x ) dans la base E ( e1 ,

par_pas ind_pre

**21098**: Proposition 2.2 Correspondance entre composition et produit matriciel Soit E , E 0 et E 00 des K - espaces vectoriels de dimension finie ( p dim E , n dim E 0 et q dim E 00 ) , soit Autrement ***dit*** , le produit matriciel MatE 0 , E 00 ( g ) MatE , E 0 ( f ) traduit le calcul de g f

par_pas ind_pre

**21118**: Proposition 2.2 Correspondance entre composition et produit matriciel Soit E , E 0 et E 00 des K - espaces vectoriels de dimension finie ( p dim E , n dim E 0 et q dim E 00 ) , soit Autrement dit , le produit matriciel MatE 0 , E 00 ( g ) MatE , E 0 ( f ) ***traduit*** le calcul de g f

par_pas ind_pre

**21930**: Soit : On a donc , avec cet abus de notation , Soit E ? la base duale de E , notons : de sorte que : Finalement : Autrement ***dit*** , 2

par_pas ind_pre

**22094**: Matrices diagonales , matrices triangulaires On dit que A est diagonale si tous ses coefficients non-diagonaux sont nuls , c' est - à - dire : Autrement ***dit*** : On note Dp ( K ) l' ensemble des matrices diagonales de Mp ( K )

par_pas ind_pre

**22141**: On dit que A est triangulaire supérieure si tous ses coefficients au - dessous de sa diagonale sont nuls , c' est - à - dire : Autrement ***dit*** : p ( K ) l' ensemble des matrices triangulaires supérieures de Mp ( K )

par_pas ind_pre

**22185**: On dit que A est triangulaire inférieur si tous ses coefficients au-dessus de sa diagonale sont nuls , c' est - à - dire : Autrement ***dit*** : p ( K ) l' ensemble des matrices triangulaires inférieures de Mp ( K )

par_pas ind_pre

**22917**: , xr ) dans la base E et on note : MatE ( X ) MatE où ai , j est le i - ième coefficient de xj dans la base E : Autrement ***dit*** , par dualité , pour tout ( i , j ) 1 , n 1 , r , ai , j e?i ( xj )

par_pas ind_pre

**23319**: Proposition 2.4 Changement de base pour les vecteurs Soit E un K - espace vectoriel de dimension finie , E et B deux bases de E , x E. Alors : MatE ( x ) PE Autrement ***dit*** , en multipliant à gauche par PE , on obtient les anciennes coordonnées en fonction des nouvelles coordonnées

par_pas ind_pre

**24294**: Plus généralement , si n N , n 2 , on peut s' intéresser aux ensembles : ( Ek ) k0,n1 est une partition de N Soit ( Ei ) iI une partition d' un ensemble E non vide et soit R la relation sur E définie par : ( autrement ***dit*** , x et y sont en relation lorsque x et y appartiennent à un même Ei )

par_pas ind_pre

**24674**: On en ***déduit*** que ( Ei ) iI recouvre E Soit ( i , j ) I 2 tel que i 6 j. Supposons que Ei Ej 6

par_pas ind_pre

**24757**: On a donc Ei Ej , ce qui ***contredit*** i 6 j donc Ei Ej

par_pas ind_pre

**25062**: Deux matrices M et N de Mn , p ( K ) sont ***dites*** équivalentes si : Si c' est le cas , on note Cela définit une relation sur Mn , p ( K ) appelée équivalence

par_pas ind_pre

**25101**: Deux matrices M et N de Mp ( K ) sont ***dites*** semblables si : Si c' est le cas , on note Cela définit une relation sur Mp ( K ) appelée similitude

par_pas ind_pre

**26697**: Autrement ***dit*** , toute matrice de Mn , p ( K ) de rang r est équivalente à Jn , p , r

par_pas ind_pre

**27017**: , Ss telles que : Autrement ***dit*** , quand A est inversible , on peut se contenter de travailler soit uniquement sur les lignes , soit uniquement sur les colonnes

par_pas ind_pre

**27723**: Dans le cas de la dimension finie et une fois des bases fixées , ce système linéaire est équivalent à un système de n équations à n inconnues , que l' on peut écrire sous forme matricielle : où A est la matrice n p de u , X la matrice p 1 de x et B la matrice n 1 de b ( avec p dim E et Lorsque l' on a un système de n équations à p inconnues , la condition de compatibilité ( c' est - à - dire la condition pour que le système admette des solutions ) s' ***écrit*** ( voir la partie suivante sur les matrices - blocs ) : rang(A ) rang A B ) ce qui se vérifie facilement à l' aide d' une méthode de pivot sur les lignes , où l' on ne prend jamais le pivot sur la colonne constituée des éléments de B. La matrice A B Mn , p1 ( K ) s' appelle la matrice augmentée du système A X B. Un système de n équations à n inconnues : est dit de Cramer , lorsque A est inversible

par_pas ind_pre

**27805**: Dans le cas de la dimension finie et une fois des bases fixées , ce système linéaire est équivalent à un système de n équations à n inconnues , que l' on peut écrire sous forme matricielle : où A est la matrice n p de u , X la matrice p 1 de x et B la matrice n 1 de b ( avec p dim E et Lorsque l' on a un système de n équations à p inconnues , la condition de compatibilité ( c' est - à - dire la condition pour que le système admette des solutions ) s' écrit ( voir la partie suivante sur les matrices - blocs ) : rang(A ) rang A B ) ce qui se vérifie facilement à l' aide d' une méthode de pivot sur les lignes , où l' on ne prend jamais le pivot sur la colonne constituée des éléments de B. La matrice A B Mn , p1 ( K ) s' appelle la matrice augmentée du système A X B. Un système de n équations à n inconnues : est ***dit*** de Cramer , lorsque A est inversible

par_pas ind_pre

**27960**: 6 1 , 6 , le système est de Cramer ( solution unique ) , le système réduit s' ***écrit*** : On voit que le cas 6 ne s' obtient pas par continuité du cas de Cramer

par_pas ind_pre

**27984**: Donc : l' ordinateur ne ***fait*** pas apparaître le cas ! ! ! Si on a vraiment besoin de calculer l' inverse d' une matrice A GLp ( K ) inversible , on peut appliquer l' algorithme du pivot de Gauss généralisée à la matrice augmentée A Ip , avec des opérations sur les lignes

par_pas ind_pre

**28080**: Autrement ***dit*** , en effectuant les mêmes opérations sur Ip , on obtient A1

par_pas ind_pre

**29373**: , ( i ) ***choisis*** , on a p i choix possibles pour ( i 1 ) ( les p i Une fois ( 1 ) ,

par_pas ind_pre

**29404**: , ( p 1 ) ***choisis*** , il ne reste plus qu' un seul choix pour ( p ) ( l' unique élément de Finalement , on a choix possibles pour construire , d' où le résultat

par_pas ind_pre

**29505**: Toute permutation 1 , p s' ***écrit*** à l' aide de transpositions , c' est - à - dire qu' il existe des transpositions de Sp , notée 1 ,

par_pas ind_pre

**30698**: , xp ) est ***liée*** , cela veut dire qu' il existe i 1 , p tel que xi soit une combinaison linéaire des Puisque est linéaire par rapport à sa i - ème variable : puisque xk apparaît deux fois dans (

par_pas pas_cop

**31495**: Supposons que C soit une base de E. D' après le résultat précédent , nous avons Par contraposition , si la famille C ne est pas une base de E alors elle est ***liée*** donc detE ( c1 ,

par_pas pas_cop

**31546**: Déterminant d' une matrice carrée Soit a A ai , j ( i , j)1,n2 Mn ( K ) , on appelle déterminant de A et on note Autrement ***dit*** , c' est le déterminant de la famille des n colonnes de A dans la base canonique de Mn,1 ( K )

par_pas ind_pre

**32274**: Ainsi , pour calculer un déterminant d' une matrice carrée d' ordre 5 , il faut effectuer Pire encore , 60 ! ' 1082 est supérieur au nombre d' atomes observables dans l' univers , alors que les problèmes de mathématiques appliquées et d' ingénierie moderne ***nécessitent*** de traiter des matrices qui ont des centaines de milliers voire des millions de lignes ... Il faut donc trouver des méthodes plus efficaces

ind_pre sub_pre

**33700**: On peut obtenir son terme général en utilisant le fait que 1 a et 2 a2 b c. On considère la fonction : C' est une fonction polynomiale en x. En effectuant les opérations élémentaires k 2 , n , Ck Ck C1 , puis en développant suivant la première colonne , on en ***déduit*** que cette fonction polynomiale est de degré inférieur ou égale à 1

par_pas ind_pre

**33716**: Elle s' ***écrit*** donc sous la forme : x

par_pas ind_pre

**33740**: Pour x a , le déterminant vaut Pour x b , le déterminant vaut On en ***déduit*** alors , puis la valeur du déterminant en évaluant en x 0

par_pas ind_pre

**34271**: On peut alors interpréter le déterminant de la manière suivante : v deux vecteurs de R2 , alors : où ( ) désigne l' aire de , le parallélogramme ***construit*** sur v

par_pas ind_pre

**34312**: w trois vecteurs de R3 , alors : où ( ) désigne le volume de , le parallélépipède ***construit*** sur On avait trouvé une autre formule ( qui est la même ) car : Plus généralement , si E est un R - espace vectoriel de dimension finie et si E et E 0 deux bases de E , on dit que E 0 a la même orientation que E si detE ( E 0 ) 0

par_pas ind_pre

**34473**: Toutes les bases ayant la même orientation que E sont ***dites*** directes et les autres indirectes

par_pas ind_pre

**34547**: Retour sur les systèmes linéaires On rappelle qu' un système linéaire de n équations à n inconnues de la forme d' inconnue X Mn,1 ( K ) avec A Mn ( K ) et B Mn,1 ( K ) est ***dit*** de Cramer lorsqu' il y a existence et unicité de la solution

par_pas ind_pre

**34562**: Autrement ***dit*** , c' est un système de Cramer si , et seulement si , A est inversible si , et seulement si , Proposition 3.3 Soit A GLn ( K ) de colonnes A1 ,

par_pas ind_pre

**35017**: ( b ) Démontrer que A possède une décomposition LU si , et seulement si , tous ses mineurs principaux m1 , ... mn sont non nuls , ***définis*** par : 3.1.9 ( a ) Démontrer que si A , B , C et D sont dans Mn ( R ) et que A C C A , alors : ( b ) Démontrer que c' est faux , en général , lorsqu' il ne y a plus commutation

par_pas ind_pre

**35974**: Le polynôme caractéristique de u , noté u , correspond à la fonction polynomiale : Afin d' alléger les notations et les calculs , on note le polynôme caractéristique u sous la forme d' un polynôme formel ( voir le cours sur les polynômes ) : au lieu d' une fonction polynomiale , où X est l' indéterminée , une variable ayant les mêmes règles de calcul que celles d' une variable dans K. Ainsi , une fonction polynomiale sur K de la forme se représente par Autrement ***dit*** , X correspond à la fonction polynomiale x 7 x. On note KX le K - espace vectoriel des polynômes ( formels ) à coefficients dans K et Kn X le sousespace vectoriel de KX des polynômes de degré inférieur ou égal à n. On définit de la même manière le polynôme caractéristique A det(A X.In ) d' une matrice carrée A Mn ( K )

par_pas ind_pre

**36180**: Posons : ai , j si i 6 j trace Atrace u puisque ( k),k a(k),k et ( ) , a ( ) , ne dépendent pas de X. On en ***déduit*** le résultat , en remarquant que le terme constant est u ( 0 ) det(u 0

par_pas ind_pre

**36243**: Autrement ***dit*** : Démonstration Immédiat en utilisant la propriété 4.1 , page précédente et en remarquant que u

par_pas ind_pre

**36982**: Autrement ***dit*** , une matrice est diagonalisable si elle est semblable à une matrice diagonale

par_pas ind_pre

**37216**: On en ***déduit*** que E est une base de E formée de vecteurs propres de u , donc u est diagonalisable

par_pas ind_pre

**37973**: On dit que u est ***dit*** trigonalisable si il existe un drapeau stable pour u , c' est - à - dire des sous-espaces vectoriels V1 ,

par_pas ind_pre

**37977**: On dit que u est dit trigonalisable si il ***existe*** un drapeau stable pour u , c' est - à - dire des sous-espaces vectoriels V1 ,

ind_pre sub_pre

**38079**: , en ) de E adaptée au drapeau , c' est - à - dire telle La diagonale de cette matrice est alors ***constituée*** des valeurs propres de u ( avec leurs multiplicités )

par_pas pas_cop

**38117**: Autrement ***dit*** , une matrice est trigonalisable si elle est semblable à une matrice triangulaire supérieure

par_pas ind_pre

**38911**: diagonalisable , il existe une base de vecteurs propres de E donc on peut écrire : avec , pour tout i 1 , k , xi Eu ( i ) On a donc : Autrement ***dit*** , on a un système linéaire d' inconnues x1 ,

par_pas ind_pre

**39031**: On peut donc écrire : Puisque que ceci est vrai pour toute forme linéaire E ? et en remarquant que les i , j ne ***dépendent*** pas de ( formules de Cramer ) , on a : en utilisant le fait que F est stable par tous les uj

ind_pre sub_pre

**39066**: On a donc démontré que tout élément de F s' ***écrit*** de manière unique comme une somme de vecteurs propres de u qui sont dans F , d' où : d' après le point 1

par_pas ind_pre

**39094**: On en ***déduit*** que v u F est diagonalisable

par_pas ind_pre

**39151**: Supposons F 6 E. Soit F une base de F que l' on complète en une base E de E. On a alors ( n dim E et p dim F ) : On en ***déduit*** que u v D

par_pas ind_pre

**39565**: D' après la propriété 4.7 , de la présente page , Eu ( ) est stable par v. Comme v est diagonalisable , on en ***déduit*** que v Eu ( ) est diagonalisable ( propriété 4.6 , page 203 )

par_pas ind_pre

**40156**: 4.2.2 Soit E est C - espace vectoriel de dimension finie non nulle et u et v sont deux endomorphismes de E qui vérifient : Démontrer que u et v ***possèdent*** au moins un vecteur propre commun

ind_pre sub_pre

**40195**: 4.2.3 Soit E est C - espace vectoriel de dimension finie non nulle et u , v et w trois endomorphismes de E qui vérifient : Démontrer que u et v ***possèdent*** au moins rang(w ) valeurs propres communes ( en comptant les multiplicités )

ind_pre sub_pre

**40342**: La recherche d' une solution particulière , soit évidente , soit par variation de la constante a : Nous sommes donc ***ramenés*** au calcul de An

par_pas pas_cop

**40824**: , p ) , alors En posant Y ( t ) P 1 X(t ) , on est ***ramené*** au système différentiel : qui est un système diagonal

par_pas pas_cop

**41045**: On est donc ***ramené*** ( par la même démarche qu' à l' exemple précédent en posant Y ( t ) P 1 X(t ) ) à un système de la forme où T est une matrice triangulaire supérieure que l' on peut résoudre facilement et on revient à X grâce à la relation X(t ) P Y ( t )

par_pas pas_cop

**41509**: Démontrer que u ***laisse*** un plan stable

ind_pre sub_pre

**41999**: On dit que P est un polynôme annulateur Soit E un K - espace vectoriel de dimension finie , soit u L ( E ) et soit P KX un polynôme annulateur de u. Alors : Autrement ***dit*** , les valeurs propres de sont racines de tout polynôme annulateur de P

par_pas ind_pre

**42135**: Ainsi , connaître les racines d' un polynôme annulateur de u ne donne que des candidats potentiels pour les valeurs propres de u. Le lemme des noyaux Théorème 5.1 ***dit*** lemme des noyaux Soit E un K - espace vectoriel et u L ( E )

par_pas ind_pre

**42223**: On en ***déduit*** Soit x Ker ( P Q)(u )

par_pas ind_pre

**42264**: De même , x2 Ker P ( u ) donc On en ***déduit*** le résultat

par_pas ind_pre

**42991**: Le polynôme minimal de u est l' unique polynôme unitaire de degré 1 u KX tel que Autrement ***dit*** , si P KX est annulateur de u , alors il existe Q KX tel que P u Q. L' existence et l' unicité du polynôme minimal sont assurées par le fait que KX est principal et que Iu est un idéal de KX non réduit à 0KX ( voir le cours sur les anneaux )

par_pas ind_pre

**43120**: On a nécessairement R 0KX ( sinon cela ***contredit*** la définition de d ) donc P Q u , autrement dit Iu u KX ( l' autre inclusion est immédiate puisque u Iu et que Iu est un idéal de KX )

par_pas ind_pre

**43132**: On a nécessairement R 0KX ( sinon cela contredit la définition de d ) donc P Q u , autrement ***dit*** Iu u KX ( l' autre inclusion est immédiate puisque u Iu et que Iu est un idéal de KX )

par_pas ind_pre

**43334**: On en ***déduit*** que u

par_pas ind_pre

**43500**: On en ***déduit*** que u est scindé à racines simples car il divise P qui est lui-même scindé à racines simples

par_pas ind_pre

**43510**: On en déduit que u est scindé à racines simples car il ***divise*** P qui est lui-même scindé à racines simples

ind_pre sub_pre

**43578**: Alors : Démonstration Reprenons les notations de la définition 5.5 , page précédente et effectuons l' opération élémentaire : de sorte que ( on ***développe*** ensuite selon la première ligne et on reconnaît le déterminant d' une matrice triangulaire ) : Théorème 5.3 Cayley - Hamilton Soit E un K - espace vectoriel de dimension finie non nulle et u L ( E )

ind_pre sub_pre

**43621**: Alors Autrement ***dit*** , le polynôme caractéristique u de u est annulateur de u. Démonstration Soit x E , x 6 0E ( possible car n dim E 1 )

par_pas ind_pre

**43678**: , up ( x ) ) soit ***liée*** , donc la famille ( x , u(x ) ,

par_pas sub_pas

**44221**: ( c ) Démontrer que le polynôme minimal f de f ***vérifie*** : iii

ind_pre sub_pre

**44565**: Son polynôme caractéristique u ne a qu' un nombre fini de racines ( car deg u dim E 1 ) donc il existe r 0 tel que u ne s' ***annule*** pas sur B(0 , r ) 0

ind_pre sub_pre

**44575**: Autrement ***dit*** , pour tout B(0 , r ) 0 , u

par_pas ind_pre

**45760**: A ) B(s ) ds Nous sommes donc ***ramenés*** au calcul de exp(t

par_pas pas_cop

**45916**: ( a ) Démontrer que u 7 u est ***continue*** de L ( E ) dans Kn X. ( b ) En déduire par un argument de densité que : ( c ) Démontrer que le résultat est encore vrai dans ne importe quel corps K et ne importe quel K - espace vectoriel E ( par un argument algébrique )

ind_pre sub_pre

**45949**: ( a ) Démontrer que u 7 u est continue de L ( E ) dans Kn X. ( b ) En déduire par un argument de densité que : ( c ) Démontrer que le résultat est encore vrai dans ne ***importe*** quel corps K et ne importe quel K - espace vectoriel E ( par un argument algébrique )

ind_pre sub_pre

**46863**: Il existe un unique couple ( d , n ) L ( E)2 tel que : et qui ***commutent*** ( d n n d )

ind_pre sub_pre

**47929**: On en ***déduit*** que les matrices compagnons C(Pi ) des Pi sont des transposées de blocs de Jordan

par_pas ind_pre

**48261**: ( b ) Démontrer que l' ensemble des endomorphismes qui ***commutent*** avec f est un sous-espace vectoriel de L ( E ) de base 5.3.5 Soit E un K - espace vectoriel de dimension 2 et u L ( E ) qui ne est pas une homothétie

ind_pre sub_pre

**48823**: On est alors ***ramené*** à la résolution de B p .In , ce qui est aisée

par_pas pas_cop

**48966**: On en ***déduit*** que B1 est diagonalisable dans C , égale à I2 ou semblable à Diag(j , j 2 ) avec j exp(2 i 3 ) , ce qui ramené dans R nous donne : Finalement , les B qui conviennent vérifient : Le calcul brutal ne est pas efficace ! Même si l' on pense à montrer que B C ( A )

par_pas ind_pre

**50050**: , e?n ) est la base duale associée , posons : Alors G est un sous-espace vectoriel de E stable par u. Démontrons que E hxi G. ce qui ***contredit*** y G. On a donc y 0E d' où hx G 0E

par_pas ind_pre

**50571**: Si C(P ) est une matrice compagnon , sa forme de Jordan ne ***fait*** apparaître qu' un et un seul bloc pour chaque valeur propre ( est une racine de P et la taille du bloc est son ordre de multiplicité )

par_pas ind_pre

**51074**: On en ***déduit*** que sa forme de Frobenius est : La forme de Smith correspondante est donc les invariants de similitude de A sont ( X 1 , A ( X 1)2 )

par_pas ind_pre

**51108**: On en ***déduit*** que sa forme de Frobenius 5.5.1 Déterminer la forme de Frobenius de la matrice : 5.5.2 Démontrer que : sont semblables

par_pas ind_pre

**51685**: Dans Z5 Z ( Nous noterons toujours les classes sous la forme a ) Le même raisonnement nous ***conduit*** , lorsque le polynôme caractéristique est scindé aux matrices ( ( , ) Z5 Z2 ) impossible de période 1 , 5 ou 20 de période 1 , 2 ou 4 En effet , on sait d' après le petit théorème de Fermat que ce qui justifie la période 1 , 2 ou 4 pour la troisième forme de matrice

par_pas ind_pre

**51732**: Dans Z5 Z ( Nous noterons toujours les classes sous la forme a ) Le même raisonnement nous conduit , lorsque le polynôme caractéristique est scindé aux matrices ( ( , ) Z5 Z2 ) impossible de période 1 , 5 ou 20 de période 1 , 2 ou 4 En effet , on sait d' après le petit théorème de Fermat que ce qui ***justifie*** la période 1 , 2 ou 4 pour la troisième forme de matrice

ind_pre sub_pre

